[{"title":"Five days with Copilot","url":"/2026/02/20/five-days-with-copilot.html","date":"2026-02-20","content":"Another itch to scratch As I mentioned yesterday , I've been a happy user of Pelican for a couple or so years now, but every so often there's a little change or tweak I'd like to make that requires diving deeper into the templates and the like and... I go \"eh, I'll look at it some time soon\" . Another thought that often goes through my head at those times is \"I should build my own static site generator that works exactly how I want\" -- because really any hacker with a blog has to do that at some point. Meanwhile... I've had free access to GitHub Copilot attached to my GitHub account for some time now, and I've hardly used it. At the same time -- the past few months especially -- I've been watching the rise of agents as coding tools, as well as the rise of advocates for them. Worse still, I've seen people I didn't expect to be advocates for giving up on coding turning to these tools and suddenly writing rationales in favour of them. So, suddenly, the idea popped into my head: I should write my own static site generator that I'll use for my blog, and I should try and use GitHub Copilot to write 100% of the code, and documentation, and see how far I get. I doing so I might firm up my opinions about where we're all going with this. The requirements were going to be pretty straightforward: It should be a static site generator that turns Markdown files into a website. It should be blog-first in its design. It should support non-blog-post pages too. It should be written in Python. It should use Jinja2 for templates. It should have a better archive system than I ever got out of my Pelican setup. It should have categories, tags, and all the usual metadata stuff you'd expect from a site where you're going to share content from. Of course, the requirements would drift and expand as I went along and I had some new ideas. Getting started To kick things off, I created my repo , and then opened Copilot and typed out a prompt to get things going. Here's what I typed: Build a blog-oriented static site generation engine. It should be built in Python, the structure of the repository should match that of my preferences for Python projects these days (see https://github.com/davep/oldnews and take clues from the makefile; I like uv and ruff and Mypy, etc). Important features: Everything is written in markdown All metadata for a post should come from frontmatter It should use Jinja2 for the output templates As you can see, rather than get very explicit about every single detail, I wanted to start out with a vague description of what I was aiming for. I did want to encourage it to try and build a Python repository how I normally would, so I pointed it at OldNews in the hope that it might go and comprehend how I go about things; I also doubled-down in the importance of using uv and mypy . The result of this was... actually impressive . As you'll see in that PR, to get to a point where it could be merged, there was some back-and-forth with Copilot to add things I hadn't thought of initially, and to get it to iron out some problems, but for the most part it delivered what I was after. Without question it delivered it faster than I would have. Some early issues where I had to point out problems to Copilot included: The order of posts on the home page wasn't obvious to me, and absolutely wasn't reverse chronological order. Footnotes were showing up kinda odd. The main index for the blog was showing just posts titles, not the full text of the article as you'd normally expect from a blog. Nothing terrible, and it did get a lot of the heavy lifting done and done well, but it was worth noting that a lot of dev-testing/QA needed to be done to be confident about its work, and doing this picked up on little details that are important. An improvement to the Markdown As an aside: during this first PR, I quickly noticed a problem where I was getting this error when generating the site from the Markdown : Error generating site: mapping values are not allowed in this context in &quot;&lt;unicode string&gt;&quot;, line 3, column 15 I just assumed it was some bug in the generated code and left Copilot to work it out. Instead it came back and educated me on something: I actually had bad YAML in the frontmatter of some of my posts ! This, by the way, wouldn't be the last time that Copilot found an issue with my input Markdown and so, having used it, improved my blog. A major feature from a simple request Another problem I ran into quickly was that previewing the generated site wasn't working well at all; all I could do was browse the files in the filesystem. So, almost as an offhand comment, in the initial PR, I asked : Can we get a serve mode please so I can locally test the site? Just like that, it went off and wrote a whole server for the project . While the server did need a lot of extra work to really work well 1 , the initial version was good enough to get me going and to iterate on the project as a whole. The main workflow Having kicked off the project and having had some success with getting Copilot to deliver what I was asking for, I settled into a new but also familiar workflow. Whereas normally, when working on a personal project, I'll write an issue for myself, at some point pick it up and create a PR, review and test the PR myself then merge, now the workflow turned into: Write an issue but do so in a way that when I assign it to Copilot it has enough information to go off and do the work. Wait for Copilot to get done. Review the PR, making change requests etc. Make any fixes that are easier for me to fix by hand that describe to Copilot. Merge. In fact, the first step had some sub-steps to it too, I was finding. What I was doing, more than ever, was writing issues like I'd write sticky notes: with simple descriptions of a bug or a new feature. I'd then come back to them later and flesh them out into something that would act as a prompt for Copilot. I found myself doing this so often I ended up adding a \"Needs prompt\" label to my usual set of issue labels . All of this made for an efficient workflow, and one where I could often get on with something else as Copilot worked on the latest job (I wasn't just working on other things on my computer; sometimes I'd be going off and doing things around the house while this happened), but... it wasn't fun. It was the opposite of what I've always enjoyed when it comes to building software. I got to dream up the ideas, I got to do the testing, I got to review the quality of the work, but I didn't get to actually lose myself in the flow state of coding. One thing I've really come to understand during those 5 days of working on BlogMore was I really missed getting lost in the flow state. Perhaps it's the issue to PR to review to merge cycle I used that amplified this, perhaps those who converse with an agent in their IDE or in some client application keep a sense of that (I might have to try that approach out), but this feels like a serious loss to me when it comes to writing code for personal enjoyment. The main problems I think it's fair to say that I've been surprised at just how well Copilot understood my (sometimes deliberately vague) requests, at how it generally managed to take some simple plain English and turn it into actual code that actually did what I wanted and, mostly, actually worked. But my experiences over the past few days haven't been without their problems. The confidently wrong problem Hopefully we all recognise that, with time and experience, we learn where the mistakes are likely to turn up. Once you've written enough code you've also written plenty of bugs and been caught out by plenty of edge-cases that you get a spidey-sense for trouble as you write code. I feel that this kind of approach can be called cautiously confident. Working with Copilot 2 , however, I often ran into the confidently wrong issue. On occasion I found it would proudly 3 request review for some minor bit of work, proclaiming that it had done the thing or solved the problem, and I'd test it and nothing had materially changed. On a couple of occasions, when I pushed back, I found it actually doubting my review before finally digging in harder and eventually solving the issue. I found that this took time and was rather tiring. There were also times where it would do the same but not directly in respect to code. One example I can think of is when it was confident that Python 3.14 was still a pre-release Python as of February 2026 ( it isn't ). This problem alone concerns me; this is the sort of thing where people without a good sense for when the agent is probably bullshitting will get into serious trouble. The tries-too-hard problem A variation on the above problem works the other way: on at least one occasion I found that Copilot tried too hard to fix a problem that wasn't really its to fix. In this case I was asking it to tidy up some validation issues in the RSS feed data . One of the main problems was root-relative URLs being in the content of the feed; for that they needed to be made absolute URLs. Copilot did an excellent job of fixing the problem, but one (and from what I could see only one) relative URL remained. I asked it to take a look and it took a real age to work over the issue. To its credit, it dug hard and it dug deep and it got to the bottom of the problem. The issue here though was it tried too hard because, having found the cause of the problem (a typo in my original Markdown, which had always existed) it went right ahead and built a workaround for this one specific broken link. Now, while I'm a fan of Postel's law , this is taking things a bit too far. If this was a real person I'd tasked with the job I would have expected and encouraged them to come back to me with their finding and say \"dude, the problem is in your input data\" and I'd have fixed my original Markdown. Here though it just went right ahead and added this one weird edge case as something to handle. I think this is something to be concerned about and to keep an eye on too. I feel there's a danger in having the agent rabbit-hole a fix for a problem that it should simply have reported back to me for further discussion. The never-pushes-back problem Something I did find unsurprising but disconcerting was Copilot's unwillingness to push back, or at least defend its choices. Sometimes it would make a decision or a change and I'd simply ask it why it had done it that way, why it had made that choice. Rather than reply with its reasoning it would pretty much go \"yeah, my bad, let me do it a way you're probably going to find more pleasing\" . A simple example of this is one time when I saw some code like this: @property def some_property ( self ) -&gt; SomeValue : from blogmore.utils import some_utility_function ... I'm not a fan of imports in the body of methods unless there's a demonstrable performance reason. I asked Copilot why it had made this choice here and its reply was simply to say it had gone ahead and changed the code, moving the import to the top of the module. I see plenty of people talk about how working with an agent is like pair-programming, but I think it misses out on what's got to be the biggest positive of that approach: the debate and exchange of ideas. This again feels like a concern to be mindful of, especially if someone less experienced is bringing code to you where they've used an agent as their pair buddy. The overall impression Now I'm at the end of the process, and using the result of this experiment to write this post 4 , I feel better informed about what these tools offer, and the pitfalls I need to be mindful of. Sometimes it wasn't a terrible way of working. For example, on the first day I started with this, at one point on a chilly but sunny Sunday afternoon, I was sat on the sofa, MacBook on lap, guiding an AI to write code, while petting the cat, watching the birds in the garden enjoy the content of the feeder, all while chatting with my partner. That's not a terrible way to write code. On the other hand, as I said earlier, I missed the flow state. I love getting lost in code for a few hours and this is not that. I also found the constant loop of prompt, wait, review, test, repeat, really quite exhausting. As best as I can describe it: it feels like the fast food of software development. It gets the job done, it gets it done fast, but it's really not fulfilling. At the end of the process I have a really useful tool, 100% \"built with AI\", under my guidance, which lets me actually be creative and build things I do create by hand. That's not a bad thing, I can see why this is appealing to people. On the other hand the process of building that tool was pretty boring and, for want of a better word... soulless. Conclusion As I write this I have about 24 hours of access to GitHub Copilot Pro left. It seems this experiment used up my preview time and triggered a \"looks like you're having fun, now you need to decide if you want to buy it\" response. That's fair. So now I'm left trying to decide if I want to pay to keep it going. At the level I've been using it at for building BlogMore it looks like it costs $10/mth. That actually isn't terrible. I spend more than that on other hobbies and other forms of entertainment. So, if I can work within the bounds of that tier, it's affordable and probably worth it. What I'm not sure about yet is if I want to. It's been educational, I can 100% see how and where I'd use this for work (and would of course expect an employer to foot the bill for it or a similar tool), and I can also see how and where I might use it to quickly build a personal-use tool to enable something more human-creative. Ultimately though I think I'm a little better informed thanks to this process, and better aware of some of the wins people claim, and also better informed so that I can be rightly incredulous when faced with some of the wilder claims. Also, it'll help put some of my reading into perspective. Amusingly I uncovered another bug while writing this post.&#160; &#8617; I keep saying Copilot, but I think it's probably more correct to say \"Claude Sonnet 4.5\" as that's what seemed to be at play under the hood, if I'm understanding things correctly.&#160; &#8617; Yes, of course that's an anthropomorphism, you'll find plenty of them in this article as it's hard not to write about the subject in any other way; it's an easy shortcut to explain some ideas&#160; &#8617; Actually I'm writing this post as I always do: in Emacs. But BlogMore is in the background serving a local copy of my blog so I can check it in the browser, and rebuilding it every time I save a change.&#160; &#8617;"},{"title":"A new engine","url":"/2026/02/19/a-new-engine.html","date":"2026-02-19","content":"For about 2 and a half years now this blog has been built with Pelican . For the most part I've enjoyed using it, it's been easy enough to work with, although not exciting to work with (which I think is a positive thing to say about a static site generator). There were, however, a couple or so things I didn't like about the layout I was getting out of it. One issue was the archive, which was a pretty boring list of titles of all the posts on the site. It would have been nice to have them broken down by date or something, at least. Of course, there are lots of themes, and it also uses templates, so I could probably have tweaked it \"just so\"; but every time I started to look into it I found myself wanting to \"fix\" the issue by building my own engine from scratch. Thankfully, every time that happened, I'd come to my senses and go off and work on some other fun personal project. Until earlier this week, that was. The thing is... I've been looking for a project where I could dive into the world of \"AI coding\" and \"Agents\" and all that nonsense. Not because I want to abandon the absolute thrill and joy I still get from writing actual code as a human, but because I want to understand things from the point of view of people who champion these tools. The only way I'm going to have an informed opinion is to get informed; the only way to get informed is to try this stuff out. So, here I am, with my blog now migrated over to BlogMore ; a project that gives me a blog-focused static site generator that I 100% drove the development of, but for which I wrote almost none of the code. At the moment it's working out well, as a generator. I'm happy with how it works, I'm happy with what it generates. I also think it's 100% backwards-compatible when it comes to URLs and feeds and so on. If you do see anything odd happening, if you do see anything that looks broken, I'd love to hear about it . As for this being a \"100% AI\" project, and how I found that process and how I feel about the implications and the results... that's a blog post to come. I took lots of notes."},{"title":"OldNews - A terminal-based client for TheOldReader","url":"/2026/02/11/oldnews.html","date":"2026-02-11","content":"I honestly can't remember when I was first introduced to the idea of RSS/Atom feeds, and the idea of having an aggregator or reader of some description to keep up with updates on your favourite sites. It's got to be over 25 years ago now. I can't remember what I used either, but I remember using one or two readers that ran locally, right up until I met Google Reader . Once I discovered that I was settled. As time moved on and I moved from platform to platform, and wandered into the smartphone era, I stuck with Google Reader (and the odd client for it here and there). It was a natural and sensible approach to consuming news and updates. It also mostly felt like a solved problem and so felt nice and stable. So, of course, I was annoyed when Google killed it off, like so many useful things . When this happened I dabbled with a couple of alternatives and, at some point, finally settled on TheOldReader . Since then it's been my \"server\" for feed subscriptions with me using desktop and mobile clients to work against it. But... I never found anything that worked for me that ran in the terminal. Given I've got a thing for writing terminal-based tools it made sense I should have a go, and so OldNews became my winter break project. I've written it as a client application for the API of TheOldReader , and only for that, and have developed it in a way that works well for me. All the functionality I want and need is in there: Add subscriptions Rename subscriptions Remove subscriptions Add folders Rename folders Remove folders Move subscriptions between folders Mark read/unread Read articles (that provide actual content in their feeds) Currently there's no support for starring feeds or interacting with the whole \"friend\" system (honestly: while I see mention of it in the API, I know nothing of that side of things and really don't care about it). As time goes on I might work on that. As with all of my other terminal-based applications, there's a rich command palette that shows you what you can do, and also what keyboard shortcuts will run those commands. While I do still need to work on some documentation for the application (although you'd hope that anyone looking for an RSS reader at this point would mostly be able to find their way around) the palette is a good place to go looking for things you can do. Plus there's a help screen too. If themes are your thing, there's themes: That's a small selection, and there's more to explore. Also on the cosmetic front there's a simple compact mode, which toggles between two ways of showing the navigation menu, the article lists and the panel headers. OldNews has been a daily-driver for a wee while now, while also under active development. I think I've covered all the main functions I want and have also shaken out plenty of bugs, so today's the day to call it v1.0.0 and go from there. If you're a user of TheOldReader and fancy interacting with it from the terminal too then it's out there to try out. It's licensed GPL-3.0 and available via GitHub and also via PyPI . If you have an environment that has pipx installed you should be able to get up and running with: $ pipx install oldnews It can also be installed using uv : uv tool install oldnews If you don't have uv installed you can use uvx.sh to perform the installation. For GNU/Linux or macOS or similar: curl -LsSf uvx.sh/oldnews/install.sh | sh or on Windows: powershell -ExecutionPolicy ByPass -c &quot;irm https://uvx.sh/oldnews/install.ps1 | iex&quot; Once installed, run the oldnews command. Hopefully this is useful to someone else; meanwhile I'll be using it more and more. If you need help, or have any ideas, please feel free to raise an issue or start a discussion ."},{"title":"Solidarity, Empathy, and Patience -- thinking about code reviews","url":"/2026/02/04/solidarity-empathy-patience.html","date":"2026-02-04","content":"So I saw this video... Death Stranding, along with its sequel, is my absolute favourite video game ever, and probably one of my favourite pieces of fiction ever too; I've watched and read a lot about the game (not to mention I've played both releases a ton too ). A good few months back I was watching a video about the making of the first game and during the video, around the 27:20 mark , the narrator says the phrase: the game's core values of solidarity, empathy, and patience This stood out to me. There was something about that phrase and what it meant given my experiences in Death Stranding and Death Stranding 2; it spoke to me enough that I jotted it down and kept coming back to it and thinking about it. It was a phrase I couldn't get out of my head. Around the same time I was also doing a lot of thinking about, and note-writing about, code reviews. Although I've been working in software development 1 for a few decades now (I started in July 1989), I was quite late to the whole process of code review -- at least in the way we talk about it today. This mostly comes down to the fact that for a lot of my time I either worked in very small companies or I was the only developer around. Given this, thinking about my own approach to reviews is something I've only really been doing for the past few years. I've made personal notes about it, read posts and articles about it, I've had conversations about it; my thoughts and feelings about it have drifted a little but seem to have settled. The idea of that phrase from the Death Stranding video crept into this thought process, as I felt it nicely summed up what a good code review would look and feel like. Weirdly I also realised that, perhaps, the things I like and value about Death Stranding are also the things I like, value, and want to embody when it comes to code reviews. One of the big selling points for me, with Death Stranding, is the asynchronous multiplayer aspect of it; the reason Kojima calls it a \"Strand type game\". I have my game, I have my goal, but other people can indirectly affect it, either doing work in their game that leaks into mine in a beneficial way, or by leaking into mine in a way that I have to clean up. There's something really satisfying about this asynchronous collaboration. That feels similar to the collective effort of working in a single repository, each person working on their own branch or PR, sometimes in tandem, sometimes in series, sometimes to the benefit of each other and sometimes in ways that block each other. But that's not the point here. There's a similarity if I think about it, but I don't want to get too carried away on that line of thought. It's the phrase from the video I care about; it's the approach of involving solidarity, empathy and patience I want to think about more. Solidarity This, for me, is all about where you position yourself when you approach reviewing code. I sense things only work well if you view the codebase as something with common ownership. I've worked on and with a codebase where the original author invited others in to collaborate, but where they constantly acted as a gatekeeper, and often as a gatekeeper who was resistant to their own contributions being reviewed, and it was an exhausting experience. I believe the key here is to work against a \"your code\" vs \"my standard\" approach, instead concentrating on an \"our repository\" view. That's not to say that there shouldn't be standards and that they shouldn't be maintained -- there should be and they should be -- but more to say that they should be agreed upon, mutually understood to be worthwhile, and that any callout of a standard not being applied is seen as a good and helpful thing. The driving force here should be the shared intent, and how the different degrees of knowledge and experience can come together to express that intent. If a reviewer can see issues with a submission, with a proposed change or addition to the codebase, the ideal approach is to highlight them in such a way as to make it feel like we discovered them, not that I discovered them and you should sort it out. Depending on the degree of proposed change, this might actually be expressed by (if you're using GitHub, for example) using the \"Suggested Change\" feature to directly feed back into the PR, or perhaps for something a little more complex, or the offer to pair up to work on the solution. Empathy As someone who has written a lot of code, and so written a lot of bugs and made a lot of bad design choices, I feel empathy is the easiest of the three words to get behind and understand, but possibly the hardest one to actually put into practice. When you look at a PR, it's easy to see code, to see those design choices, and to approach the reading as if you were the one who had written it, assessing it through that lens. In my own experience, this is where I find myself writing and re-writing my comments during a review. As much as possible I try and ask the author why they've taken a particular approach. It could be, perhaps, that I've simply missed a different perspective they have. If that's the case I'll learn something about the code (and about them); if that isn't the case I've invited them to have a second read of their contribution. It seems to me that this benefits everyone. I feel that where I land with this is the idea of striving to act less like a critic and more like a collaborator, and in doing so aiming to add to an atmosphere of psychological safety. Nobody should feel like there's a penalty to getting something \"wrong\" in a contribution; they should ideally feel like they've learnt a new \"gotcha\" to be mindful of in the future (both as an author and a reviewer). Done right the whole team, and the work, benefits. Patience The patience aspect of this view of reviews, for me, covers a few things. There's the patience that should be applied when reading over the code; there's the patience that should be applied when walking someone through feedback and suggestions; and there's the patience needed by the whole team to not treat code reviews as a speed bump on the road to getting work over the line. While patience applies to other facets of a review too, I think these are the most important parts. In a work environment I think it's the last point -- that of the team's collective patience -- that is the most difficult to embody and protect. Often we'll find ourselves in a wider environment that employs a myopic view of progress and getting things done , where the burn-down chart for the sprint is all that matters. In that sort of environment a code review can often be seen, by some, as a frustrating hurdle to moving that little card across that board. Cards over quality. Cards over sustainability. It's my belief that this is one of those times where the phrase \"slow down to speed up\" really does apply. For me, review time is where the team gets to grow, to own the project, to own the code, to really apply the development and engineering principles they want to embody. Time spent on a review now will, in my experience, collectively save a lot more time later on, as the team becomes more cohesive and increasingly employs a shared intuition for what's right for the project. This is not (entirely) a post about code reviews The thing with code reviews, or any other team activities, is they don't exist in a vacuum. They take on the taste and smell of the culture in which they operate. It's my experience that it doesn't matter how much solidarity, empathy or patience you display during your day-to-day, if it's counter to the culture in which you work it's always going to be exhausting, it's always going to feel like a slog. If leadership in technology, in software engineering, were to show more of these three basic qualities, they'd start to appear like they realise that they're working with actual humans, not producers of code; and I think we need more of that now than at any time in the history of coding. Since I first saw that video, and heard that phrase, and had it run around my head, I've come to feel that it's not just a good mantra for code reviews; I think it's a simple blueprint for what good tech leadership should look like. If there was more \"Strand-type\" leadership in my chosen industry I feel it would be more open, more accessible, would offer more psychological safety and ultimately would result in teams, and projects, that thrive. Or software engineering, if you prefer, but that's a whole other blog post I'll never get round to writing one day.&#160; &#8617;"},{"title":"TIL - uvx.sh","url":"/2026/01/27/til-uvx-sh.html","date":"2026-01-27","content":"In the past few months, like a lot of folk in the Python world, I've been won over by uv . When it comes to managing my own projects my journey over the past few years as been pipenv , then rye , and then when rye was killed off I finally swapped to uv (later than I should have, I realised in hindsight). At each step I've found each tool cleaner, easier to work with and more feature-rich. There's no doubt in my mind that uv has done the most work to make installing Python-based tools (or at least PyPI-based tools) as friction-free an experience as possible . Now I've discovered uvx.sh . The thing with uv is the person installing your application first needs to get and install uv ; this site removes that friction. Now if someone wants to install obs2nlm (for example) they should be able to just do: curl -LsSf uvx.sh/obs2nlm/install.sh | sh and away they go (assuming they have curl installed, which is generally going to be far more likely than having uv installed). Of course, there are the usual caveats and concerns about the \"just pipe this stuff via sh trust me bro\" approach, but if you are comfortable with suggesting this kind of install method it looks worth adding this to an application's installation documentation. I think I'm going to start mentioning it as an option."},{"title":"ng2nlm - Feed NotebookLM a Norton Guide","url":"/2026/01/13/ng2nlm.html","date":"2026-01-13","content":"After having knocked up obs2nlm the other day I realised there was another source of sources available to me that might be fun to throw into NotebookLM: one or more of the Norton Guide files in my collection ! And so, after a wee bit of hacking on a wet Sunday afternoon, ng2nlm was born. In terms of what it does, it's pretty much the same as obs2nlm , only it uses ngdb to read the contents of a Norton Guide and turn it into a single Markdown file which can then be used as a source in NotebookLM. So far it seems to be working a treat. Here I grabbed the guide to assembly language Norton Guide, and the DOS interrupts Norton Guide, turned them into sources, created a notebook and let it do its thing. I can't vouch for how valid the answer to my question is -- it's a long time since I wrote any 8086 assembler code and it's a moment since I last had to dig into DOS interrupts and the like -- but I like the result. Probably the biggest issue I see at the moment is with the code examples: it seems to have a habit of adding some sort of citation marker that links to nowhere when it's emitting code. I think this is down to the instructions I've given it in the source I output, at least that's what it's suggesting when I ask it: Me: What are all the numbers in square brackets for? NotebookLM: The numbers in square brackets are passage indices used to cite which specific part of the sources supports each statement [Instruction]. Within the source files themselves, these markers identify distinct entries or sections within the Norton Guide databases. Given I am trying to encourage it to cite its sources, I think this is where the confusion comes from. In \"normal\" paragraphs it does do a good job of citing its source and linking to it : so presumably, when it \"thinks\" it's outputting code it doesn't do the markup to actually do the linking, and so things end up looking a little confused. If I ask that citations aren't included in the code, this does seem to have the desired effect: So, given this, perhaps I can use the --additional-instructions switch for the particular source to encourage it to not add citation links to code? Or of course I could tweak ng2nlm itself to include that instruction to start with. While it's a little specific to one use case, Norton Guide files do tend to be coding-related so it could make sense. Anyway, in the very unlikely event that you have a need to turn one or more Norton Guide files into sources to throw at NotebookLM or similar tools: ng2nlm exists."},{"title":"obs2nlm - Feed NotebookLM an Obsidian Vault","url":"/2026/01/10/obs2nlm.html","date":"2026-01-10","content":"I'm sure I've mentioned a couple of times before that I've become quite the fan of Obsidian . For the past few years, at any given point, I've had a couple of vaults on the go. Generally I find such vaults a really useful place to record things I'd otherwise forget, and of course as a place to go back and look things up. But... even then, it's easy enough to forget what you might have recorded and know that you can even go back and look things up. Also I tend to find that I can't quite figure out a good way of getting a good overview of what I've recorded, over time. Meanwhile: I've been playing around with Google's NotebookLM as a tool to help research and understand various topics. After doing this with my recent winter break coding project (more on that in the future) I realised I really should get serious about taking this approach with my Obsidian Vaults. I'm sure this is far from novel, I'm sure lots of people have done similar things already; in fact I'd quickly dabbled with the idea a few months ago , had a bit of a laugh at some of the things the \"studio\" made of a vault, and promptly forgot about it. This time though I got to thinking that I should try and take it a little more seriously. And so obs2nlm was born. The idea is simple enough: enumerate all the Markdown files in the vault, wrap them in boundary markers, add some instructions to the start of the file to help NotebookLM \"comprehend\" the content better, throw in a table of contents to give clues to the structure of the vault, and see what happens when you use the resulting file as a source. So far it's actually turning out to be really helpful. I've been using it to get summaries regarding my work over the past 18 months or so and it's helped me to consolidate my thoughts on all sorts of issues and subjects. It's not perfect, however. I've had it \"hallucinate\" some stuff when making things in the studio (most notably in the slide deck facility); for me though I find this an acceptable use of an LLM. I know the subject it's talking to me about and I know when it's making stuff up. This, in turn, makes for a useful lesson in how and when to not trust the output of a tool like this. Having tested it out with a currently-active vault, I'm now interested to find out what it'll make of some of the archived vaults I have. Back in 2024 I wrote a couple or so tools for making vaults from other things and so I have a vault of a journal I kept in Journey for a number of years, a vault of a journal I'd kept before then in Evernote , and I also have a vault of all the tweets I wrote before I abandoned Twitter. I also have a vault that was dedicated to recording the daily events and thoughts of my time working at Textualize . It's going to be fun seeing what NotebookLM makes of each of those; especially the last one. Anyway, if Obsidian is your thing, and if you are dabbling with or fancy dabbling with NotebookLM, perhaps obs2nlm will be handy for you."},{"title":"A Norton Guide collection","url":"/2025/12/12/norton-guide-collection.html","date":"2025-12-12","content":"As I've mentioned a few times on this blog , I've long had a bit of a thing for writing tools for reading the content of Norton Guide files . I first used Norton Guides back in the early 1990s thanks to the release of Clipper 5, and later on in that decade I wrote my first couple of tools to turn guides into HTML (and also wrote a Windows-based reader, then rewrote it, wrote one for OS/2, wrote one for GNU/Linux, and so on). One tool ( ng2html ) got used by a few sites on the 'net to publish all sorts of guides, but it's not something I ever got into doing myself. Amusingly, from time to time, because I had a credit on those sites as the author of the conversion tool, I'd get random emails from people hoping I could help them with the topic of whatever guide they'd been reading. Sometimes I could help, often not. From what I've recently been told two of the biggest sites for this sort of thing (they might even have been the same site, or one a copy of the other, I didn't really dive into them too much and wasn't sure who was behind them anyway) have long since gone offline. This means that, as far as I can tell, a huge collection of knowledge from the DOS days is a lot harder to get to, if it hasn't disappeared altogether. This makes me kind of sad. Edit to add: digging a little, one of the sites was called www.clipx.net and it looks to have long-since gone offline. It is on archive.org though . The other was x-hacker.org which, digging a wee bit more, seems to have been a copy of what was on clipx.net. So I had an idea: having recently polished up my replacement for ng2html , why not use that to build my own site that publishes the guides I have? So I set about it. There's one wrinkle to this though. While the other sites seemed to just publish every NG file they got their hands on, I'd prefer to try and do it like this: publish every guide I have in my collection that I have a licence or permission to publish ; or as near as possible 1 Given all of this, norton-guides.davep.dev has been born. The repository that drives it is on GitHub , and I have a wiki page that lists all the guides I have that I could possibly publish, showing what I know about the copyright/licence of each one and what the publishing state is. So with this, I'm putting out a call for help: if you remember the days of Norton Guide help files, if you have Norton Guide help files I don't have, and especially if you are the copyright-holder of any of these files and you can extend me the permission to open them up, or if you know the right people and can get me in touch with them, DROP ME A LINE ! I'd also love to have others join me in this... quest. So if you want to contribute to the repository and help build it up I'd also love to hear from you. I will possibly be a little permissive when it comes to things that I believe contain public domain information to start with.&#160; &#8617;"},{"title":"DHV","url":"/2025/07/19/dhv.html","date":"2025-07-19","content":"Back in the very early days of my involvement with Textualize , while looking for fun things to build to test out the framework and find problems with it, I created textual-astview . The idea was pretty simple: exercise Textual's Tree widget by using it to display the output of Python's abstract syntax tree module . While the code still works, Textual has moved on a lot, as has my approach to building applications with Textual, and so I've been wanting to do a ground-up rewrite of it. At the same time I was also thinking that it might be interesting to build a tool that provides other ways of understanding how your Python source gets turned into runnable code; with this in mind I've ended up building a terminal-based application called DHV. The idea is pretty straightforward: you type in, paste in, or load up, Python code, and you get a real-time display of what the resulting bytecode and abstract syntax tree would be. If you've ever wondered what a particular bit of code looks like under the hood, or wondered if one particular approach to a problem is \"more efficient\" 1 than another, or just wondered to yourself if 1+1 ends up being a complex operation or simply gets turned into 2 , this tool might be useful to experiment and see. As of now DHV only works with Python 3.13. The main reason for this is that the Python dis module is a bit of a moving target and has had some noticeable interface changes over the past few versions. When I find some time I might work on making DHV a little more backward-compatible. But for now keep this in mind: when you're looking at the results for some code you're looking at what Python 3.13 (or later) would do, earlier Pythons may differ. DHV is licensed GPL-3.0 and available via GitHub and also via PyPI . If you have an environment that has pipx installed you should be able to get up and going with: pipx install dhv If you're a fan of uv and friends you can install it like this: uv tool install --python 3.13 dhv I'm sure many of us have worked with that person who claims \"this is more efficient\" without providing any evidence; this might just be the tool to let you check that assertion.&#160; &#8617;"},{"title":"Complexitty","url":"/2025/04/20/complexitty.html","date":"2025-04-20","content":"Much like Norton Guide readers or the 5x5 puzzle , code that has fun with the Mandelbrot set is another one of my goto exercises. I've written versions in many languages, and messed with plots in some different environments, as varied as in VR on the web to wearable items . Back in the early days of my involvement with Textualize I wrote a deliberately worst-approach version using that framework. The whole thing was about taking a really silly approach while also stress-testing Textual itself. It did the job. Later on I did a second version that targets Textual . This time it did a better job and was the catalyst for building textual-canvas . This version was intended more to be a widget that happened to come with an example application, and while it was far more better than the on-purpose-terrible version mentioned above, I still wasn't 100% happy with the way it worked. Recently I did some maintenance work on textual-canvas , cleaning up the repository and bringing it in line with how I like to maintain my Python projects these days, and this prompted me to look back at textual-mandelbrot and rework it too. Quickly I realised it wasn't really sensible to rewrite it in a way that it would be backward compatible (not that I think anyone has ever used the widget) and instead I decided to kick off a fresh stand-alone application. Complexitty is the result. Right now the application has all the same features as the mandelexp application that came with textual-mandelbrot , plus a couple more. Also it's built on top of the common core library I've been putting together for all my own terminal-based Python applications. As time goes on I'll add more features . As with most of my recent TUI-based projects, the application is built with comprehensive help for commands and key bindings. and there's also a command palette that helps you discover (and run) commands and their keyboard bindings. Complexitty is licensed GPL-3.0 and available via GitHub and also via PyPI . If you have an environment that has pipx installed you should be able to get up and going with: pipx install complexitty It can also be installed with Homebrew by tapping davep/homebrew and then installing complexitty : brew tap davep/homebrew brew install complexitty"},{"title":"ng2web v1.0.0","url":"/2025/03/24/ng2web.html","date":"2025-03-24","content":"It pretty much all started with this: * Revision 1.1 1996/02/15 18:57:13 davep * Initial revision That's from the rcs log for the source for w3ng , a tool I wrote so I could read Norton Guide files in my web browser, served by Apache, running on my GNU/Linux server in my office. The tool itself was written as a CGI tool (remember them?). I believe I posted about this to comp.lang.clipper and pretty quickly some folk asked if it might be possible to do a version that would write the whole guide as a collection of HTML files for static hosting, rather than serving them from a cgi-bin utility. That seemed like a sensible idea and so: * Revision 1.1 1996/03/16 09:49:00 davep * Initial revision ng2html was born. Fast forward around a quarter of a century and I decided it would be fun to write a library for Python that reads Norton Guide files , and a tool called ng2web was the first test I wrote of it, designed as a more flexible replacement for ng2html . I've tweaked and tinkered with the tool since I first created it, but never actually \"finished\" it. That's changed today. I've just released v1.0.0 of ng2web . If turning one or more Norton Guide files into static websites seems like the sort of thing you want to be doing, take a look at the documentation . ng2web is licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install ng2web It can also be installed with Homebrew by tapping davep/homebrew and then installing ng2web : $ brew tap davep/homebrew $ brew install ng2web"},{"title":"AgiNG v0.3.0","url":"/2025/03/22/aging-0-3-0.html","date":"2025-03-22","content":"I've just released AgiNG v0.3.0 . The main focus of this release was to get some searching added to the application. Similar to what I added to WEG back in the day, I wanted three types of searching: Current entry search. Current guide-wide search. All registered guides-wide search. The current entry search is done with a simple modal input, and for now the searching is always case-insensitive (I was going to add a switch for this but it sort of felt unnecessary and I liked how clean the input is). The search is started by pressing / , and if a hit is found n will take you through all subsequent matches. As always, if you're not sure of the keys, you'll find them in the help screen or via the command palette: Guide-wide and all-guide searching is done in the same dialog. To search guide-wide you enter what you want to find and untick \"All Guides\" . With that, the search will stick to the current guide. As will be obvious, searching all guides that have been registered with AgiNG is as simple as ticking \"All Guides\" . Then when you search it'll take a walk through every entry of every guide you've added to the guide directory in the application. Global searching is accessed with Ctrl + / or via the command palette. With this added, I think that's most of the major functionality I wanted for AgiNG. I imagine there's a few more tweaks I'll think of (for example: I think adding regex search to the global search screen could be handy), but I don't think there's any more big features it needs. AgiNG can be installed with pip or (ideally) pipx from PyPi . It can also be installed with Homebrew by tapping davep/homebrew and then installing aging : $ brew tap davep/homebrew $ brew install aging The source is available on GitHub ."},{"title":"AgiNG","url":"/2025/03/12/aging.html","date":"2025-03-12","content":"It seems I really do still have this need to create new terminal-based projects at the moment. There's been Braindrop , then Peplum , then after that came Hike . While I'm still tweaking and adding to them, and also using them to refine a wee library I'm building up that forms the core of my latest apps , I felt I still had this one app that I needed to finally build. Since the 1990s I've had this mild obsession with building tools for maintaining access to Norton Guide files . I've written readers for GNU/Linux (which also works on macOS too) , OS/2 , Windows , GNU Emacs , and also or the web (in multiple incarnations). Those builds have covered a few languages, including C, C++, Pascal, JavaScript and Emacs Lisp. I'd never written a Python library or application for it though. So when I first saw Textual mentioned in passing on Twitter a few years back, way back in the 0.1 days, I thought that could be the thing that would push me over the edge. In anticipation of that, back in 2021, I initially developed ngdb.py . This is a library that provides the core Norton Guide reading code for Python applications and could form the basis for other tools. As a test for this I then wrote ng2web (which works, but I think still needs a bit of tidying up -- something I'm aiming to do in the next few weeks). Meanwhile, the journey with Textual itself kicked off , happened, and came to an end ; and yet somehow I'd never got round to building the thing I'd initially looked at Textual for: a terminal-based Norton Guide reader that looked nice and modern (by terminal standards). When I initially joined Textualize the owner had actually said they wanted me to build this as test of the framework, to essentially start out by employing me to create some Free Software that would help dogfood the library, but that seemed to get forgotten. Fast forward to the start of this month and I finally felt it was time to tackle this. The result is AgiNG 1 . As of v0.1.0 it has most of the features you'd expect from a usable Norton Guide reader, including: An ability to add guide files to an in-application directory. The ability open and navigate a guide. Full see-also support, etc. Full translation of characters as were under MS-DOS into the terminal. The ability to copy entry text or source to the clipboard. The ability to copy save entry text or source to a file. Access to a guide's credits. I still need to write some proper documentation for the application, but meanwhile all commands and key shortcuts can be discovered either via the help screen: or by pulling up the command palette: Hopefully the workings of the application will be fairly obvious to anyone who is familiar with Norton Guide files; if anything isn't making sense I'm more than happy to answer questions or take suggestions for improvements . One wee feature I want to call out, that I felt was important to add, was a \"classic view\" facility. The thing with Norton Guide files is they were mostly created in the very late 1980s and early-to-mid 1990s. People would often get creative with the colouring within them, but in many cases the colouring assumed the default Norton Guide application. Its colours were white text on a blue background. So sometimes other colouring was done assuming that background. You can see an example of this here, with an entry in a guide being viewed using the default textual-dark theme: Notice the colouring in the syntax section. This is more obvious if the application is switched to one of the light themes: With a nod to this issue in mind, I added the \"classic view\" for entries (which is a sticky setting -- turn it on and it stays on until you turn it off): A little hard on the eyes, I think, but also filled with nostalgia! Talking of themes, all the usual application themes are available, here's a wee selection: AgiNG is licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install aging It can also be installed with Homebrew by tapping davep/homebrew and then installing aging : $ brew tap davep/homebrew $ brew install aging Expect to see more updates in the near future; as with other recent projects this is very much something I'm going to be dabbling with and improving as time goes on. If you're wondering about the name, it's nothing more than a word that happens to have NG in it, and also a mild pun about this being an ageing hypertext help system; with the spelling acknowledging Peter Norton's nationality.&#160; &#8617;"},{"title":"MkDocs/mkdocstrings 404 CSS TIL update","url":"/2025/02/28/mkdocs-gh-pages-redux.html","date":"2025-02-28","content":"Following on from my post this morning , regarding the problem I was having with _mkdocstrings.css being 404 any time I deployed by documentation, build with mkdocs / mkdocstrings , to GitHub Pages... It's come to light that I was doing this on hard mode, pretty much. While trying to figure out the best way of deploying the docs, I'd stumbled on ghp-import and had been using that. On the other hand, MkDocs has it's own command for doing the same thing: mkdocs gh-deploy . Timothe pointed out to me that he never runs into this problem, but he used this command. As it turns out, if you use mkdocs gh-deploy it creates the .nojekyll file by default. And how does it do this? It uses the ghp-import code and uses a switch it has to achieve exactly this . In fact... the command line version even has a switch for it! -n, --no-jekyll Include a .nojekyll file in the branch. This is off by default, when you run the command itself, but I wish I'd noticed this when I was first experimenting. O_o Anyway, thanks to Timothe's pointers, I've now managed to simplify how I build and publish the docs from textual-fspicker , and I'll apply this to other projects too."},{"title":"Documenting textual-fspicker (plus a TIL)","url":"/2025/02/28/documenting-fspicker.html","date":"2025-02-28","content":"I've just made a wee update to textual-fspicker , my dialog library for Textual which adds FileOpen , FileSave and SelectDirectory dialogs. There's no substantial change to the workings of the library itself, but I have added something it's been lacking for a long time: documentation! Well... that's not quite true, it's always had documentation. I'm an avid writer of Python docstrings and I make a point of always writing them for every class, function, method or global value as I write the code. As such the low-level \"API\" documentation has always been sat there ready to be published somehow, eventually. Meanwhile the description for how to use the library was mostly a pointer to some example code inside the README. Not ideal, and something I really wanted to improve at some point. Given I'm still on a bit of a coding spree in my spare time, I finally decided to get round to using the amazing mkdocstrings , in conjunction with mkdocs , to get some better documentation up an running . The approach I decided to take with the documentation was to have a page that gave some general information on how to use the library and then also generate low-level documentation for the all the useful content of the library from the docstrings . While latter isn't really useful to anyone wanting to use the library in their own applications, it could be useful to anyone wanting to understand how it hangs together at a lower-level, perhaps because they want to contribute to or extend the library in some way. While writing some of the general guide took a bit of work, of course, the work to get the documentation up and running and generating was simple enough. The effort comes down to 3 rules in the Makefile for the project: ############################################################################## # Documentation. .PHONY : docs docs : # Generate the system documentation $( mkdocs ) build .PHONY : rtfm rtfm : # Locally read the library documentation $( mkdocs ) serve .PHONY : publishdocs publishdocs : docs # Set up the docs for publishing $( run ) ghp-import --push site The rtfm target is useful for locally-serving the documentation so I can live preview as I write things and update the code. The publishdocs target is used to create and push a gh-pages branch for the repository, resulting in the documentation being hosted by GitHub. A wee problem NOTE: I've since found out there's an easier way of fixing the issue . This is, however, where I ran into a wee problem. I noticed that the locally-hosted version of the documentation looked great, but the version hosted on GitHub Pages was... not so great. I was seeing a load of text alignment issues, and also whole bits of text just not appearing at all. Here's an example of what I was seeing locally: and here's what I was seeing being served up from GitHub Pages: As you can see, in the \"bad\" version the func label is missing from the header, and the Parameters and Returns tables look quite messy. I spent a little bit of time digging and, looking in Safari's console, I then noticed that I was getting a 404 on a file called _mkdocstrings.css in the assets folder. Problem found! Only... was it though? If I looked in the gh-pages local branch the file was there (and with fine permissions). If I looked in the remote branch, it was there too. Thinking it could be some odd browser problem I even tried to grab the file back from the command line and it came back 404 as well. At this point it was getting kind of late so I decided I must have screwed up somehow but I should leave it for the evening and head to bed. Before doing so though I decided to drop a question into the mkdocstrings discussions to see if anyone could see where I'd messed up . As it turns out, it looked like I hadn't messed up and the reply from the always super-helpful Timothe was, in effect, \"yeah, that should work fine\" . At least I wasn't the only one confused. Fast forward to this morning and, with breakfast and coffee inside me, I decided to try and methodically get to the bottom of it. I wrote up the current state of understanding and looked at what might be the common cause. The thing that stood out to me was that this was a file that started with an underscore, so I did a quick search for \"github pages underscore\" and right away landed on this result . Bingo! That had to be it! A little bit of testing later and sure enough, the documentation hosted on GitHub Pages looked exactly like the locally-hosted version. So, TIL: by default sites hosted by GitHub Pages will pretend that any asset that starts with an underscore doesn't exist, unless you have a .nojekyll in the root of the repository, on the gh-pages branch (or whatever branch you decide to serve from). To make this all work I added .nojekyll to docs/source and added this to mkdocs.yml : exclude_docs : | !.nojekyll All done! And now I've worked out a simple workflow for using mkdocs / mkdocstrings for my own Python projects, in conjunction with GitHub Pages, I guess I'll start to sprinkle it over other projects too."},{"title":"Hike","url":"/2025/02/14/hike.html","date":"2025-02-14","content":"The run of writing new terminal-based tools that I want still keeps going. First there was Braindrop , then there was Peplum , and now, released today, there's Hike . Hike is yet another terminal-based Markdown browser. While it's far from the first, and unlikely to be the last, it's mine and it looks and works exactly how I need. Perhaps it'll be your sort of thing too? This initial release has a bunch of handy features, including things like: A command line where file names, URLs and commands can be entered. A persistent history for the command line. A local file browser. A simple bookmarking system. A browsing history. Commands for quickly loading and viewing files held on GitHub, GitLab, Codeberg and Bitbucket. As there's a lot to discover in the application, I've tried to make the help screen as comprehensive as possible: and there's also the command palette to help with discovering commands and the keys that are associated with them: Once again, themes are supported so no matter your taste you should find something that's easy on your eyes: Hike is licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install hike It can also be installed with Homebrew by tapping davep/homebrew and then installing hike : $ brew tap davep/homebrew $ brew install hike Expect to see more updates in the near future; this is very much an ongoing tinker project."},{"title":"Peplum","url":"/2025/01/25/peplum.html","date":"2025-01-25","content":"I seem to be back in the swing of writing handy (for me) little terminal-based applications again. Having not long since released Braindrop (which I'm still working on and tinkering with; it'll get more features in the near future, for sure), I had an idea for another tool I'd like to have: something for looking through, searching, and filtering Python PEPs . As with anyone who is interested in what's happening with Python itself, I subscribe to the RSS feed of the latest Python PEPs, but I also wanted something that would let me look back at older ones in a way that worked \"just so\" ( \"just so\" being \"what feels right for me\" , of course). Having finished the main work on Braindrop I realised that the general layout of its UI would work here, as would the filtering and searching approach I used. From this idea Peplum was born! In this first release I've simply concentrated on all things to do with grabbing the list of PEPs and presenting them in a useful way; adding various forms of filtering them; adding the ability to search the metadata; that sort of thing. I aim to keep developing this out over the next few weeks and months, adding things like the ability to make notes, to locally view the text of a PEP, perhaps even to mark PEPs as unread and read, etc. As I mentioned earlier, much of the design was driven by what I did with Braindrop, so once again I've tried my very best to make it keyboard-friendly and as much as possible keyboard-first. This sometimes means having to work against how Textual works, but generally that isn't too tricky to do. I'm once again making heavy use of the command palette and also ensuring that all commands that have corresponding keyboard bindings are documented in the help screen. There's enough common code between Peplum and Braindrop, when it comes to this aspect of building a Textual application, that I'm minded to spin it out into a little library of its own. I'm going to sit on this code for a wee while and see how it develops, but I can see me taking this approach with future applications and doing this will stop the need to copy and paste. It might also be useful to others building with Textual. Also as with Braindrop, themes are a thing, and the theme setting is sticky so you can set it the once and stick with that you like. Here's some examples: That's a small selection of the themes, with more to explore. While working on this project I managed to find a couple more bugs in Textual, including a fun way to get transparent backgrounds to get out of sync and also a way to get an easy crash out of OptionList if it's set to width: auto . What was even more fun was I sort of discovered a bug in the Python PEP API . Thanks to Hugo noticing my \"huh, weird\" post on Fosstodon, there's now an issue for it as well as a PR in the works . In retrospect I should have raised an issue myself; instead I fell into that \"they obviously know what they're doing so it must be like this for a reason\" trap. Lesson relearned: it's always better to ask and get an answer, than to assume a thing is how it is for a reason you don't know; which I guess is a version of Linus' law really. So that's v0.1.0 out in the wild. I'm pleased with how it's turned out and there's more to come. It's licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install peplum It can also be installed with Homebrew by tapping davep/homebrew and then installing peplum : $ brew tap davep/homebrew $ brew install peplum I'm going to be making good use of this and working on it more; I hope it's useful to someone else. :-)"},{"title":"Braindrop","url":"/2025/01/03/braindrop.html","date":"2025-01-03","content":"A touch over a year ago I did the initial work on an application called Tinboard , a terminal-based client for the Pinboard bookmarking service. I had a lot of fun building it and it was an application that I used on a near-daily basis. However, around August last year I realised it was time for me to move on from Pinboard and try something new ; based on various recommendations I settled on Raindrop . As mentioned in the other blog post , Raindrop offered more or less everything I had with Pinboard and so the move was fairly straightforward. The one thing that was missing though was an application similar to Tinboard. So, late on last year, with my winter break approaching, I decided to start from scratch and build a \"Tinboard for Raindrop\" , which I'm calling Braindrop . This was going to be a bit of an adventure too. Since being laid off from Textualize earlier in 2024 I'd not been following its development quite as closely as I used to, and had also run into some issues and bugs with it since that time; moreover, as well as various bugs appearing, some breaking changes had also been made. As such this was going to be a process where I'd wrap my head around what's happened with the framework over the prior six months or so. Given all this, over the past couple of weeks I've been spending a few hours a day doing some for-pleasure coding and v0.1.0 of Braindrop is the result. As much as possible I've tried to keep the look and feel similar to that of Tinboard, while also doing my best to avoid some of the \"ah, I wish I hadn't done it this way\" design decisions I'd made. As of the time of writing I'm very pleased with the result. One thing I did want to do is ensure that the application was as keyboard-friendly as possible, while also still allowing use of the mouse. Textual can sometimes get that wrong and I ran into an example of this while trying to ensure that there's good in-application help. Somewhat recently Textual added a built-in help system which, sadly, can't easily be used by and navigated by someone using the keyboard. So instead I've recreated the help system I built into Tinboard, while adopting the documentation standard that Textual had settled on (which, coincidentally, was kind of similar to what I did in Tinboard to start with). As with Tinboard, I've also made sure to make full use of the command palette, with every action that makes sense having a keyboard hotkey as well as a command in the palette. I also took things a little further and made sure that the hotkeys are shown in the command palette for easier discovery. I've also made sure that Textual's new theme system is available for easy use; so out goes dark/light mode toggling and in comes a collection of different themes. Here's a wee selection as an example: That's a small selection of the themes, with more to explore. There's a few more things I want to do before I consider the application v1.0-ready, but it's already in use by me and working well. As I decide what else I want to add to it I'm building up a list of TODO items . Given that my day job these days is quite varied, isn't quite so coding-intensive, and isn't always related to all things Python, it's actually been fun to sit down and hack up a pure Python application from scratch again. It's also helped me discover a couple or so fresh bugs in Textual (which I've reported , of course) and given me the opportunity to PR some trivial fixes as I've noticed typos and stuff as I go . Anyway; that's v0.1.0 out in the wild. I'm pleased with how it's turned out and there's more to come. It's licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install braindrop It can also be installed with Homebrew by tapping davep/homebrew and then installing braindrop : $ brew tap davep/homebrew $ brew install braindrop I hope this is useful to someone else. :-)"},{"title":"Markdown all the things","url":"/2024/11/04/markdown-all-the-things.html","date":"2024-11-04","content":"Recently I've been on a bit of a \"turn stuff into Markdown files and slap them in an Obsidian Vault\" trip. This kicked off a couple of months back when I made a decision unrelated to coding. On and off, since my teenage years, I've kept journals. Since those teenage years it's been more off than on, but a couple of times in my adult life it's been really helpful to actually write one. The last time this happened was early 2019. It was pretty vital I did that at the time and it was a really sensible and helpful decision, and an approach to the situation I was in that I'd recommend to anyone (and have done on occasion to anyone going through the same thing). The actual motivation for starting that particular journal is long behind me, but I'd got into the habit of writing it and so, until a couple or so months back, I kept jotting something down every day. But I came to the realisation that I didn't need to and that it had become something of a chore. I'd been using an application called Journey . It's a great app, does the job well, but was also suffering from the creep of \"AI\" (I've had a few apps ion my arsenal that don't need it, acquire a useless \"AI\" feature). This privacy-problematic change of direction, combined with the realisation that I didn't need to write about my day, every day, any more, made me decide it was time to stop and cancel the subscription. Thankfully Journey has a pretty comprehensive export option so I used it and didn't think too much more about it for a while. Meanwhile I also had a subscription to Evernote that I didn't really use any more. Within it I had held a handful of years of journal entries from a decade or so ago, along with other \"remember this for some point in the future\" stuff. For the longest time I was on some really cheap tier that didn't exist any more, one that was low enough that I didn't really notice the cost go out each month so I kept putting off exporting things and closing it all down until \"next month\" . Then I got an email from them to say they were forcing me onto some new tier that was more expensive. So that was the final straw there. I made an export of what I had in Evernote and closed that account down too. A wee while went past and then I got to thinking that it might be interesting to try and combine both these sources into one archived journal. I had stuff from around 2010 to 2015, and I also had stuff from 2019 until 2024; the former in the Evernote archive and the latter in the Journey archive. Surely I could write a couple of tools to turn that data into one consolidated Obsidian Vault? Over the course of a couple of weekends journey2md and evernote2md were born. While both of those tools work differently, they're both designed to populate the same Obsidian Vault. Once I was happy with this I did the mass conversion and I was happy with the result. Now I have years of journal entries, all converted to Markdown files and made available for reading via an application that lets me rummage through history using dates and tags and all sorts of other searching. So I was happy with that and didn't give it much more though. Then last week I got to thinking... Twitter has turned into the worst place possible and I can't for the life of me think why any right-thinking person who has an ounce of humanity or has anything approaching a humanistic outlook on life would remain an active user. Honestly I stuck it out longer than was sensible, but in June 2023 I finally quit for good. Back when the new owner was confirmed I, like a lot of people, extracted my archive. It's since been sat in storage doing nothing, yet there's a lot of data in there that could be interesting to work with, or just to go back and look through. So last week's thought was \"why don't I also turn this into an Obsidian Vault?\" . So I did... The tool I built to do this is bird2glass . As you'll see in the README it makes a few assumptions about the state of Twitter archive dumps and also what a user wants from this. Personally I'm pleased with the result. The main aim of the tool is to break the tweets down into a hierarchy of year, month and day... ...and also to connect them with any account that was being replied to or mentioned in some way... This user view is handy when viewing backlinks, as it gives you a list of all the tweets that mention that user (and, of course, if you're into Obsidian's graph it will make for some interesting connections within there). I sense there's more I can do with this, and I imagine I will continue to tinker with it. Meanwhile though, if that sounds like something you'd benefit from do feel free to grab it and play with it and hack on it. Keep in mind the notes and assumptions that are in the README, and really be prepared for a lot of files to be created if you did a lot of tweeting like I did (I do think that over 50,000 individual files for an Obsidian Vault is a bit silly, if I'm honest). Meanwhile... I might need to look at other applications and think about how I can turn the data into useful Markdown collections!"},{"title":"Paindrop v1.0.0","url":"/2024/08/18/paindrop.html","date":"2024-08-18","content":"I was quite late discovering Pinboard; by the looks of things I created my account and paid my first subscription for it in early 2019. Since then I've been a pretty avid user and found it really useful. I've even written a couple of clients for it ( one for Emacs and one for the terminal ). During that time it's had its fair share of hiccups and outages, but on the whole I've found it a stable and useful service. The service does have its detractors, and concerns over its long-term stability and how well it's maintained are fairly common . I half paid attention to these, and had started to think about where I might go if there was an issue. While maintaining and syncing bookmarks isn't exactly a difficult or unsolved problem, and while it's also true that it could be fun to roll my own solution, there are a couple of things I need that would make building my own approach a bit of a chore. Things important to me are: An extension for any random browser I might find myself using A good mobile client for at least iOS and iPadOS A good API so I can write my own tools if I need to A clean and focused backend website I kept these things in mind and kept an eye out but I'd never really felt the need to actively start looking around. Then I stumbled on this after posting about another Pinboard outage . That... yeah, that was the final push I needed to start to think seriously about where to move and how. A couple of people suggested Raindrop , and from what I could tell it was coming up as a pretty popular service that some Pinboard users were migrating to. I had a look and it wasn't quite what I was after; but close. You see, there's two things I really like about Pinboard that Raindop didn't seem to cover: Simple support for \"this shit is unread\". I see things, I share to whatever Pinboard app I have on my phone or tablet, etc, and then I review some time later (normally in Tinboard ). Support for Private and Public pins. I've liked having a feed of bookmarks I can let people see and Raindrop doesn't have this. I looked around at some blogs that talked about Pinboard vs Raindrop and didn't see any that really dived into this particular aspect of migrating; I also asked a couple of folk who'd made the move about this and they didn't really have any insight (mainly because they didn't care about those particular uses). One thing I did notice though was that Raindrop does support making individual collections public. So, if I was willing to sacrifice any other uses for collections (a bookmark in Raindrop can only be in one collection), I could simply have a Public and a Private collection and import pins into the appropriate one. Also, unread pins could be left out of the collections and I could use that to signify unread status. This seemed fine as I'm heavy on the tags anyway. Now... Raindrop has a pretty comprehensive import facility built in. I gave it a try with Pinboard's backup file and it worked really well. That is... really well except it just threw away the public/private/unread aspect of the pins. There was only one thing for it then: I had to write my own importer! Which brings me to Paindrop . It's a quick hack but it does the job, and it does the import just how I wanted. The result of the first test was pretty much spot on (in this image I'm comparing what Raindrop says vs what Tinboard says I have in Pinboard): Usage is pretty straightforward. You create Public and Private collections in Raindrop, you create an app in Raindrop and get the access token, you grab your Pinboard access token and then: $ paindrop example:xxxxxxxxxxxxxxxxxxxx xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx where the first parameter is the Pinboard access token and the second the Raindrop access token. If all goes well, after a few moments, the importer should finish and you should find that all of your pins have migrated to Raindrop, all public pins are in the Public collection and all private pins are in the Private collection. Any pins that were marked as unread will be Unsorted . Note that if you used different names for your public and private collections you can pass those names to paindrop with the --public and --private switches. If you're looking to move your bookmarking history out of Pinboard and want to keep the same sort of structure I had I hope Paindrop will be useful to you too. Paindrop can be installed with pip or (ideally) pipx from PyPi . It can also be installed with Homebrew by tapping davep/homebrew and then installing paindrop : $ brew tap davep/homebrew $ brew install paindrop The source is available on GitHub . PS: As for the name... originally it was pin2rain but then Darren Burns pointed out the obvious and it had to happen ."},{"title":"On to something new (redux) (redux)","url":"/2024/06/16/on-to-something-new-redux-redux.html","date":"2024-06-16","content":"It's been a wee while since I wrote anything here (been about a month) so I thought I'd make mention of what's going on. The main news is that I'm employed again! Once the news about the Textual layoffs hit I, of course, started the job hunting process. This lasted for a wee while (and I have a couple of stories about that -- perhaps I'll write them up one day). I officially became \"unemployed\" on April the 1st (yeah, I know), and by the 23rd I had an offer for a new position, which I accepted. As of the time of writing I've been in that position for a touch over 3 weeks and it's going really well. Right at this moment I'm doing zero Python work (that will change, I strongly suspect) and, actually, for the first time ever, I'm writing some TypeScript (it's tempting me to dive into that some more). The team I'm working in are great and I'm also really impressed so far by the practices they have in place relating to getting stuff done. It's actually a refreshing change to work in a bigger organisation and actually find it not massively frustrating! I'm also back to working from home full time. This isn't that big a deal for me as I spent around 22 years doing so up until 2018 , and of course it isn't that big of a deal to many folk these days anyway thanks to the 2020- period. This prompted me to finally clear out the spare room (I've only been in here a touch under 5 years so of course there were a lot of \"I'll sort those soon\" boxes and stuff in there), buy a second desk, and make a work-coding area that is away from totally separate from my for-fun-coding area. This has turned out to be a really good decision. I love my main hacking space in the living room, and have done a lot of work there, but that was always on the odd days here and there when I'd work at home. Now that working at home is a full-time role it felt important to make the distinction. Weirdly though, all of this means that I'm spending less time working on personal stuff. When I was working at Textualize, most days, I'd be spending the best part of 3 hours in the day getting to and from the office. I thought that perhaps getting that time back would translate into having more time to tinker with my own stuff. Actually what I'm finding I'm doing is I'm spending the time on more general self-care and domestic things. This is a good thing. Doubtless once things really settle down and I form my new routine I'll dive back into FOSS coding more again, and perhaps get back to streaming while I code . Meanwhile though you can find me steaming many late evenings, mucking about on my PS5 . Right at this moment I'm finally playing all the way through Just Cause 4 (a game I bought back in 2019 and never finished). In fact last night I finished the main story. Expect a lot more PS5-based streaming nonsense over the next few months. One other change I have made is to my VR video publishing schedule. For the longest time I had the time and was playing so much that I published a video every day. This wasn't a schedule I set myself, this was more a case of I was playing so much that to publish less frequently would mean there would be a huge backlog. These days I'm back to working 5 days a week (previously I was working 4 days) so I have to cram a little more into my weekends, and also I want to try and do other things during weekends too. So recently I changed to an every-other-day schedule . And, really, that's about it. For now expect to see a bit less Python-based content on here, and also quite a bit less Textual-based stuff too. Currently my focus is elsewhere and it also seems that Textual is a bit of a moving target recently, throwing in some fun new bugs and breaking changes which are tricky to keep on top of. That said, you will still find me in the repo, lending a hand when I can, and of course in the Textual Discord too; just don't expect to see me quite so omnipresent there, especially during the work day."},{"title":"Tinboard v0.14.0","url":"/2024/05/14/tinboard-0-14-0.html","date":"2024-05-14","content":"I've just released Tinboard v0.14.0. This release adds a feature that a user requested , where you can set the default values for the privacy and read-later status of a new bookmark: So, any time you create a new bookmark, the edit dialog will use those values by default. It's a feature that makes perfect sense but I didn't think to add it early on because... well, I set the defaults to my preference. Tinboard can be installed with pip or (ideally) pipx from PyPi . It can also be installed with Homebrew by tapping davep/homebrew and then installing tinboard : $ brew tap davep/homebrew $ brew install tinboard The source is available on GitHub ."},{"title":"Tinboard v0.12.0","url":"/2024/04/18/tinboard-0-12-0.html","date":"2024-04-18","content":"Tinboard has turned into a tool I use pretty much every day; it's probably my most-used Textual/Python-developed application at this point. This is causing me to think more and more about how I can add things to it that are related to the core purpose, but are also outside of the main \"interface with Pinboard\" thing. A thing with keeping bookmarks for a long time is that some of them go stale, go away. Some will just plain 404, others the whole site will disappear. If I find myself going back to a bookmark and seeing this is the case, I'll hit the Wayback Machine and see if there's an archive there. So I got to thinking: what if I add the ability to perform this check into Tinboard itself? So I did just that . Now, in the application, if you press w with a bookmark highlighted, it will check with the Wayback Machine to see if the bookmark is in the archive. If it isn't you see this: On the other hand, if it is in the archive, you'll see something like this: I sense this is going to be the first step in a couple of features related to this. I'm thinking that I may go on to add a \"swap the URL for this bookmark with the Wayback Machine archive URL\" feature, which will be handy for those bookmarks that have one away, and it would also be useful to look at the options for a \"please archive a copy of this bookmark\" feature. But, for now, v0.12.0 is available and has this handy (for me anyway) first step. Tinboard can be installed with pip or (ideally) pipx from PyPi . It can also be installed with Homebrew by tapping davep/homebrew and then installing tinboard : $ brew tap davep/homebrew $ brew install tinboard The source is available on GitHub ."},{"title":"PISpy v0.6.0","url":"/2024/04/17/pispy-0-6-0.html","date":"2024-04-17","content":"Back in the very early days of the Textual adventure , within the first month or so of working on the framework, we had a period of dogfooding . One of the projects I wrote during that time was a little tool I called PISpy . The initial version was pretty much a quick hack; during that dogfooding period I did my best to try and develop a new project every couple of days. Since then I've let PISpy descend into bit rot . In the last week or so I've turned my attention back to it and made an effort to tidy up the code , tidy it some more , and some more , and even some more . This morning I put the finishing touches to these changes and released v0.6.0 . PISpy can be installed with pip or (ideallty) pipx from PyPI . It can also be installed with Homebrew by tapping davep/homebrew and then installing pispy : $ brew tap davep/homebrew $ brew install pispy The source is available on GitHub ."},{"title":"macOS desktop widget switching","url":"/2024/04/17/macos-desktop-widget-switching.html","date":"2024-04-17","content":"When desktop widgets first turned up in macOS I was pretty quick to embrace them. On my personal Mac Mini I use a pair of screens, the right one mostly given over to Emacs, and there was generally room to space there. These days that screen generally looks something like this: Recently I've got into streaming while I do some coding and it's the right-hand screen that I work on and capture using OBS. When I was setting this up I realised that the widgets being there could be a problem; not because they could distract or anything, more that they could, at times, contain sensitive information (there's my reminder list and my calendar there after all). What I needed was a quick method of hiding all the widgets, and showing them again later, without it being a lot of faff. With a little bit of digging around on the net I finally came up with a pair of fish abbreviations that do just the job! abbr -g widoff &quot;defaults write com.apple.WindowManager StandardHideWidgets -int 1&quot; abbr -g widon &quot;defaults write com.apple.WindowManager StandardHideWidgets -int 0&quot; Now, when I'm going to stream, part of my \"getting stuff ready to go live\" checklist is to run widoff in the terminal; once I'm finished I can then just run widon again to have them come back. Fast, clean, handy. I've also got a pair for when I'm using Stage Manager : abbr -g smwidoff &quot;defaults write com.apple.WindowManager StageManagerHideWidgets -int 1&quot; abbr -g smwidon &quot;defaults write com.apple.WindowManager StageManagerHideWidgets -int 0&quot; Although, really, I can't remember the last time I used Stage Manager. I dabbled with it for a wee while, found it vaguely handy in a couple of situations, but it doesn't seem to have stuck as part of my workflow or work environment."},{"title":"Tinboard v0.11.0","url":"/2024/04/09/tinboard-0-11-0.html","date":"2024-04-09","content":"While my time working on Textual might have come to an end , my time working with Textual hasn't. Three days back I experimented with Textual's newly-added \"inline mode\" : In doing so I extended the application so that it's possible to run tinboard add and quickly enter a new bookmark and then carry on in the terminal, without needing to \"go fullscreen\". I'll admit it's of limited use, but it seemed like a good shakedown of the feature and in working on it I was able to discover a couple of bugs ( #4385 , #4403 ). The effect of this is this: Tinboard can be installed with pip or (ideally) pipx from PyPi . It can also be installed with Homebrew by tapping davep/homebrew and then installing tinboard : $ brew tap davep/homebrew $ brew install tinboard The source is available on GitHub ."},{"title":"Goodbye Textualize","url":"/2024/03/28/goodbye-textualize.html","date":"2024-03-28","content":"While I have been on the receiving end of redundancy once before , that was after 21 years of service at a company that, while it was in part about software development, I would never have called it a \"tech\" company. So, as of today, I can finally say that the \" tech layoffs \" came for me and I'm one of 67% of employees being let go from a tech startup. Achievement unlocked, I guess? To be clear: I'm not annoyed about this, I'm not even shocked about this; I planned for this from the off and realised and recognised the gamble I was taking back in 2022 . I am disappointed about this. Not in a \"I'm disappointed in you\" kind of way, but disappointed for all involved and what it says about how FOSS projects are funded and maintained. It's been an interesting journey, and it's been a privilege to do something I've been wanting to do since the 1990s, when I first read the GNU Manifesto and subsequently watched the free software and open source movements develop and grow: work on FOSS for a living. In doing this I've developed my thoughts about the feasibility of such an endeavour, I've refined how I feel about working in very small teams, I've learnt a lot of useful lessons I'm going to draw on in the future (keeping a journal of my experience has been a great move; I have a lot of notes and thoughts written down that I'll be reviewing and distilling for myself over the coming weeks). Most of all: it's been an absolute blast working on something that people are actually using to build cool things , and to provide help and guidance to those people when they've needed it . So... what happens now? Well, of course, right now, I'm looking for a new position. If you're reading this and you are looking for someone who's kinda handy with Python and a bunch of other languages and who loves learning new stuff, or if you know someone who is looking for such a person, do drop me a line ! As for what happens with Textual, and my involvement with it... Well, what happens with Textual is Will 's call, of course. As for my involvement with it: I care about FOSS and I care about Textual; I also care about the folk who have been kind enough to use their time to explore it, test it, build with it, commit to it and make neat stuff with it. My intention, as long as free time allows, is to carry on being involved, both on GitHub and in the Discord server . It's my sincere hope that, as a community of FOSS-friendly developers, we see Textual over the 1.0 line and beyond. But all that starts next week. It's a bank holiday weekend and I think I might have deserved a run, a bit of mucking about in VR , a beer, and just a wee bit of down time."},{"title":"Homebrew all the Python things","url":"/2024/03/10/homebrew-all-the-python-things.html","date":"2024-03-10","content":"Over the past year and a half I've written a lot of Python code, and a lot of that Python code has been Textual applications; most of those Textual applications have been very quick demonstration or test applications built to help support someone asking for help; some of them have been less-trivial applications written in my own time and for my own use and amusement. Of them I'd say there are two near-daily-drivers, and a couple that I either have more plans for, or like to maintain just for the hell of it. Those latter applications are all ones that I've deployed to PyPI , and because of that are all ones that I've recommenced be installed using pipx . During that time though I've had half an inclination to make them installable via Homebrew . While probably not installable from the core Homebrew repository 1 , at least installable from a \"tap\" 2 that's under my own GitHub account or something. To this end I've had a blog post about packaging Python apps for Homebrew saved in Pinboard for a while now, and every time I look at it I think \"this is a lot of faff, maybe later\" . Today was that \"later\". As it turned out, it was way easier than I first realised. The evolution of today pretty much went like this: Deciding to use a single repository as the \"tap\" The blog post above seemed to suggest that for every application repository you want a tap for, you probably want a parallel homebrew- -prefixed repository. This in turn would suggest that every time someone wants to install one of your tools, they'd need to add a new tap 3 . As I looked at it this seemed like way too much faff, so in the end I decided to create a single repository that I'd keep all my formula files in . The naming of homebrew-homebrew meant that the tap name would simply be davep/homebrew . Simple and clean, I think: things for homebrew, things that can be installed via homebrew, that come from davep. To add the tap it's simply: $ brew tap davep/homebrew Ensuring that all my applications and libraries publish source Although it seems that it might be (possibly, maybe, perhaps, who can tell?) deprecated, it looked like homebrew-pypi-poet was a tool I'd need to do all the heavy work on making the formula file. A quick test threw up a problem where it was complaining that my test package (one of my own applications) didn't have an sdist . Sure enough, through nothing more than never having bothered to make it happen, the source of my libraries and applications wasn't been uploaded to PyPI when I published. So I went through some of my repositories and fixed that, making patch releases as I went. Making a Makefile to let me be lazy The next thing to do was to figure out the most lazy way of building the formula files. From what I could see the main steps to making all of this work were: Make a venv and activate it Install homebrew-pypi-poet Install the package you want to package for Homebrew Run poet to make the formula Seemed simple enough. For all sorts of lazy reasons I still tend to use pipenv to get things done quickly, and that seemed to work fine here too. I'm also a fan of PIPENV_VENV_IN_PROJECT=true which makes things clean and tidy, so I figured a rule in a Makefile like this: clean : rm -rf .venv rm -f Pipfile Pipfile.lock pipenv --python 3 .12 pipenv install --dev homebrew-pypi-poet would be fine to make a clean venv ready to build the formula, and then I'd have a rule for the package itself that depended on the above, like this: oshit : clean pipenv install oshit pipenv run poet -f oshit &gt; Formula/oshit.rb Fixing the package description The above was great, and worked really well. But there was one issue that I could see: the resulting formula file always had this desc inside it: desc &quot;Shiny new formula&quot; From what I could see there was no way to tell poet what I wanted the description to be, and neither did I want to have to remember to edit that line each time I regenerated the formula file. So sed to the rescue then I guess, with this sort of thing: sed -i &#39;&#39; &#39;s/Shiny new formula/The actual text I want/&#39; Formula/coolapp.rb The result The result of all of this is that I now have a repository that I or anyone else can use as a tap to be able to install my stuff using the brew command. So now if you want a little Hacker News reader for the terminal but you don't want to be messing with installing pipx and the like, but you do use brew on your machine, it's just this: $ brew tap davep/homebrew $ brew install oshit Fingers crossed it all \"just works\" when I next upgrade one of those packages. I will, of course, have to remember to go into davep/homebrew-homebrew and make the-app for the relevant application, and then commit and push the changes, but that's really not too difficult to remember and do. Hopefully it'll then all just work. I do actually have one package in Homebrew , but it wasn't me who put it there.&#160; &#8617; I really like Homebrew as a tool for getting stuff installed, by oh my gods the naming of things in its ecosystem is terrible and confusing!&#160; &#8617; No, really, I mean it, this naming convention is kinda cringe right?&#160; &#8617;"},{"title":"Tinboard v0.10.0","url":"/2024/03/07/tinboard-0-10-0.html","date":"2024-03-07","content":"I just realised that it's been a while since I last posted an update about tinboard . This is probably my most-used Textual-based application, and one I'm constantly tinkering with, and just this morning I published v0.10.0. Often the changes are small tweaks or fixes to how it works, sometimes they're simply updates to the version of Textual used, making use of some new feature or other; I've yet to add another \"major\" feature so far. They will come, but so far the ideas I have for the application haven't actually felt that necessary. Although I say so myself it does what I need it to do and it does it really well. So, as a quick catch-up of what's changed since v0.4.0 (which was the last version I posted about): v0.5.0 was released 2024-01-04; this included all the tags of a bookmark when doing full-text searching. v0.6.0 was released 2024-01-10; it fixed a small bug where the tag suggestion facility got confused by trailing spaces in the input field. v0.7.0 was released 2024-02-02; this updated the minimum Textual version to v0.48.2 and removed all the custom changes to the Textual TextArea widget, making use of the updates to TextArea that version of Textual made available. v0.8.0 was released 2024-02-18; this fixed a crash on startup caused by a newer release of Textual (the fault was in tinboard ; the update to Textual helped reveal the problem). v0.9.0 was released 2024-02-29; it simply added support for using Esc at the top level of the application to quit (I like to camp on Esc to GTFO). Then, just now, I released v0.10.0. This release makes full use of some work I recently did to enhance Textual's CommandPalette widget , which added a \"discover\" system. The change in tinboard is that all of the command palette providers now have discover methods too. The result of this change is that when you open the command palette in tinboard ( ctrl + p ) you can see every possible command right away. Tinboard can be installed with pip or (ideally) pipx from PyPi . The source is available on GitHub ."},{"title":"Back to Death Stranding","url":"/2024/02/05/back-to-death-stranding.html","date":"2024-02-05","content":"Death Stranding is easily one of my top 5 games ever. I bought the PS4 version, on a whim, back in early 2020, to see what all the fuss was about. I didn't know much about it other than the love/hate it seemed to be getting. I can still remember the first session, being a bit confused about what was going on, and then suddenly hitting a perfect moment in the game where I knew it was for me, and that I was going to love it. That moment? It's when you're setting out for the incinerator, the camera pulls back, the landscape opens up before you, and Bones by Low Roar kicks in . Perfection! I went on to finish the story in around 45 to 50 hours (much of that overlapping with the first week or so of lockdown during the pandemic); and then played at least as much again just exploring, building zip lines, roads, etc. I even kept a photoblog of my time in the game . About a year back I bought the Director's Cut of the game, this time for PC. I'd decided that I had to play it through again and did start streaming it . Annoyingly though the PC setup wasn't great. The game itself ran just fine on my PC, but the controller setup meant that, as I sat on the sofa, it would drop connection from time to time. The only workaround for this was to sit on my office chair closer to the TV and, really, this wasn't comfortable. Eventually that play-through fell away. Fast forward to last week and the release of the 10 minute Death Stranding 2 trailer and I was hooked all over again! While it never totally went away, my obsession with this game was back full force. I had to play again! Meanwhile, between the attempt to play through on the PC and now, I'd acquired a PS5 and at some point I'd upgraded my PS4 version of Death Stranding to the PS5 Director's Cut. So I had to. I just had to. I'd had a great time streaming my play through the story of Cyberpunk 2077 so it made sense to do the same with Death Stranding. Last night I hit New game on my PS5 and played for just over 2 hours . This play through is likely going to take a long time -- my work situation means I have a longer and more tiring commute -- but I'm determined to do it. I want to experience all of the extra things in the Director's Cut, including the extra story (which I've read there is, but haven't seen or read about). I hope, eventually, the playlist I started will have the full story plus lots more fun and building and exploring in it. Hopefully I'll be done just in time for the release of DS2! (and GTA6 , it's going to be a busy year for gaming next year!)"},{"title":"How not to ask for help","url":"/2024/02/04/how-not-to-ask-for-help.html","date":"2024-02-04","content":"My association with Textual works on two levels: on the one hand, sure, it's currently my day job ; on the other hand it's a FOSS project that I'm keen to support so \"free time me\" tries to work with it and support others working with it too. For this reason you'll often see me being terminally 1 online in the Textual Discord, trying to answer questions as they come up, every waking free moment. Almost without exception the people who ask for help are appreciative and ask in the spirit of wanting help and wanting to work together with whoever is helping them to get an answer. That... that's actually quite a cool thing to be part of. I like the sense of community that comes from someone going \"bah I'm trying to do this thing and it isn't working PLEASE HELP!\" . And then... well, let's just say that sometimes the odd question will crop up that seems to be asked from a less collaborative position. Without wanting to appear to dunk on an individual (I don't wish to), I want to break down an example that happened yesterday. For some background, I'd been AFK all day, having a wonderful time in town with a friend , shopping, lunch , a movie, that sort of thing. A nicely-chilled day where I didn't even look at the Discord notifications that had popped up on my watch and phone. However, later on that evening, finally home and flopped on the sofa, I saw a question pop up that, while lacking any useful detail and possibly suffering a wee bit from being an XY problem , the immediate answer was clear: BadIdentifier: 'test.udp_json_client-input' is an invalid id; identifiers must contain only letters, numbers, underscores, or hyphens, and must not begin with a number. ????????????????? a dot isn't allowed? Like I say: it lacks context and detail, and the number of question marks doesn't really clarify much, but the core question that seems to be at play here is \"is it true that a full stop can't be used as part of the ID of a widget?\" . The answer is: no, it can't. There's a reason for that too, and if someone were to take a step back for a moment and think about how IDs play a part in queries and how they'd be used in a stylesheet, the reason for that might pop out. So, to help the person asking the question walk in the direction of the answer, I reply: When you come to query that how would the parser know its not ID test combined with a class, if dot was allowed? Before we go on, to illustrate my point, consider this ID: foo.bar . When you come to query that back, or use it in a stylesheet, how would #foo.bar look? Is it a widget with the ID foo.bar ; or is it a widget with the id foo and the class bar ? As far as Textual's CSS is concerned, it would be the latter. But at this point it didn't seem necessary to get into all that detail; I like to try and assume knowledge on the part of the person asking the question, sans any other evidence, so for the moment I'll assume a \"oh, right, yeah, that's a damn good point\" kind of reply. Or if not, perhaps a \"I don't quite follow, could you explain?\" reply, in which case I'm happy to go into all the detail. The reply was neither: why are element ID and classes co-mingled? this was previously allowed so your question doesn't really make sense to me Now I'm confused. Asking why element IDs and classes are co-mingled seems odd; but I'm used to chatting with people who don't have English as a first language so I'm going to assume it's just a wording choice; but the latter part is very odd: this has never been allowed. Or, more to the point... without any proper context I can't really appreciate what claim is being made here. You see... I did notice a bug in Textual recently, when it came to widget IDs . Long story short: when you set your ID for the widget in your code, no actual validation of the ID was being done. This was an oversight that was fixed in the latest release . But knowing that that's the case would be guesswork on my part; I'm also fresh at my desk after a day out; I'm probably not quite in the coding/Textual zone yet, so rather than try and guess half of the conversation, it's easier to just ask the person who is asking. So I ask them to restate the question, and give some more background. The reply is: the objective is to put a string like test.udp_json_client-input as the label of a tab, which previously just used the ID property. from skimming release notes, is it better to explicitly set the label, and then assign something compliant for the ID separately? Wait... what? I thought we were talking about valid widget IDs, now we're talking about tabs and labels? Do we mean TabbeContent and the labels of a TabPane ? This is a bit different. So I'm sat there trying to figure out this person's thought process so I can offer the help they're after and this follows: okay @davep, you have a real bug. --content-tab- prefix is not ephemeral. if I create a tab and grab .id, that prefix comes with it, so if you save it for later and try to set .active, assigning .active doesn't agree that there is a tab --content-tab-thing so I need to de-mangle the name manually before assigning .active I guess? Wut? Like... wut? Okay, we do seem to be talking about TabbedContent , I recognise the values being mentioned here; we did some work late on last year that added some namespacing to parts of the TabbedContent widget in an effort to reduce some foot-gun situations . But... there's no . being used in the IDs as part of that; why are we now proclaiming a bug in an unrelated PR? That's quite the leap with zero evidence. Like... sure, I'm all for being alerted to bugs and fixing them, but this doesn't seem like that. And then there's the \"so I need to...\" conclusion that also seems to have no connection to the original question. Anyone who has ever done support will recognise this situation, I'm sure. Someone has seen a problem, they've dug around a little and reached a conclusion about what the cause is, and turns up looking for help with the conclusion they've reached (very much a variant of a XY problem ). That almost never gets us where we want to go, so I do the obvious thing; I try and reboot the question; I try and get us back to the start and try and get some clarity; I try and encourage asking the question with zero assumptions: I'm afraid I'm still not really understanding your question, as it now no longer seems to relate to what you very first asked. Perhaps you could start again, ideally with an MRE of what you're looking at and trying to do, for clarity? I figure, whatever the problem is, it can be illustrated with like a dozen lines of code. Also, when asking people to do this, it often actually helps them rubber-duck their own problem. There's been plenty of times on Discord where someone's \"found a bug\" in Textual, they're asked to make an MRE of it, and they come back and go \"oh, shoot, right, I did that and realised the bug was in my code\" . It's cool when they happens; everyone learns something. So... no MRE comes back, but this is the reply: I'm trying to fix multiple breakages in my application from some recent changes. Right now I can't wrap my head around what to assign a tabbed_content.active for it to work how it did before (where if you have a tab with ID sample, you can assign tabbed_content.active = \"sample\", but you can't do that anymore) While not an MRE, I can work with this. It seems clear that they have a TabbedContent where they have a TabPane with the ID \"sample\" and they are struggling to make it the active tab by setting active to \"sample\" . That seems hugely unlikely, this is what TabbedContent is all about, I think we'd have noticed (I'm petty sure we've got unit tests that cover this), but I'm game. I can test this. And the MRE I write will illustrate there isn't a problem. So I reply: Again, I can only suggest that you make an MRE of the issue you're seeing. For example, here's me making a set of tabs, the last of which has the ID \"four\", and I set the active to \"four\": and provide the code: from textual.app import App , ComposeResult from textual.widgets import TabbedContent , TabPane , Label class TabbedContentApp ( App [ None ]): def compose ( self ) -&gt; ComposeResult : with TabbedContent (): with TabPane ( &quot;One&quot; , id = &quot;one&quot; ): yield Label ( &quot;One&quot; ) with TabPane ( &quot;Two&quot; , id = &quot;two&quot; ): yield Label ( &quot;Two&quot; ) with TabPane ( &quot;Three&quot; , id = &quot;three&quot; ): yield Label ( &quot;Three&quot; ) with TabPane ( &quot;Four&quot; , id = &quot;four&quot; ): yield Label ( &quot;Four&quot; ) def on_mount ( self ) -&gt; None : self . query_one ( TabbedContent ) . active = &quot;four&quot; if __name__ == &quot;__main__&quot; : TabbedContentApp () . run () Based on what they've most-recently said is the problem, I'm confident they'll see that this MRE is their situation in a nutshell, and we can work out from there and figure out what the problem is they're seeing and where this . in their IDs is coming from (because I'm very confident it isn't coming from the work that was done on TabbedContent ). This is good. We're getting close to heading down a good path; I can feel it! I was wrong. https://github.com/Textualize/textual/blob/main/src/textual/widgets/_tabbed_content.py#L513 there's no way you can deny you just added a metric ton of shenanigans with the tab ID stuff. I can't get it to work at all anymore (assigning .active), but yes I will either come up with an MRE or find the bug and let you know So, rather than back up a wee bit, work with the MRE I wrote for them so we can take a walk through the problem, they instead decide to tell me that the PR I did last year (which still isn't implicated in any of this outwith of them seemingly assuming it's the cause of all the issues, presented with zero evidence that it is) was simply \"a metric ton of shenanigans\" . No! Stop! This is not how you ask for help. This isn't how you ask for help from a product or service you pay for. This really isn't how you ask for help from a Free Software project, where the people who are offering you help are doing so in their free time because they want people to be able to build cool things with it. It really isn't hard at all to show just a wee bit of respect for people's time and willingness to try and help you. Now... I get it. I can imagine a scenario where someone has just updated Textual and their application suddenly starts throwing all sorts of weird and new errors. That happens. That happened to me on Thursday evening just gone . But that's no reason for approaching getting help like this. The way to approach it is this: pin the problem dependency, perhaps publish a new version of your application so there's no accidental update of the dependency, then head to any of the help resources for the dependency has and work with people who want to help you to find the cause of the problem . Trust me, it'll go a lot faster if you work with them, take on board suggestions (no matter how odd they might first appear), and really don't call their code \"a metric ton of shenanigans\" . The conclusion to all of this? The person asking the question eventually found they were setting some widget's ID to an invalid ID; one with a . in it. So as I suspected and wanted to walk them to: they had invalid IDs all along and they only found out about this because ID validation was fixed. Perhaps one day they'll retract the claim that my actually-unrelated code that wasn't \"just\" released but was from last year is \"a metric ton of shenanigans\" . \\_()_/ Geddit? GEDDIT?&#160; &#8617;"},{"title":"Quizzical","url":"/2024/01/29/quizzical.html","date":"2024-01-29","content":"I feel like I'm on a bit of a roll when it comes to building applications for the terminal at the moment; while I'm still tinkering and improving tinboard and OSHit , I had the urge to tackle another idea that's been on my TODO list for a while. This is something I did for Emacs back in 2017 and I felt it was a perfect candidate for a Textual-based project. It's a terminal-based trivia quiz game, using the Open Trivia Database as the source of questions. I've just published an early version to PyPI ; it still needs some polish and I have a few other ideas for it, but as it stands I feel it's a fun little game to mess around with. The idea is pretty straightforward: you can run it up and create lots of different quizzes, there are various parameters you can use to create lots of different kinds of challenges: Once you're created a quiz, you can run it and answer away: Right now the idea is that you answer by pressing either 1 , 2 , 3 or 4 (or just 1 or 2 for true/false questions); when I get a moment I'll also enable mouse support for selecting an answer too (honestly I feel keyboard-answering feels far more natural). Once the quiz is done you can review your answers and see which were right and which were wrong: As I say: there's a bunch of other things I want to add to this (keeping track of scores, adding session token support to reduce the chances of repeat questions, etc), but this felt like a good spot to make a v0.1.0 available if anyone else wanted to have a play. Anyway, if this sounds like your sort of thing, it can be installed with pip or (ideally) pipx from PyPi . The source is available over on GitHub . PS: Now you can see why I made textual-countdown ."},{"title":"Orange Site Hit v0.5.0","url":"/2024/01/17/oshit-0-5-0.html","date":"2024-01-17","content":"Just a wee catch-up post about OSHit, my terminal-based HackerNews browser . Over the past couple of weeks I've made some small changes, so I thought I'd make mention of what I've done. As of v0.5.0, which I released earlier today, I've: Added a quick way of following links while viewing a comment. While a comment is highlighted you can press l to follow a link; if there's more than one link in the comment a menu will be shown and you can select which one to follow. Added support for viewing polls. Polls seem to be few and far between on HackerNews, so when I published the first version of OSHit I didn't have one to hand to test any code against. Eventually one turned up and broke OSHit (on purpose; I wanted to see when that happened) so I could then add the code to load polls and show them. Right now it just shows scores; I might do actual charts at some point. Added optional item numbers in the lists; turned on/off with F4 . So far all small things, but handy little improvements. There's still a nice TODO list in the README and I will slowly work through it. Along with tinboard these are two applications that have absolutely turned into \"daily drivers\", so they're going to get a lot of tweaking over the next few weeks, probably even months."},{"title":"textual-dominfo","url":"/2024/01/15/textual-dominfo.html","date":"2024-01-15","content":"Last week I was wrestling with some Textual code, trying to get something to lay out on the screen \"just so\". On the whole this isn't too tricky at all, and for those times where it might feel tricky there's some advice available on how to go about it . But in this case I was trying to do a couple of \"on the edge\" things and one thing I really needed to know was what particular part of the display was being \"caused\" by what container or widget 1 . Now, at the moment anyway, Textual doesn't have a full-blown devtools with all the bells and whistles; not like in your average web browser. It does have a devtools , but not with all the fancy DOM-diving stuff the above would have needed. What I needed was the equivalent of print -debugging but with a point-and-ask interface. Now, I actually do often do print -debugging with Textual apps only I use notify ; this time though notify wasn't going to cut it. I needed something that would let me point at a widget and say \"show me stuff about this\" . Something that happens when the mouse hovers over a widget. Something like... a tooltip ! So that was easy: def on_mount ( self ) -&gt; None : for widget in [ self , * self . query ( &quot;*&quot; )]: widget . tooltip = &quot; \\n &quot; . join ( f &quot; { node !r} &quot; for node in widget . ancestors_with_self ) Suddenly I could hover my mouse over a bit of space on the screen and get a \"traceback\" of sorts for what \"caused\" it. I posted this little hack to #show-and-tell on the Discord server and someone mentioned it would be handy if it also showed the CSS for the widget too. That was simple enough because every widget has a styles.css property that is the CSS for the widget, as a string. After that I didn't think much more about it; until today. Looking back, one thing I realised is that adding the CSS information on_mount wasn't quite good enough, as it would only show me the state of CSS when the mount happened, not at the moment I inspect the widget. I needed the tooltip to be dynamic. Thing is... Textual tooltips can't be functions (which would be the obvious approach to make it dynamic); so there was no way to get this on-the-fly behaviour I wanted. Except there was! The type of tooltip is RenderableType . So that means I could assign it an object that is a Rich renderable; that in turn means I could write a __rich__ method for a class that wraps a widget and then reports back what it can see every time it's called. In other words, via one step of indirection, I could get the \"call a function each time\" approach I was after! It works a treat too. All of which is a long-winded way of saying I now have a print -debug-level DOM inspector tool for when I'm building applications with Textual: If this sounds handy to you, you can grab the code too. Install it into your development environment with pip : $ pip install textual-dominfo and then attach it to your app or screen or some top-level widget you're interested in via on_mount ; for example: def on_mount(self) -&gt; None: from textual_dominfo import DOMInfo DOMInfo.attach_to(self) and then hover away with that mouse cursor and inspect all the things! Whatever you do though, don't make it part of your runtime, and don't keep it installed; just make it a development dependency. The source can be found over on GitHub and the package is, as mentioned above, over on PyPi . ObPedant: Containers are widgets, but it's often helpful to make a distinction between widgets that exist just to control the layout of the widgets inside them, and widgets that exist to actually do or show stuff.&#160; &#8617;"},{"title":"textual-countdown","url":"/2024/01/11/textual-countdown.html","date":"2024-01-11","content":"The idea for this one popped into my head while on the bus back from Textual Towers this evening. So after dinner and some nonsense on TV I had to visit my desk and do a quick hack. This is textual-countdown , a subtle but I think useful countdown widget for Textual applications. The idea is that you compose it somewhere into your screen, and when you start the countdown the bar highlights and then starts to shrink down to \"nothing\" in the middle of its display. When the countdown ends a message is posted so you can then perform the task that was being waited for in an event handler. Not really a novel thing, I've seen this kind of thing before on the web; I'm sure we all have. I just thought it would be a fun idea for Textual applications too. I envisage using this where, perhaps, an application needs to wait for an API-visiting cooldown period, or perhaps as a subtle countdown for a question in a quiz; something like that. Anyway, if this sounds like it's something useful for your Textual applications, it's now available from PyPi and, of course, the source is over on GitHub ."},{"title":"Orange Site Hit v0.2.0","url":"/2024/01/07/oshit-0-2-0.html","date":"2024-01-07","content":"This is actually the second release of OSHit since I first announced it a week back , and I'll get to that other release in a moment. I've just published v0.2.0, which isn't a very substantial release, but which bumps the required version of Textual to v0.47.1 and has some fun with the new nested CSS feature . Underlying the point of this release was me taking a \"real world\" application of mine and nesting as much of the CSS within it as possible, in part to get a feel for how and when it's useful, but also to give it a proper test in a \"proper\" application. In doing so I think I've found one bug . Dogfooding is always a good idea. The main visible change in this release is I've played around with the look of the comments dialog a bit: I'm still narrowing this down, but I think I prefer this look to what I started out with. Another change I made was also to the comments dialog. Before, if you performed the \"expand comments\" action on a comment card that already had its comments expanded, it would move focus to the first child comment; this was a deliberate choice that felt right at the time. Having used the app for a few days now I've realised that making it an open/close toggle is far more useful. So that's what I've done. Now... as for the previous release I mentioned above. That was a fun one. Back when I released v0.1.0 some joker decided that it would be fun to submit the blog post about it to the Orange Site . The comments there went as you'd expected: Some riffed off the opening paragraph, ignoring the tool itself. Some riffed off the opening paragraph in self-reflective way. Some riffed off the opening paragraph in a \"I never see the problem\" way. One or two did the usual \"why even bother building that when $TOOL_OF_CHOICE exists?\" dance to show their terminal purity. One or two posted genuinely useful links to other similar projects. The biggest tree of comments was kind of a fight. One comment caught my eye though; someone reported having a problem running it. My initial thought on reading it was \"my dude, seriously, you're going to report the problem in some random comment on HN rather than raise an issue with the author?!?\" . For once I was wrong to be so cynical . So, yeah, that was the reminder I needed that I'd been intentionally reckless while writing the original code, and hadn't gone back to the API code I'd written and made it behave before doing the initial release. All of which is to say: if you run into a problem with some FOSS project, be like @mihaitodor . Issue that thing so the developer gets to know about it; don't assume they'll be reading some random comment section, social media site or Discord server! That and don't make 500+ HTTP requests at once; that might not end well for some."},{"title":"Orange Site Hit","url":"/2024/01/01/oshit.html","date":"2024-01-01","content":"I know I'm not alone in having a relationship with the orange site that is... weird. I generally dislike the culture there, it's almost impossible to read any of the comments without being frustrated about the industry I work in or am adjacent to and some of the people who inhabit it; but as a link aggregator of stuff I might find interesting... I honestly can't think of anywhere better. So, yes, I've been a fairly avid reader of HackerNews for many years, and have even had an account there for over 4 years. Given this, for a wee while now, I've been meaning to knock up a terminal-based client for it using Textual . So after work on Tinboard settled down I got the urge to start a new pet project (not abandoning Tinboard, I'm still going to be tweaking and extending it of course) and finally knocking up that client seemed like the one. Orange Site Hit is the result. It's worth making clear from the very start: this is a read-only reader. There is no logging in, there is no voting, there is no posting of things. This is a client built with their own API and it doesn't provide such a thing; at least not now and despite me seeing past promises that this will change, there's no API for doing that sort of thing. 1 The idea of this application is you can run it up in the terminal, check the top, best and latest from the categories provided by the API, perhaps dive off into your web browser if needed, and then got on with other things. It's there for when you're in the terminal you just need your hit of the orange site. The main screen of the app revolves around the index of items, most of which are going to be stories. You can see an example of that above. For people who prefer things to be slightly less cramped, I've also added a \"relaxed layout\" mode too: From the index you can head off into your web-browser by hitting Enter on any item; if the item is a story that links to somewhere that link will be opened; if it's something more like AskHN , or a job, it'll open the related page on HackerNews itself. Pressing u with an item selected will let you view the details for the user who posted the item: If you're the sort of person who wants to torture themselves by reading the comments (oh come on we all do it!), there's a comment reader/navigator too. With an item selected press c and the comment dialog will open: I think the navigation within that dialog is fine; although I can see some scope for improvement. At the moment it uses a widget-per-comment (actually, it's at least 4 widgets per comment), which is fine and Textual handles that without an issue, even on items with lots of comments, but longer-term I can see me having some fun using the line API to build a super-efficient comment presentation and navigation widget. That's it for now; it feels like a good v0.1.0 spot to be in. There are a bunch of things I still want to do with it (better cleaning up of the text, perhaps with some markup support so links get handled, etc; plus lots of ways of searching for stuff), but I felt it was in a place where I could start using it. Anyway, if this sounds like your sort of thing, it can be installed with pip or (ideally) pipx from PyPi . The source is available over on GitHub . Yes, there are lots of clients that do all sorts of HTML-scraping of the actual website to make this possible; this ain't that. This ain't going to be that.&#160; &#8617;"},{"title":"Tinboard v0.4.0","url":"/2023/12/25/tinboard-0-4-0.html","date":"2023-12-25","content":"Although it's not planned this way, so far it looks like I'm on a \"every other day\" release cycle with Tinboard right now! Today's release is a small but handy one, I think. Thanks to the handy little library pyperclip I've added: The ability to copy a bookmark's URL to the clipboard. URL field autofill if you go to add a new bookmark and the clipboard appears to have a valid URL in it. At the moment the copy facility is just a straightforward copy of the URL, nothing else. At some point I may add an extended copy option, which will open a dialog with a bunch of options of what to copy from the bookmark, and perhaps also how to format it or something. Like, often, if I'm copying a bookmark's URL, it's because I want to paste it into some Markdown document, or some location that will handle Markdown markup. Perhaps that'll turn up in v0.5.0 in a couple of days? ;-) Tinboard can be installed with pip or (ideally) pipx from PyPi . The source is available on GitHub ."},{"title":"Tinboard v0.3.0","url":"/2023/12/23/tinboard-0-3-0.html","date":"2023-12-23","content":"It looks like I'm in a wee period of small incremental changes and release of Tinboard . This morning I've release v0.3.0, which has a couple of small but useful changes. The first is more of a cosmetic thing. The Footer widget in Textual is handy for showing the current keyboard bindings in a given context, but it can get massively cluttered very quickly (we do have plans to revisit this); in Tinboard this clutter creep was turning into a thing. So I've removed almost every binding from being displayed in the Footer , and have placed an emphasis on the user pressing F1 to get context-sensitive help, and have also left the most useful bindings in the footer with very minimal descriptions. Given that this is a keyboard-first application, and I've tried to make the bindings easy to remember, I think it's going to make more sense to do it like this, and will make for a tidier UI too. There is one disadvantage here of course: by removing the display of bindings from the footer, the mouse-heavy user becomes disadvantaged; if a particular binding doesn't have a UI feature that favours the mouse to cover it too there's no way to initiate that action with the mouse. I'm going to think on this a little. Again, Tinboard is designed for me first and foremost, and my preference is to be keyboard-first when using the application; but finding a good compromise would be advantageous when it comes to advising people asking about Textual application design. The second change is a simple but useful one. I've added a toggle of the sort order of the tags menu in the left-hand column (bound to F4 ). Right now it simply toggles between alphabetical order, or bookmark count order (most to least). At some point I might make it more of a cycle than a toggle, but this serves my purposes for now. Tinboard can be installed with pip or (ideally) pipx from PyPi . The source is available on GitHub ."},{"title":"Tinboard v0.2.0","url":"/2023/12/21/tinboard-0-2-0.html","date":"2023-12-21","content":"Following on from the initial full release a couple of days ago , I've just released v0.2.0 of Tinboard . There's just one small change in this, but I think it's a really useful one. In the top-left corner of the screen there's a menu of main filters, letting you switch between seeing all bookmarks, or a combination of read, unread, public, private, etc... In using the application I quickly realised that it would be handy to have bookmark counts in that menu. So I added that: These counts are a little different from those in the tags list, in that they always show the number of matching bookmarks amongst all recorded bookmarks , not just those currently on display (and so subject to any sort of filter that's in play). I think this is the right approach here. I know for sure that that's what I want from this, and I am writing this for me after all... What's handy about this is that it makes it easier for me to see how many bookmarks haven't been tagged, and also how many I haven't looked back over and marked as read. This is already helping me get to untagged-zero. Tinboard can be installed with pip or (ideally) pipx from PyPi . The source is available on GitHub ."},{"title":"Tinboard","url":"/2023/12/19/tinboard.html","date":"2023-12-19","content":"Over the past few weeks I've been working on a new pet project, in part done as a Textual \"dogfooding\" project, but also because this is a tool I've been wanting for a while now: a terminal-based client for the Pinboard bookmarking service . The dogfooding side of the development has been helping, uncovering a couple of fun bugs in Textual; plus the act of building this has let me try out a few of the newer features we've recently added to the framework. What's really important though is this is a tool I actually wanted , and I'm using pretty often. I've written a lot of Textual-based applications over the past year, most small examples, some quite a bit bigger , but none of them really form part of my daily workflow. This changes with Tinboard. Tinboard is designed as a fully-featured client, allowing for the creation of new Bookmarks, complete with tag suggestion support: Not only are tag suggestions pulled from Pinboard, but entry of tags can auto-complete, taking completions from both the suggested tags and also tags used amongst your own bookmarks: That feature was really easy to add thanks to the Suggester API . Thanks to the recently-added TextArea widget the add/edit dialog allows for proper full editing of the extended text description of the bookmark too: One caveat here is a lack of word-wrapping; but this will be arriving in an update to Textual early in the new year. As well as all the usual add/edit/delete facilities, Tinboard is also designed to make it pretty easy to find bookmarks too. There are filtering options for seeing all read/unread, public/private and tagged/untagged bookmarks; this makes bookmark management really easy for me because I can filter for all the untagged and private bookmarks, which are likely the ones that need editing and expanding on, and tidy up my bookmark library. There is also, of course, full text search too. When a filter or search is in operation, the related tags and the like react too: Another thing I've made a point of doing in Tinboard is leaning pretty hard on the Command Palette . No functionality is only available by it (I've done my best to make sure that keyboard is the primary input device here, with keyboard shortcuts for as much as possible). Initially I approached this as a \"for the sake of completeness\" feature, but already I'm finding that it's a pretty quick method of pulling up a tag filter. To help make all the features as discoverable possible, I've also ensured there's a pretty comprehensive help screen: Anyway; that's v0.1.0 out in the wild. I'm pleased with how it's turned out and there's a few more things I'd like to add. It's licensed GPL-3.0 and available via GitHub and also via PyPi . If you have an environment that has pipx installed you should be able to get up and going with: $ pipx install tinboard I hope this is useful to someone else. :-)"},{"title":"Steam Deck","url":"/2023/12/14/Steam-Deck.html","date":"2023-12-14","content":"Back in 2021, I think it was, when Value first announced the Steam Deck, I was all \"hell yes sign me up!\" ; like... really, I signed up there and then to go on the waiting list. The idea of a wee device that would let me play a ton of games in my Steam library seemed like a great idea. The price seemed right too. So, I signed up, and waited, and waited, and life moved on. When I finally (I think it was the best part of 18 months later?) got the email saying my Deck was up for grabs and did I want to complete the purchase I... said nah. By this point I was so heavily into VR gaming that mucking with stuff on a Deck didn't seem to make much sense to me any more. I moved on. Then a few weeks back they announced the OLED version and I took a second look. There was now over a year of reviews to read, hacks to notice, fun to follow; now I could get an idea if a Deck was any good and if it was for me. So after a bit of review-reading and review-watching, Thursday last week, I slapped down an order; and by Tuesday the Deck turned up. The overturning of my original decision to not buy came down to a couple of things. The first was: I recognised that there were a lot of games in my library, sometimes things I'd bought (often in a sale), sometimes things I'd got as part of a Humble Bundle, that just never got played. This, I noticed, was sort of down to an unfortunate relationship I'd developed with gaming. See... VR has won me over. I love gaming in VR. Also, I love recording my gaming sessions and throwing them on YouTube . This means that, to some extent, in my head, there's effort to getting going with playing a game: I've got to power up the Windows PC; I've got to let it update stuff; I've got to let Steam update stuff; I've got to power up the VR headset; I've got to get it to connect to the PC (which generally works fine but on occasion needs a complete restart of everything); I need to decide what I'm playing next and what to record; I've got to get the recording software going; I've got to... You get the idea. Also, of course, I've got to be in the right state to be okay with having a computer strapped to my face (sometimes you don't feel 100% and being lost in a virtual world isn't the best thing to be doing). This can feel like too much effort. It also means that gaming tends to be left for when I've got a few hours to dedicate to it. 1 But I also love playing games. My thinking then was a Deck would be a great way of \"forcing\" myself to play the more casual stuff. There's no easy (that I know of) way to record or stream from the Deck; it's also easy to have it on the sofa and turn it on in a moment. This felt like the ideal device to have to hand, that was dedicated to gaming, and which would encourage me to take smaller gaming sessions when the time arises. Like... sometimes I'll put something on to cook, come into the living room, pick up the tablet and scroll through the Internet. While I try not to doom-scroll too much, I can see that it would be more healthy to pick up the Deck and play DooM! So far, two days in, I'm convinced this was an excellent idea and I'm totally won over. I'm still getting a feel for what does and doesn't work best on the Deck, from a \"my taste in games\" point of view, but things that allow for dipping in and having a quick blast are winners. Hong Kong Massacre has finally got a play, despite me owning it ever since I saw John Wick 4. DooM II got installed and is working well -- I may have to slowly play my way through the whole thing. I've also installed Abyss Odyssey and so far am finding it quite charming and fun (it's an example of a game that isn't really my kind of thing; but I got it in a Humble Bundle, I think, and it's been sat there with 0 hours for way too long). I've also failed to resist one of the more questionable titles from my younger days ... The real surprise for me though has been a game I bought on a whim a couple of weeks back, which was going cheap, looked fun, seemed nice and casual and which I installed on the PC and totally ignored (because, again, turning on the PC to have a quick game seems like a lot of faff): Brotato . This game is frantic, way over the top, kinda confusing in parts (for me) but accessible enough that I can actually have a ton of fun with it; and what's really important is that I can pick up the Deck, turn it on, play a game of this for 10 minutes and then go on to do the thing I needed to do next. It's the perfect game to play while waiting for the next step in dinner to cook. So, yeah, The Steam Deck... I'm won over; I'm so won over. And I haven't even properly explored the fact that it has a full GNU/Linux desktop inside it that I can use as a desktop machine... Some of this is also true with gaming on the PS5; while it's easier to turn on and get going, and while I don't have a VR setup for it, I do have it in my head that it's more for \"epic gaming\" than quick casual stuff; see Death Stranding or Cyberpunk 2077 for example.&#160; &#8617;"},{"title":"When it doesn't just work","url":"/2023/12/08/when-it-does-not-just-work.html","date":"2023-12-08","content":"My journey into the Apple ecosystem has been gradual but all-consuming. I've gone from, around a 8 years ago , being unconvinced about how good the whole Apple world is, to pretty much having all the hardware they make available, in some form, that I have an actual use for 1 . One of the devices I was late to, but won over by, after moving away from Android to iPhone, was the Apple Watch. These days I have two: the original SE, and also a Series 8. Generally I've marvelled at just how seamless the experience is. I swap watches: the connection to my phone \"just works\" and it figures all that out. Stuff syncs. Stuff stays in sync. I lean heavily on the watch. The Series 8 is my daily driver, and the SE acts as my nighttime tracking device while the 8 charges and I sleep. I record walks. I record runs. I record lots of heart rate data. I pay for things, pretty much everything, with it. I... take it for granted really. Yesterday though, something odd started to happen. I noticed that some things didn't seem to be syncing from my watch to the phone. Health-related things weren't turning up. A recorded workout didn't show. The control of all things audio seemed to decouple and the watch kept taking over use of my AirPods from the phone in an annoying way I'd never experienced before. Things like that. I tried a reboot of the watch. Stuff turned up. It happened again. I tried a reboot of the phone. Stuff turned up. It happened again. I then rebooted watch and phone, stuff seemed fine, and I didn't think much more about it. Then this morning I swapped from the SE back to the Series 8 as I sat down for breakfast, my usual routine, and the syncing was failing again . This, for me, this is when Apple stuff gets really frustrating. There's no easy or obvious way to diagnose what's going on. Like: I could not sync some health data from the watch to the phone, but I could use \"Find My\" to ping the watch (presumably a difference in communication route, BT vs Wi-Fi perhaps). There's no obvious error dialog. There's no obvious log to look at. There's no \"your BT is borked\" alert or something. Searching online the advice seemed to be the nuclear option: unpair the watch, reset it, start again. So I've done that this morning and it's been quite the pain. Getting it set up again was straightforward enough, but having to go through the whole thing of dismissing all the \"here's some tips on how to use this watch you've had for a year and used every day\" cards was annoying, also having to set up my payment cards again was annoying. Also, and this is on me for not backing them up recently, trying to recreate my watch faces from memory and remembering which ones they were based on was also annoying. Apple are actually so good at a lot of this seamless shit; but damn do I wish they'd also be good at making a tool that lets you easily and smoothly diagnose some issues. I would imagine sync issues between watch and phone are common enough that a wee tool where you run through diagnostics, and where there's a Q&amp;A to help narrow down the issue, would be a great experience. Anyway... it seems to be up and running again, so hopefully that's that issue solved. I tried a couple of things that would need to sync from the watch to the phone and they showed up instantly; actually faster than I've been used to for quite a while. Fingers crossed... During a conversation about this at work the other week, I think I figured out that the only Apple product category in which I don't own an example of the hardware is displays 2 . :-/&#160; &#8617; When the VisionPro comes out I'll be able to say there's two.&#160; &#8617;"},{"title":"Fender Mustang Micro","url":"/2023/11/05/fender-mustang-micro.html","date":"2023-11-05","content":"The urge to go gadget crazy, when getting a new hobby, or reviving an old one, is a real thing. Having recently bought the new guitar with a view to trying to learn to play properly, it's something I'm very mindful of and doing my best to avoid. However, in the middle of the week I did crack and buy one little extra thing: As I said in the previous blog post about the guitar: I ended up getting something that could be played acoustic without being annoying for neighbours, which in turn meant I didn't need any sort of amp, or pedals, etc. This has been working out just fine. But early last week, in an idle moment, I was looking up what might be good options for a small amp for practising should I want to and I stumbled on the Mustang Micro . Reading up on it and checking out some reviews, it sounded perfect for my setup. I enjoy living in a small space, so could do without a proper amp kicking about, so something that just plugs right into the guitar sounded ideal. I added it to a list of things to keep in mind and then... a couple of days later I was working from home which meant I'd be about to receive a delivery if I was to place an order and... oops! I've been using it every day since it turned up and I'm so damn impressed! This thing might be small, but it's pretty mighty! For a complete notice like me, to muck about, and fiddle and get some great sounds out of it, I couldn't have asked for anything more. The range of amp styles is way more than I could possibly do justice right now, but what's important for me is it's got versions that are nice and clean, and versions that are dirty and distorted. The effects are pretty much spot on too; there's everything I could ever possibly want there. My only real complaint about it is that the UI itself -- small lights that use colour to indicate their setting -- is terrible. I don't know how else they could have done it, but I know this is bad. I am at least grateful that it's standalone and doesn't require some app on a phone to control or something like that. I know it's going to take a while for me to get the most out of this, but already it's giving me a bit more confidence to experiment and doodle away in idle moments. Also, the USB connection means it can be plugged into my Mac, presumably allowing me to record with GarageBand or similar software. While I wouldn't use it to subject anyone to my terrible playing, that will be something for me to explore in terms of keeping a record of my progress."},{"title":"Evolve Words","url":"/2023/10/31/evolve-words.html","date":"2023-10-31","content":"This follows on from my previous post . If you've not read that, it's worth having a dive in first for the background. The Ruby code I mention, that was written back in 2008, was actually a pair of scripts. The first one, called selection , did what visual-selection does, only visual-selection does it with a nice TUI interface: it takes a random collection of letters and symbols and evolves them into a target phrase. As covered before: I don't remember all of the details of the conversation that was going on at the time, but I do seem to remember something along the lines of \"yes, but you start out and end up with something the same length\" and \"nothing more complex is made\" (let's gloss over the whole \"complex\" thing for now... well okay let's just gloss over it, end of story; this is just a fun coding exercise). What I do remember is that the seed of an idea was planted. Fine: how about I start off with one small word, and using a list of English words as the \"fitness landscape\" that the mutations had to survive in, mutate a population over and over and see what happens. Would I \"randomly\" create known words, with fewer letters, with the same letters, with more letters? So this version of the code randomly did three forms of mutation: it would randomly flip a letter, or randomly delete a letter, or randomly insert a random letter. It would do this over and over and eliminate words that aren't in the original list (the simple form of selecting for survival within the landscape). Like I said last time: never going to convince anyone of anything, but fun to write some code. This version became selection2 . So, having turned selection into a TUI application with Textual, I had to do the same with this code... As before, because it's fun to do so, this leans heavily on the worker API and textual-plotext . If you want to check out the app itself there's a GitHub repo and it can also be installed from PyPi using pipx ."},{"title":"Visual Selection","url":"/2023/10/26/visual-selection.html","date":"2023-10-26","content":"Over the last few weeks I've had a couple of sessions of working on a library to wrap Plotext -- a popular terminal-based plotting library for Python -- so that it can easily be used in Textual apps; textual-plotext is the result. I feel it's come together pretty well But... I've been itching to find a reason to use it in a project of my own. Meanwhile... Back in the mid-2000s, when phpBB systems were still the fashion, I used to hang out on a site that was chiefly aimed at the atheist and secular humanist crowd. We'd get a good number of drive-by YEC types who'd want to argue (sorry... debate) and often talk nonsense about biology and the like. Now, I'm no biologist, I'm no scientist, I'm just a hacker who likes to write code for fun and profit; so any time there was a chance to write some code to help illustrate an idea I'd jump at the chance. I forget the detail now -- this was back in 2008; 15 years ago as of the time of writing -- but one time I remember a conversation was taking place where someone was just flat out claiming that \"random mutation\" can only cause \"loss of information\" and could never lead to a \"desired result\", or some such thing. If you've ever had, read or watched those debates, you'll know the sort of thing I mean. So that got me thinking back then, could I write something that could give a simple illustration of how this doesn't quite make sense? So I had a little hacking session and came up with some Ruby code 1 that did what I felt was the job. You'd give it a phrase you wanted it to generate (a stand-in for the current \"fitness landscape\", in effect), it would then generate a totally random string of that length, and then would set about mutating it, finding mutations that were \"fitter\" than others (a stand in for selection), breed the best two so far (randomly copy one chunk from another to create a child), then repeat over and over. When I first wrote it I wasn't sure what to expect; would it ever finish given a reasonably large target string? It did. It was fun to code. It got posted to the BB and of course wasn't in any way persuasive to them (honestly I never expected it would be). I seem to recall it being hand-waved away with calls of there obviously being an intelligent designer involved 2 . Anyway, the \"meanwhile...\" in this: a few times this year I've thought it could be fun to rework this in Python (it's really not that complex after all; just a string-chopping loop really) and use Textual to put a fun UI on it. So, that's what I did, complete with textual-plotext plot: While, 15 years on, this isn't going to convince anyone of the underlying point, I think it does serve a good educational purpose. It shows that you can create a fun UI for the terminal, with Textual, with not a lot of code. It also shows off how you can easily create dynamic plots. Plus -- and I think this might be the really important one -- it shows you can write \"traditional\" tight-loop code in a Textual application and still have a responsive UI; all thanks to the worker API . The heart of the code for this application is this: environment = Environment ( &quot;This is the target string we want to create!&quot; ) while not environment . best_fit_found : environment . shit_happens () Sure, there's some detail in the Environment class, but you get the idea: while we've not hit the target, let life find a way . A loop like that would totally bog down an application with a UI without some other work taking place. With Textual and workers the resulting method in the application, complete with code to send updates to the UI, really doesn't look much different: @work ( thread = True , exclusive = True ) def run_world ( self , target : str ) -&gt; None : worker = get_current_worker () environment = Environment ( target ) iterations = 0 self . post_message ( self . WorldUpdate ( environment , iterations , * environment . best )) while not worker . is_cancelled and not environment . best_fit_found : environment . shit_happens () iterations += 1 if ( iterations % 1000 ) == 0 or environment . best_fit_found : self . post_message ( self . WorldUpdate ( environment , iterations , * environment . best ) ) if environment . best_fit_found : self . post_message ( self . Finished ( iterations )) I honestly think the worker API is one of the coolest things added to Textual and I so often see people have real \"woah!\" moments when they get to grips with it. Anyway... I've covered science, religion, and how Ruby is better than Python, so I'm sure I've annoyed almost everyone. Job done I guess. ;-) If you want to check out the app itself there's a GitHub repo and it can also be installed from PyPi using pipx . Expect it to be my tinker project of choice for a wee while; there's a couple of other things I'd like to add to it. Possibly unpopular opinion with some folk who will read this, but I've long been a fan of Ruby as a language and actually generally prefer it to Python.&#160; &#8617; Me, the coder. While utterly missing the point of a simple illustration, while apparently not understanding the concept of an analogy, I guess at least they felt I was intelligent?&#160; &#8617;"},{"title":"Constant Siri voice loss","url":"/2023/10/20/constant-siri-voice-loss.html","date":"2023-10-20","content":"This seems to have started with iOS 17, and I can't narrow down the how and the when of it happening, but over the last week or so I've found that every couple of days Siri seems to lose their voice. By this I mean the high quality voice that's used when they speak seems to disappear. I notice this when I ask my phone or headphones a question or to do something, and I get a really low-quality voice that speaks back to me. The voice itself seems to be a version of the voice I normally use, but like it's using an on-device much-cut-down version. If I go into the settings to check what voice is selected, it's the one I normally use, but it wants to download it again. Sure enough, once the download is complete all is good again. I've not kept track of when it happens -- and I think I should from now on -- but it feels like it happens every couple of days; I almost always notice it first thing in the morning, the first time I ask the phone or the headphones something. I hope it is some sort of iOS 17 weirdness and is gone when 17.1 turns up."},{"title":"A new guitar","url":"/2023/10/20/a-new-guitar.html","date":"2023-10-20","content":"This one has been brewing for a year, more or less. Now that I commute into and back from Edinburgh most days of the working week, I find myself walking past a couple of music shops. Seeing these reminds me of the days, back in my 20s, when I mucked around in a couple of bands and had fun making noises on a bass guitar. Since that time I've also owned a cheap six string electric, which is currently in storage (and has been since 2016) and an acoustic, which I have with me but I live in an apartment building and I'm not an arsehole so I never play it. So, yeah, walking past those shops has made me want to muck about on a guitar again. I've never properly learnt the guitar, I've just managed to learn enough chords to make some noises I like for my own amusement, but even then I've not picked one up since around 2016 and what little I do know is very rusty. Add to the above: earlier this year I was at a friend's and admiring her collection of bass and six string guitars and picked a couple up and realised I could not play anything. It had been too long, I'd lost most muscle memory and coordination, and what little knowledge I had. So this made me want to fix this even more. Given the apartment thing I decided on a plan: how about I get an eclectic, and then some sort of amplification that would always rely on headphones? Given such a setup I could knuckle down and try and learn properly. So, this week, being on holiday, I told myself I'd pop into Edinburgh one day and have a look at my options; perhaps even come home with something. Yesterday was that day. It didn't quite go to plan, but the outcome was that I ended up with something to play. So, on getting into the shop, and explaining what I was after and why to the chap in there, I tried the usual Stratocaster and Telecaster thing. Both were fine (I think I liked the feel of the Telecaster more in my hand). I had one eye on a Les Paul too, but never tried that. What I did see though was this rather lovely black Hfner. Now, of course, it's hollow body, so sort of has that acoustic thing going on. This isn't what I wanted for playing in an apartment. But I had to try it anyway. As soon as I started dabbling I was sold. The sound was enough that it would be easy to pick up and play without having to faff with amplification of any sort, on the other hand it was nowhere near as loud as my acoustic. I felt like it bridged the gap between easy to pick up, and versatile enough should I ever want to plug it into something. And... let's be honest: it was black. Sooooo black. I like black. Long story short... it had to come home with me! As mentioned earlier: most of my guitar stuff is still in storage, from when I moved to Scotland, but I did find my old tin of plectrums and the tuner. *(Yes, the tin was once mine and was once full; the early 90s were a different time)* I even found one of my old stands, that I've had since around 1991! So now it's set up in my living room, next to the PCVR rig, ready to go at a moment's notice. This is my plan now: each weekend I aim to put in at least an hour a day of practice, to try and get my fingers up to strength again, and to build up the muscle memory of where the strings are, to get the coordination between both hands, etc. I'm also going to be working through beginner's lessons from a tutor application. I'm going to treat this like I'm the complete novice I am and slowly work on improving. There's no end goal; other than just get proficient enough that I can muck about on my own and be happy that I can play the sorts of things I want to be able to play. Also, it's good to learn new stuff, especially new stuff that isn't just more coding."},{"title":"I got a YouTube play button!","url":"/2023/10/18/i-got-a-youtube-play-button.html","date":"2023-10-18","content":"According to YouTube I joined up on 2006-09-04. I don't think that's quite correct. I did have a Google Video account from very early on, and uploaded a couple of things, and it got ported to a YouTube account when Google discontinued the original video service and settled on YouTube post-purchase. So I guess, in some respects, it's kind of correct. For most of that time I had hardly anything on there. Couple of videos to do with the weather station I ran for a few years, some things related to my photography, couple of things related to hacking with code; that's about it. Then, a couple or so years back, when I got heavily into PCVR gaming, I started to record my gaming sessions and upload them . As of the time of writing there are 1,109 videos in the PCVR playlist, and around 1,300 videos on my channel in total. As for subscribers... eh, come on, few people are really interested in watching some old bloke stumble around in VR, and I was very late to the game anyway. But, apparently, around 350 lovely folk care enough about my nonsense to subscribe. Nowhere near enough for a YouTube play button, that's for sure. Only... I now have a play button! I mean, sure, I have to build it myself... ...but it's something to show for all my efforts, I guess. ;-) As for how I got it: presumably anyone/everyone with a YouTube account with some content got the offer of goodies (I also got offered free coffee, sausage rolls, socks, and a bunch of other stuff I've forgotten), and I was lucky to claim one of these almost the instant the email turned up. It's very likely the only YouTube play button I'll ever receive. I think it will take pride of place on my desk."},{"title":"LinkedIn is useless","url":"/2023/10/16/linkedin-is-useless.html","date":"2023-10-16","content":"I have a LinkedIn profile more by accident than on purpose. For most of that site's early days I just ignored it, even needing to go to the trouble of aggressively marking emails from it as spam as it seemed to want to turn itself into some sort of online networking cult, encouraging folk to send invites to their contacts, or worse . But after job-seeking in late 2017 the recruiter who found me the position I took up asked if I might join up and endorse him or some such nonsense and, at the time, I thought what the hell. Since then though I've mostly found it useless, and at times straight up horrific. Don't even get me started on how a previous employer's push to make everyone use their profiles as more company branding created a perfect pool for people to go phishing in, while at the same time IT were on a phishing-awareness push; a perfect illustration of how some people lose their minds when it comes to that site. The last year though, while working in a more FOSSy world, I've started to dip my toe back in when it comes to linking to what we're building with Textual. As such, I drop into the app once or twice a week and look to see what other folk might be talking about too. During a recent dip in I saw this: Huh! Okay! That... that's actually kind of sensible! While I'm nowhere near looking for anything else to do, showing off the public projects you care about seems like a good idea. GitHub repos can be a good CV, I believe. So I click through... And that's where it all falls apart. Pretty typical for LinkedIn I'd say. Name, description, obsession with skills, obsession with building up a social graph. But... No link to the repo. No. Link. To. The. Repo. O_o o_O I can't even."},{"title":"Going full Apple search","url":"/2023/10/14/going-full-apple-search.html","date":"2023-10-14","content":"For as long as I've had a smartphone -- so ever since the HTC Magic was released -- I've used whatever search tool Google have had available as my way of searching for stuff from my phone. Even when I made the switch to the iPhone, back when the iPhone 11 was around, I still installed and used the Google Search app. Since jumping ship from Android to iPhone, I've followed the usual track that some do of \"embracing the ecosystem\", and it generally has paid off. The more I lean into \"the Apple way\", the more stuff actually does work together and work together well (I won't say \"it just works\", because that can sometimes so very not be true, but really I do find that Apple's ecosystem is more coherent and more stable than the one Google provided). But searching for stuff... that stuck with the Google search app. So, more as an experiment than anything else, starting this morning I've removed the Google search app from the home screens of my iPhone and my iPad and I'm going to force myself to use Spotlight to do all my searching, and see how I get on with it. Of course, when it comes to searching for stuff on the web, it's not going to make a whole heap of difference; it's sill going to end up searching with Google, but I do like the idea of search leaning into what Spotlight knows about my stuff too. Also, on my phone at least, it has the added benefit of freeing up a slot in the dock at the bottom of the home screen."},{"title":"astare v0.8.0 released","url":"/2023/10/10/astare-0-8-0.html","date":"2023-10-10","content":"textual-astare is another Textual-based Python project that I've developed in the last year and I don't believe I've mentioned on this blog. Simply put, it's a took for viewing the abstract syntax tree of Python code, in the terminal. I've just made a small update to it this evening after someone asked for a sensible change I've been meaning to do for a while . When I first read the request I was going to look at it next week, when I have some time off work, but you know how it is when you sit at your desk and have a \"quick look\". So anyway, yeah, v0.8.0 is out there and can be installed, with the main changes being: Updated textual-fspicker Updated textual Made it so you can open a directory to browser from the command line. Made opening the current working directory the default. Tweaked the way dark/light mode get toggled so that it's now command-palette-friendly. I think the code does need a wee bit of tidying -- this was one of my earliest apps built with Textual and my approach to writing Textual apps has changed a fair bit this year, and Textual itself has grown and improved in that time -- but it's still working well for now."},{"title":"All green on GitHub","url":"/2023/10/01/all-green-on-github.html","date":"2023-10-01","content":"In about a week's time I'll have had a GitHub account for 15 years! I can't even remember what motivated me to create one now, but back in October 2008 I grabbed the davep account... ...and then made my first repo . My use of the site after that was very sporadic. It looks like I'd add or update something once or twice a year, but I wasn't a heavy user. Then around the middle of 2015 I seem to have started using it a lot more. This very much shows that during those years I was working on personal stuff that I was making available in case anyone found it useful, but also leaning heavily on GitHub as a ( a , not the ) place to keep backups of code I cared about (or even no longer cared about). Quite a lot of that green will likely be me having a few periods of revamping my Emacs configuration . The really fun part though starts about a year ago: It's pretty obvious when I started working at Textualize, and working on a FOSS project full time. This is, without a doubt, the most green my contribution graph has looked. It looks like there's a couple of days this year where I haven't visited my desk at all, and I think this is a good thing (I try really hard to have a life outside of coding when it comes to weekends), but I'm also delighted to see just how busy this year looks. I really hope this carries on for a while to come. Apparently, as of the time of writing, I've made 12,588 contributions that are on GitHub. What's really fun is the fact that my first contribution pre-dates my GitHub account by 9 years! This one's pretty easy to explain: this is back from when I was involved with Harbour . Back then we were using SourceForge to manage the project (as was the fashion at the time), and at some point in the past whoever is maintaining the project has pulled the full history into GitHub. My contribution history on GitHub is actually older than my adult son. I suspect it's older than at least one person I work with. :-/ 1 I'm informed that this isn't the case 2 ; apparently I'm either bad at estimating people's ages, or bad at remembering them; or both.&#160; &#8617; Although it's not too far off. :-/&#160; &#8617;"},{"title":"Mandelbrot Commands","url":"/2023/09/29/mandelbrot-commands.html","date":"2023-09-29","content":"I don't think I've mentioned it before on this blog, but some time back I decided it would be fun to use Textual to write a Mandelbrot explorer (simple Mandelbrot explorers have been another one of my favourite known problem to try an unknown thing problems). Doing it in the terminal seemed like a fun little hack. I started off with creating textual-canvas and then built textual-mandelbrot on top of that. Not too long back I added a \"command palette\" to Textual (I'd prefer to call it a minibuffer, but I get that that's not fashionable these days), but so far I've not used it in any of my own projects; earlier today I thought it could be fun to add it to textual-mandelbrot . Most of the commands I've added are trivial and really better covered by (and are covered by) keystrokes, but it was a good test and a way to show off how to create a command provider. Having started this I can see some more useful things to add: for example it might be interesting to add a facility where you can bookmark a specific location, zoom level, iteration value, etc, and revisit later. The command palette would feel like a great way to pull back those bookmarks. What I really liked though was how easy this was to do. The code to make the commands available is pretty trivial and, I believe, easy to follow. Although I do say so myself I think I managed to design a very accessible API for this. There's more I'd like to add to that (the Textual command palette itself, I mean), of course; this was just the start. Support for commands that accept and prompt for arguments would be a neat and obvious enhancement (especially if done in a way that's reminiscent of how commands could be defined in CLIM -- I remember really liking how you could create self-documenting and self-completing commands in that). All in good time..."},{"title":"Apple Design","url":"/2023/09/23/apple-design.html","date":"2023-09-23","content":"As someone who started out in the Android ecosystem when it came to smart phones -- starting out with a HTC Magic and going through a few different phones before settling on Pixels (until I finally jumped ship to iOS in 2020) -- I have to admit that there's always been something nice about the design of iPhones. iOS, less so... My first exposure to iOS was back in 2015 when I got an iPod , and I wasn't terribly impressed. It looked okay, but it felt so far behind Android in terms of functionality. Much has changed and improved since then. These days, 3 years into being totally consumed by the Apple ecosystem (one day I should write a post about how comprehensively I've moved over), I'm won over and I like how iOS works now. Except this... That thing where, when you're in one app, it will show the most useless link \"back\" to another app, and in doing so bump the time up and out of the way a little. Like, seriously, compare it to when the app link thing isn't there: Once you see it, you can't unsee it. After all this time you'd think they would have found a less janky way of doing this; perhaps even simply removed it (I can't remember the last time I needed or wanted the ability to go \"back\" an app like this, especially not with the bottom-of-screen swipe gesture being a thing). If nothing else you'd think that, by now, they'd have found a way of doing it that doesn't look so terrible. The \"eh, let's just shove it here\" approach that seems to be on display here almost reminds me of the \"time wiggle\" that used to mildly annoy me back on my iMac ."},{"title":"A map of my year in Obsidian","url":"/2023/09/11/a-map-of-my-year-in-obsidian.html","date":"2023-09-11","content":"Some time around late October or early November last year, around the time I started working at Textualize , I \"discovered\" Obsidian . While I didn't need another note-taking application (having gone through Evernote, trying to use Org , dabbling with a couple of other things and finally settling mainly on Apple Notes), I was quite taken by its style and ubiquity and the fact that it was, at heart, just a bunch of Markdown files. So quite quickly I started using it; not to replace Apple Notes (which is still my general note-taking tool of choice), but to keep work notes and a daily coding journal, the latter coming in useful for the quick end-of-day meetings we normally have. One of the things I was quite taken by was the graph. It was interesting and fun to see how each of my work days related to other work days, and what subjects kept getting pulled in, etc. So come the start of this year I had an idea: what would it be like to keep a personal vault, but one where I track things I've done. Not a journal as such (I do keep one of those too, have done for many years now, but that's for other far more important reasons -- perhaps I'll write about that one day too), just a daily record of stuff I've achieved, stuff I've actually done, the routine things and the exceptional things? What would that graph look like? While it's not the end of this year yet, here's how that's shaping up: Each of the yellow circles is a day, each of the blue ones is a tag of some sort. As you'd imagine, the size of the circles relates to how often that item is tagged. So I can see what proportion of my days so far this year have been tagged with being heavily involved with work: Likewise, if I want to see how many days this year have involved a significant spot of gaming: Ditto for days where I've done some coding on pet projects, or even some personal-time coding relating to work projects (it might be work, but it's also Free Software and I do like to support FOSS!) I sort of have a curated set of tags I apply, but I've not made it a strict set; if some new situation crops up that calls for a new tag I'll use it. Mostly though I try and keep the tags pretty general so lots of days can relate to the same general subject. Another thing I've done is tag each and every day with the day of the week, so while it's not really surprising to find that Sunday doesn't dominate over other days, I can see which days are Sundays and perhaps wander along the connections and see what I get up to: I don't quite know what I hope to get out of this, I don't really know if there's anything useful to be had here at all, but it will be interesting to look back over it at the end of the year. It also means that I'll have a directory hierarchy full of Markdown files, all tagged and filled with information, which I'll be able to grep and slice and dice and count and perhaps pull into a database and cross-reference with stuff and things. Or perhaps it's all just really me not having a good use for Obsidian but inventing one anyway. ;-)"},{"title":"Textual Query Sandbox Update","url":"/2023/09/10/textual-query-sandbox-update.html","date":"2023-09-10","content":"Since quickly hacking together textual-query-sandbox a few days back , I've made a bunch of small changes here and there. While most have been cosmetic and playing with some ideas, some have also been internal improvements that should make the tool work better. The most prominent change is one I pondered in the previous post, where I thought it might be interesting to have a small collection of playgrounds grounded together with a TabbedContent . So as of now the tool still has the original playground which had an emphasis on nested containers: There's now a playground with an emphasis on selecting widgets within containers 1 : There's also now a playground that has an emphasis on pulling out widgets based on ID and classes: The other change you will notice from the original post is the DOM tree shown in the bottom right corner. Note that that isn't there to show your query result (that's the bottom left panel), it's there to help picture how the DOM in the current playground hangs together, and will hopefully help in picturing the structure for when you write a query. I sense there's still a lot of fun things I could add to this, and I'm still keen on the idea of having the playgrounds \"soft coded\" in some way, so people can make their own and load them up. Another thing I want to try and work on is making the display as useful as possible. While I think it's actually pretty neat and clear, there's not a lot of space 2 available to show the playground and the results. Finding a good balance is an interesting problem. For a number of reasons this is turning into a really enjoyable tinker project. This is, of course, slightly nonsensical wording. Containers are widgets in Textual. Pretty much everything you see in your terminal is a widget, even a Screen is a widget.&#160; &#8617; A lot of this of course hinges on how big someone's terminal is. I tend to run a fairly high resolutions with the smallest font I find readable so my terminal windows are often pretty \"big\"; other people tend to have something much smaller in terms of cell with/height.&#160; &#8617;"},{"title":"Textual Query Sandbox","url":"/2023/09/01/textual-query-sandbox.html","date":"2023-09-01","content":"Sometimes I can have an idea for a Textual widget, library or application on my ideas list for weeks, months even, before I get around to it -- mostly just due to not having the clear time to make a run at getting it going -- and then other times an idea can pop into my head and it has to be created there and then. Has to be! This happened yesterday evening. While the tool I built is something I'd thought of before (back around November last year I think) it hadn't even made it to my \"list of stuff I should make\" that I keep in Apple Reminders; not sure why really. But then yesterday evening a question cropped up on the Textual Discord server that related to the subject and I was reminded of it. The subject being: Textual DOM queries . I like to think that DOM queries in Textual are pretty easy to do, and well-explained in the docs, but it's fair to admit that they need a bit of practice first, just like any powerful tool. So I was reminded that I'd wanted to write a sandbox application, that would have a practice DOM inside it, an input field to type in a query, and a way of displaying the results. So textual-query-sandbox was born! In this very first version (which was really quickly put together -- it was something like 15 minutes to write the main code and then probably 45 minutes tweaking styles, adding all the admin stuff to allow deployment to PyPi and writing the README) there's an Input , a display of a group of nested containers with different IDs and classes, and then a Pretty widget at the bottom to show the query result. If you think this looks like it might be useful to you, it can be installed using either pip or (ideally) pipx : $ pipx install textual-query-sandbox and then you can run it with: $ tqs At which point load up the Textual query docs, type queries into the input field, hit enter and see what gets highlighted and which widgets end up in the result set at the bottom of the screen. Like I say: this was a quick hack yesterday evening, I think there's a lot more can go into this. For one thing I think a more interesting practice DOM would be a good idea, with a good mix of widgets; another thing could be having a collection of different DOM playgrounds that can be switched between (a TabbedContent of different playgrounds could be fun here); this could even be taken further such that the user can create their own playground DOM to practice against. Eventually it would be neat if this could be turned into a library that can be included in a Textual application, as a development-time debug tool, so that on-the-fly test queries can be made. For now though, it's started, it's under way, and I think the current version probably covers 90% of the use cases for something like this; making for a really quick and easy tool to double-check how to query something."},{"title":"Mythos: Ragnarok (plus Oppenheimer)","url":"/2023/08/27/mythos-ragnarok.html","date":"2023-08-27","content":"And I'm done! While it did only turn out to be one a week, I pulled it off , I managed to make it to at least one Fringe show per week! Yesterday was a full, busy, and hugely enjoyable day. While it could have just been a dash into town to see the show and back home again, in conjunction with Marille (who first introduced me to the Mythos show ) we arranged to go watch Oppenheimer first (amazing, easily the fastest any combined 3 hours have passed for me -- I'm not even going to try and write up anything about this, other than I was utterly enthralled by the movie from start to end), grab some dinner, then go and see Mythos: Ragnarok . With a wee bit of shopping thrown in along the way. As I've mentioned before, I first saw Ragnarok last year. Then they were in a fairly small venue, with a pretty full crowd. At the end they talked about how the first night they'd played the audience had been a single person; over the nights of the run it had slowly grown, and by the end of the run (we went on the last night) it was getting properly busy. This year they were in a much bigger place , with a lot more seating, and the house was full. This did make it feel a little less intimate than last year, and also last year we were sat all around the stage, which worked well for the performance; this time around it was a more traditional stage at the front, seating all on one side thing. I was really pleased for them that they were in a much bigger place, but I did miss the layout from last year. As for the show itself... just as fantastic. There seemed to have been some tweaks and changes to how the story was done over what I remember from last year, but mainly it was the same. The energy in the performance was incredible, and the comedy was spot on, with a lot of nods and winks to the audience. This is the part that I think I enjoy most: they know what they have, they know what they're doing, they know what they have on offer. It's a high-energy play performed by stunt people. It's amazing. As I write this there's one last show, I believe, tonight; so the chances of anyone reading this and getting to see it are very remote. But if they're back next year, and you're reading this near then and wondering about Fringe shows, do it! Really, do it. You won't regret it. I'll be going again. No question."},{"title":"Seen by davep broke (again)","url":"/2023/08/20/seen-by-davep-broke-again.html","date":"2023-08-20","content":"Almost seven years ago I took up maintaining an ad-hoc photoblog again. I say again because I'd had one once before. I'd kicked that off back in the late 200xs, with my little HTC Magic, and hosted it on Posterous . Eventually Posterous was shut down, mostly because the company (or at least the team behind it)) had been bought up by Twitter . When kicking off the blog this time I decided on a few things: I'd host it on Blogger.com; it had been around for long enough, and of course Google could be trusted to keep something that big up and running for good . I'd keep multiple backup copies of the images and file them in useful ways (I keep copies in Google Photos, on Google Drive, on iCloud and locally). As much as possible I'd automate the process of doing some, if not all of this. At this point, while it was kind of old as an idea, this felt very much like one of those things that was perfect to do in a Web 2.0 way; the good old reliable mashable web ! So the plan became this: Every post would be a tweet, posted to Twitter with a #photoblog tag. I'd use ifttt to keep an eye on my tweets and when it saw one with that tag it would extract the image, make a post to Blogger, drop a copy into Google Drive, and do a couple of other things too. Every week or so I'd do some manual checks to make sure everything is looking okay. This worked. Mostly. It ran fine for a few years, with very few problems. I'd take a photo, manipulate the heck out of it for the emotional effect I was going for (that was the point of the blog; it was all about the messing with the image), tweet it, and Web 2.0 magic would happen. Then the odd issue started to crop up. At one point Twitter made changes to how images were stored, or something, and the ifttt recipe broke for a wee while; then they changed the way that public posts could be seen (long before the Musk-era bullshit) and that broke things again, and so on. I forget the details but at every point I was able to nurse it back to life and things carried on. Recently, of course, it all fell apart when Musk took over Twitter and massively ruined it, turning it into the steaming pile it is now 1 . I've honestly lost track of which change broke what, and of course I also gave up even trying to use Twitter (the drip, drip, drip of right-wing hate politics got to a point where I could not find a way to make it work any more). So that's when I decided to cut Twitter out altogether. This had actually started a little earlier than that, when the whole API fiasco kicked off. When that came in ifttt had to remove Twitter things from its free tier; I was on the free tier. I was on the free tier only because I didn't need anything the paid service offered. If Twitter had been \"normal\" and this change had been made I'd have happily paid -- I don't mind paying for things I find useful. But, nope, given all the context, I bailed. So by that point I decided the easiest thing to do was to simply hand-add posts to Blogger, and also along the way post to a pixelfed account instead , reposting those posts from my Fosstodon account . Not ideal, needing more manual input, but also I was thinking that once I find a good flow I could probably automate the whole thing again. Anyway, that's the point I'd reached. Twitter was 100% out of the workflow, there was a bit more manual intervention, but the primary location for the photos was still getting updated. Then yesterday I noticed this: I don't actually quite know exactly what's going on here, and at this point I really don't care. My working hypothesis is this: when ifttt added the images to the Blogger posts, it was doing so in a way that it was using the image hosted by Twitter. Because of this, either due to some change in the Twitter API, or perhaps because I've locked down my Twitter account, the images can't be served any more. That's my best guess anyway. I don't really care to dig deeper than that. But, yeah, this is another example of the long-growing rot of the dream of Web 2.0. I'm not surprised; I'm not angry; I'm just disappointed. Thankfully I have all the images saved (see backup options above), so I can go back and edit the posts and drop fresh copies of the images into them. There's 100s of posts affected so this is going to take quite a while; I mean, sure, I could probably do it in a day if I sat and did nothing else, but I have other things to do. Another option would of course be to create a fresh blog using my own tools; that would be simple enough. I have the images, they're all set with the right date and time, recreating things would be fairly trivial (post titles a slight problem but I could work around that); a tool like mkdocs or Pelican plus some Python code to recreate the posts from the images would be a fun couple of hours mucking about. But... I have a lot of posts on Blogger and all the URLs are stable and still there many years later. Perhaps I could automate the \"fixing\" of the broken posts? I wonder what the Blogger API is like to work with? PS: If you've read this and feel that what's really needed is a \"helpful\" comment that self-hosting is the solution; please sit on that and read the above again (and, you know, look over the rest of this blog and the entirety of my time and content on the Internet in general and the Web in particular, going back to the mid-90s). Seriously, if you are reading this and you're still maintaining a Twitter account that you actively use, what the hell is wrong with you? Multiply that lots if you have a blue tick.&#160; &#8617;"},{"title":"Little Shop of Horrors at the Fringe","url":"/2023/08/19/little-shop-of-horrors-at-the-fringe.html","date":"2023-08-19","content":"As mentioned just over a week back , last night I went to see a Fringe show that was a production of The Little Shop of Horrors . Before going I had no idea what to expect (in terms of how it would be done, not what the content would be): I wasn't clear if it would be a really small affair, or something on a bigger stage with reasonably high production values (what can I say? It was LSoH, it was a Fringe show, it was booked knowing nothing else). When we got there and got into the venue it was... small, oh so very small! No real set to speak of. The cast who were about to kick off the performance didn't really seem to have much of a costume going on. So, without judgement, I settled down to expect the next 90 minutes or so to be... a Fringe experience. First impressions were oh so wrong! While there was (for obvious reasons) a lack of any real set, the effort that went into the performance really worked and I absolutely enjoyed every single moment. Also, because it was a production of the musical (which I haven't seen), rather than an adaption of the movie (which I have), I got to experience a fresh ending (spoilers!). The seats were uncomfortable. The room was down in the basement, with no ventilation, and so was uncomfortably hot. Physically it wasn't a great space to be. And yet I really wasn't wishing for it to be over. I think that says a lot about the show itself. I think special mention has to be given to the Audrey II models, of which there were three different sizes. Someone put some real effort into them. So, yeah, a fun night, topped and tailed with pre-show dinner and post-show drinks with friends. I couldn't have asked for more. Unless I last-moment book anything else over the next week, there's one more show to go in my push to go and see at least one show per week of the Fringe . PS: Sadly no photos. I wasn't sat in a great spot to take photos."},{"title":"Mythos: Ragnarok booked","url":"/2023/08/15/mythos-ragnarok-booked.html","date":"2023-08-15","content":"That's a third show booked! This means that, as I hoped , I'm going to manage at least one show a week for the Fringe! Now, this one could be seen as a cheat, sorta, kinda. I've seen this show before. But I liked it so much last year I have to see it again! The odd thing about it was it's not something I would have gone for on my own, it's technically not really my thing, but I got talked into it and I'm so glad I was! So a year back Marille told me about this wrestling show at the Fringe and how she wanted to go but nobody else was interested and I was all \"yebbut wrestling though?\" and didn't think much more about it. Eventually though, after some persuasion (I mean, an hour or so at a show and some beers afterwards, how bad could it be really?), I agreed to go. I expected to find it meh. Holy shit was it so much fun! Like, seriously so much fun . I'd never realised that wrestling was the best way to tell the tales from Norse mythology; turns out that wrestling is absolutely the best way to tell the tales from Norse mythology. So we're off back again this year . All booked, not this weekend, the weekend after. There might even be a beer afterwards. Perhaps not quite so many as last year though."},{"title":"Website: Miscellaneous Stuff moved","url":"/2023/08/14/website-misc-stuff-moved.html","date":"2023-08-14","content":"This evening I've spent more time working on the planned complete remake of my personal website , in this case \"porting\" over many of the files that made up the old \"miscellaneous stuff\" section of the site. If I'm honest, most if not all of the things in there are no longer relevant (like: who really needs a shell script to make gnuplot plots from files pulled off a 1990s-era Garmin handheld GPS unit?), but I thought I'd keep them kicking around \"just in case\". One wee section I wasn't going to get rid of though was my scans of three pages from a UK magazine called Personal Computer News . These contain Grid Bike ; a game I wrote for the VIC-20, all in BASIC, and got published. For my efforts I got a huge cheque for 40! If that doesn't seem like much to you, trust me, to 1983 me this was huge . I bought a 16k RAM pack with the money. Funnily enough, while trying to improve some of the links in the text, I decided to see if there was now an archive online somewhere and, sure enough, there is: in the obvious place . This means that my web site isn't the only copy of my program on the net. If you go to the December 21st 1983 edition and turn to around page 84, there I am! At this point I'm almost tempted to try and get an emulator up and running and get the code going again. How much fun would it be to add a video to my YouTube channel , of me playing one of the very first games I wrote?"},{"title":"Unbored v0.6.0","url":"/2023/08/13/unbored-0-6-0.html","date":"2023-08-13","content":"Late on last year I wrote about a bunch of new things that I'd added to PyPi, things mostly kicked off by an early dog-fooding session we had at textual HQ . Since then I've been slowly doing my best to keep the applications up to date with Textual. As much as possible we try and not make breaking changes with the framework, but at the same time it is still 0.x software and there's still new ways of doing things being designed so there's going to be the odd break in approach now and again. Unbored , my kind of silly self-populating TODO list application, has been sitting atop Textual 0.20.x for a while now and earlier today I checked how it was getting in with 0.32.0 and... actually surprisingly okay. Not perfect, there were a couple of things that had suffered from bitrot, but it wasn't crashing. The main thing I needed to change was the ability to focus a couple of containers (they didn't used to receive focus by default, now they do so I had to tell them not to again), and that was about it. While I was in there I also updated the application so that I dropped the nifty little slide-in error dialog I'd made , and instead embraced the new Textual notification system . While the application itself is a bit silly, and likely of no real use to anyone, I feel it's a pretty good barometer application, helping me check what the experience is like when it comes to maintaining a Textual application and the needs to keep on top of changes to Textual. It goes without saying, I hope, that really you should pin the Textual dependency for your applications, and upgrade in a controlled and tested way; for this though it's less crucial and is a good test of the state of the ecosystem, and on the remote chance that anyone is using it, it'll be helpful to me if it does break and they yell."},{"title":"Website: Norton Guide information moved","url":"/2023/08/13/website-norton-guide-information-moved.html","date":"2023-08-13","content":"This morning I've spent a wee bit of time tinkering with the configuration of the planned complete remake of my personal website . As part of this I made an effort to \"port\" over a section of the site. The choice for the first section to move was easy enough: Norton Guides . Of all the parts of my old site, this is probably the most useful in terms of \"contains information that isn't generally available out there on the web elsewhere and some folk might find it useful\" . I mean, at some point in the past, someone edited the Wikipedia page for Norton Guides and linked to mine as a source. So getting that one back up and running as soon as possible made sense. I've not added every bit of Norton Guide code to the main page, instead just pulling over and tidying up what was there before. On the other hand, just hacking on Markdown makes it all so much easier so I may expand on it a bit. The really important part was moving over the file format details . This, I feel, is the information that people will be looking for, if anyone is ever looking. So, proper start made; there's content beyond the landing page. There's still a lot to weed out and move over, and I think there's a lot of tweaking and the like with the configuration to do too. But the ball is rolling now. Ever time I get a spare hour and the desire to sit at my desk I can pick a section, look it over, decide if it deserves to come over, and act on that. Heck, at this rate I might even end up with an actively-maintained website again!"},{"title":"Nick Harper at the Jazz Bar","url":"/2023/08/12/nick-harper-at-the-jazz-bar.html","date":"2023-08-12","content":"As mentioned about a week back , my first show booked for this year's Edinburgh Fringe was to see Nick Harper . It's been a long time since I've seen him; far too long. As best as I can tell the last gig I made it to was in 2009. Fourteen years. Shit's changed in that time, for me, for the world. O_o On first getting into town it was warm and crowded, with that fun \"town is doing festival shit\" vibe that I like, so I went and grabbed an ice cream to kill some time until the venue opened. I knew I was in the right spot when, as I stood on Chambers Street, enjoying the cooldown, the man himself dashed passed, guitar case in hand! When I got into the venue I grabbed a drink and tried to find a seat; most were taken; except for one right at the front and off to the side. So I grabbed it. Moments later Nick himself came over to say hello to the folk sat in this spot. We had a wee chat about how long it was since I'd last seen him, nattered about general stuff, and he said very nice things about my hat. The gig itself was fantastic. While I love his recorded work anyway, Nick's always been one of those artists who I enjoy most live. He's got this way of singing and playing guitar that fills whatever time he's got to play; never once have I ever found myself looking at my watch, wondering if it's near the end; or if I have it's because I'm worried it'll be over soon. A good number of the tracks he played I didn't recognise; at least two of them I know are from a new album that's coming, and I have to admit that when I do listen to his stuff it's the earlier works that tend to go into heavy rotation (I think the last album of his I bought was The Last Guitar ). But I loved everything I got to hear. I'll be diving back into his catalogue and also keeping an eye out for the new release. While there was only an hour for his slot, he did manage to get a couple of old favourites of mine in; I was delighted when he launched into By My Rocket Comes Fire , did a wonderful She Rules My World , and even squeezed in a quick Galaxy Song . All too quickly though, the hour was up. It was kind of fitting that many of the songs he did have on the set list were all about time (on purpose, I'm sure). I'm happy to say I got to say a quick thank you and goodbye and then it was time for me to head out of town again. Seeing Nick brought back a lot of good memories, and reminded me that I need to catch up on his more recent works. While most of his stuff doesn't seem to be on Apple Music (what can I say, I'm very online these days when it comes to music), I'm glad to see he's got a full Bandcamp , so I'll be paying that a visit! I hope he swings back this way some time soon, not during the Fringe, and with a proper long set. It's been too long since I got to enjoy him really going for it and having a ton of fun ."},{"title":"The HomePod fixed itself","url":"/2023/08/12/the-homepod-fixed-itself.html","date":"2023-08-12","content":"A couple of weeks back I mentioned home my main HomePod had got stuck installing 16.6 of the software that runs it. This situation persisted for days after writing that post and I kept promising myself that I was going to see if I could unstick it by removing it from the Home, doing a factory reset and adding it back again. Of course, during the week that followed, I never got round to that. You can imagine what it's like: no time in the morning, and by the time I get home in the evening I want to watch TV and use the HomePod as the speaker for the Apple TV, I don't want to be doing tech support shit. The following weekend... yeah, I kinda forgot. So, here I am, a couple of Saturdays on, it's early morning, I've had breakfast and I'm having coffee and I think it's the perfect time to do this. I hope the Home app my on iPad and... it's sorted! So, yeah, it looks like it somehow managed to unstick itself in the end. A quick test of some of the issues I was seeing suggested there was still an issue, for example asking for the temperature in the bedroom would still result in a \"working on it\" reply followed by it telling me it wasn't responding. A quick reset seems to have fixed that. I guess it's good to know: if it happens again, it'll keep on working as the speaker for my Apple TV, and it'll eventually sort itself out even if I don't muck about with a hard reset."},{"title":"The reboot begins","url":"/2023/08/11/the-reboot-begins.html","date":"2023-08-11","content":"And I'm off! This morning I spent a good amount of time going through the sources for the old version of davep.org and removing everything that won't be needed any more, and also building up a rough TODO list of things I may want to recreate as content. With that done, as mentioned earlier today , I started work on building the site around Pelican. Pretty quickly though I started to feel that that was going to be a bad choice. While Pelican felt like a perfect fit for this blog -- mainly because it seems to be very blog-oriented -- it was feeling a bit clunky for a general website that would have a handful of static pages at best; likely something I wouldn't be updating too often. So I put it aside and went on with my morning, doing normal Friday domestic stuff like the weekly supermarket shop. It was while I was out doing that that I realised the obvious answer: use what we use for the Textual docs and what's been used for label.dev : Material for MkDocs ! I've just spent about 40 minutes after lunch kicking that off and it was really straightforward. Of course the result is horrifically cookie-cutter in terms of its look -- such is the way that mkdocs-material sites end up looking out of the box -- but I don't much care about that; what's important is that I've got a placeholder page in place, and I've quickly built a framework for writing and publishing the content. So that's the plan: now that the welcome page is in place and there's something on my domain that looks like a working website again I can start to slowly drag in old content in a new format. Heck, if I'm careful I might even be able to retain some of the old URLs! Longer-term plans might involve finally sorting out https support (yes, even today, my site is http -only), and perhaps adding some sort of RSS feed so there's a record of when changes are made. After that... hopefully that'll be about it and perhaps the website will last another 22 years running on top of the same engine (actually that part should be easier because the \"engine\" is now local and it generates a static site). The question then becomes who'll last longer, the site or me?"},{"title":"Admitting defeat on my website","url":"/2023/08/11/admitting-defeat-on-my-website.html","date":"2023-08-11","content":"I've had davep.org since very late 1999. Initially it started as a domain used just for email; while I did have a website, around that time it was still hosted on my then-ISPs hosting service, with a mirror on a friend's web server. A year or so later I finally did a proper revamp of my website and finally settled on www.davep.org as the place to point people to. I think , when I made that move, that's when I decided to write my own website engine in php. It was fun. It worked. I didn't want to code backend stuff (I don't think the backend vs frontend distinction was even a thing we were talking about then) so hacking it together in an unholy mix of ruby to generate various static files that live in the filesystem and then php to turn them into actual HTML made sense. And it worked. I heavily maintained the site for many years; keeping the same engine, tweaking the styles, adding features and content. I figure some time around 2013 or 2014 I probably stopped being quite so active in messing with it, and then in the last 5 or 6 years I've pretty much neglected it. The neglect shows. Meanwhile... php has changed. Quite a lot. It's one of those languages I used back in the day and pay no attention to. Then earlier this week I noticed that there must have been an update on the host and huge parts of my site broke, lots of content missing, pretty much useless and dead in the water. I did briefly think about breaking out the latest and greatest php locally, setting things up to investigate what's going on, and seeing if I could breathe some more life into it; but really what's the point? So after all these years I'm finally admitting defeat. Right now, on the home page, I've just got a placeholder saying that bitrot finally ate my website and that I'm going to start again from scratch. That's my plan: given that I had a good experience moving this blog over to Pelican I think I'm going to build a new www.davep.org with Pelican. Where possible I'll try and drag some of the old content over, but I'm also going to use this opportunity to have a proper digital spring clean. There's no planned timescale for this, but this morning I've spent an hour or so over coffee, branching the repo for the site and pruning out all the stuff I know I won't need and don't want. I'll try and drop the odd update in here as things progress."},{"title":"Off to see Little Shop of Horrors","url":"/2023/08/10/little-shop-of-horrors.html","date":"2023-08-10","content":"I almost feel bad admitting this. For someone my age it feels like a thing you should not really admit, but here goes... I only saw Little Shop of Horrors for the first time back in 2020. Don't ask me why. I just... never got round to it. I've known plenty of people who have seen it and loved it. I had a girlfriend for a while in the late 80s who was obsessed with it. She, like plenty of people I know, would quote all the quotes from it. And yet... yeah, I never got round to seeing it. Until 2020. On first viewing it became really bloody obvious why so many people seem to love it. So you can imagine my delight when, earlier this week, I was fighting through the Edinburgh crowds to get to my bus home and I saw this: Oh yes please! Oh so yes please! Given my desire to try and take in a few more Fringe shows that I normally would , this year, this seemed like a perfect fit. It also solved the choice paralysis problem for at least one week (really, have you seen how much there is on offer?). So today I booked some tickets for myself and a couple of friends. Next week's \"try and see at least one Fringe show\" problem is solved: I'm going to go and see a performance of Little Shop of Horrors ."},{"title":"I turned it off and on again","url":"/2023/08/10/i-turned-it-off-and-on-again.html","date":"2023-08-10","content":"Following on from the previous entry , where I outlined a weird problem I'd started having with syncing Obsidian via iCloud, I finally decided to sit down and try and work out the exact flow of the problem. Today, for example, I'd created an entry in two different vaults on my phone while on the bus into work, and when I got to my desk the vault I use on my work machine had updated. However, when I got home this evening, the vault for my personal stuff hadn't updated on my home Mac Mini. I tried a few edits, in both vaults, on the iPhone, and nothing came through to the Mac. So... before I started really diving into things I decided to \"turn it off and on again\" -- the iPhone that is -- and when it came back I ran up Obsidian, which told me it wasn't allowed to access my iCloud drive! I took a moment to go into the settings to try and figure it out, didn't find what I wanted right away, then got to thinking that perhaps some of the phone's services were still spinning up, so I ran Obsidian up again (after killing it). Sure enough, this time, it saw my vaults. With both vaults open on my Mac I made edits to open entries and the edits started to flow . So, yup, looks like it was a simple case of \"turn it off and on again\" . Apple: #ItJustWorks ."},{"title":"Strange Obsidian sync issue","url":"/2023/08/08/strange-obsidian-sync-issue.html","date":"2023-08-08","content":"Since October last year I've been getting into using Obsidian . Not that heavily, not to the extent some people do, but just as a way to keep a daily journal of work-related things. Each day at Textual HQ we finish off with a chat about how our day has gone, stuff we're wondering about, etc, etc... So I don't lose tack of what I've been up to I keep notes and Obsidian is how I do that. One of the things I really like about it is how I can have iPhone, iPad and macOS versions on the go and have it all sync via iCloud. It generally works well. But in the last couple of days I've noted the oddest problem, and I've yet to pin down the exact flow. But it seems to be this: If I create or edit a note on my iPhone, it doesn't turn up on my Mac. If I create or edit a note on my Mac, it turns up on my iPhone. I think I might have seen variations on that theme but I've not made careful note -- normally I'm made aware of it when I'm trying to get something done. What's super weird is this: on the iPhone, if I create a note, and then go into the Files app and look at the iCloud folders for Obsidian, the file isn't there! It's there in Obsidian itself, I can move it about, edit it, etc, etc... but it's not in the \"vault\" as seen from the Files app. It's the last part that has be really puzzled. If I get to the bottom of this I'll try and remember to write up what I find. I suspect I'm going to need some proper clear time, without other distractions, and experiment with all the edit and sync options and see what works and what fails."},{"title":"Off to see Nick Harper","url":"/2023/08/07/off-to-see-nick-harper.html","date":"2023-08-07","content":"I've lived near Edinburgh for getting on well over 6 years now and, aside form the odd show here and there, I've never really done the Fringe. As in, really dived in. Since moving up here my life situation didn't quite allow for it and then the pandemic hit and... well, you can imagine. Every year I've been up here I've managed one show, at least, but this year I want to try and make myself get to a few. Maybe one per week. Possibly. Might not happen, but I'm going to try. What can I say? I don't live in Edinburgh, I'm not a big \"be out amongst people\" kind of person, and the activation energy to get on a bus into town vs what I can do in my little part of Scotland is a constant battle. But this year I'm going to try my best. This evening I've booked a ticket for an artist I've been a fan of since the 1990s: Nick Harper . I saw Nick quite a few times in the 200xs (see the image above, I think 2009 might be the last time I saw him!) and then my going to gigs tailed off somewhat (again, life stuff). So seeing that he's playing here for a few days was something I could not ignore. This weekend me can thank Monday me for committing him to doing something kinda sociable. I'm sure he'll be mad at me most of the day it's happening, but once it all kicks off and the music is flowing he'll be thankful. Right now, at this moment... I'm rather looking forward to it."},{"title":"HomePod Stuck Installing Update","url":"/2023/07/29/home-pod-stuck-installing.html","date":"2023-07-29","content":"I have three HomePods. I have a Mini in the kitchen and one in the bedroom. I then have one of the newer-gen \"big\" HomePods in the living room, which amongst other things is the speaker for my Apple TV device (yeah, I'm kinda Apple all over the place these days). This week there was an update to the software, updating to 16.6. The two Minis updated just fine. The big one, however, days later... It's been like this all the time since the update turned up. I've tried a reboot from the Home app. I've tried pulling the plug and plugging it in again. Nope. It just keeps sitting there like this. Meanwhile... it's working (more or less) fine. It's still playing music. It's still being the speaker for the Apple TV. It still answers most questions and performs most commands (most of the commands I give it are to add stuff to my Reminders). On occasion if I ask it questions about other devices in the apartment ( \"hey siri, what's the temperature in the bedroom?\" ) it'll do the \"working on it\" thing and then give up saying the thing wasn't responding. That seems to be about the worst of it. Having checked this online it looks like, annoyingly, the one option I have left is to do a full reset, removing it from my Home, doing a factory reset, and then setting it up again. I'm sure it's something that'll take 10 minutes or so; but it's an annoyance. Apple: #ItJustWorks ."},{"title":"Quiche Reader","url":"/2023/07/27/quiche-reader.html","date":"2023-07-27","content":"I can't quite remember where I found this this week, I think it might have been via a comment on some article on the orange site 1 , but I stumbled on a really handy bit of free (as in beer) software called Quiche Reader . It's really simple and I feel exactly the sort of thing I need. Over the years I've tried all sorts of \"save to read later\" tools and systems; be it things like Pocket, or tools now built into the browser these days, even adding URLs to Remember the Milk (back when I used that) or (these days) Apple Reminders. Nothing ever quite stuck. Normally I'd end up slapping stuff to read into these systems and then never reading them. Quiche Reader, so far, feels like the perfect approach. It's quite simple: if I see something I want to read a bit later I save it into the application (which will sync to my other devices via iCloud). Then, when I go to Quiche Reader, I have to read the article or delete it and move on. This is sort of what I'd do anyway, saving stuff up for months on end until one day I'd declare saved reading bankruptcy and then start the whole cycle again. Now I can look at the saved article stack and I'm forced to either read the thing, or be honest with myself that if I'm not gonna read it now, I'm probably never going to. It does have a \"pause\" facility (or something like that, I forget the name) where you can throw an article to the back of the queue; but even then that means it'll keep popping back to the top again. I'll see how it goes; but so far I feel like this is the best \"I'll save this to read later\" tool I've found yet. I know, I KNOW! But there's so few places left to aimlessly scroll on the bus now!&#160; &#8617;"},{"title":"Encouragement, I guess?","url":"/2023/07/21/encouragement-i-guess.html","date":"2023-07-21","content":"Anyone who was (un)lucky enough to follow me on Twitter back in 2020 will know that, starting January 1st that year, I set about losing weight. At the time I was very overweight and wanted to get into some sort of healthy state. By August that year I'd managed to drop 30kg and hit and then went a wee way under my goal. These days I'm back up a wee bit. Not much: generally about 5kg or so above that goal, most of that having turned up on the last 7 or 8 months (not exactly coincidental that it's happened in conjunction with the new job, the new work location, and the new commute). While it's no real cause for concern -- I'm still generally careful and still get plenty of exercise (normally walk around 35km a week, run 20km, get my 10k steps in every day) About a week back I decided that it was time to give myself a bit of breathing room, to try and at least drop a couple or kg; so with that in mind I set a lower daily calorie goal in my tacking app. When recording my weight first thing this morning (yes, I'm one of those people who records it every day and have for a few years -- it makes for interesting data!), this is what my calorie/stats tracker had to say: I guess it's putting a positive spin in things? (for the record, I'm 5.3kg above my absolute goal)."},{"title":"textual-canvas v0.2.0","url":"/2023/07/16/textual-canvas-0-2-0.html","date":"2023-07-16","content":"Given that for a good chunk of this year I've been a bit lax about writing here, there's a couple or so coding projects I've not written about (well, not on here anyway -- I have spoken lots about them over on Fosstodon ). One such project is textual-canvas . As the name might suggest, it's a \"canvas\" for Textual applications, which provides a pretty basic interface for drawing pixels, lines and circles -- and of course any other shape you are able to build up from those basics. I've just released a quick update after it was requested that I add a clear method to the Canvas widget ; a request that makes perfect sense."},{"title":"Cmd-Tab switcher on all screens","url":"/2023/07/14/cmd-tab-switcher-on-all-screens.html","date":"2023-07-14","content":"This week, on Monday gone in fact, we moved office. We've now got a bigger space and, as part of that, bigger desks. Somewhat (but not entirely) coincidentally the work desk will also convert into a standing desk 1 . Also also... I inherited a second screen for the desk too. Ever since the days of CRTs and video cards that supported it, I've been a fan of having at least a couple of screens in front of me, and now at my work desk I've got 3 (two external displays and the display of the MacBook Pro itself). This caused a slight problem though: horizontally there's quite the spread of things to look at. This is fine, mostly I'm looking at the screen that's in front of me; the MacBook is to the left and the \"second\" screen is to the right, both with \"other\" stuff on them. In front of me is Emacs and my browser, which I flip between lots. The problem is this: the MacBook needs to go to the left (because of physical layout), which means that despite me setting the screen in front of me as the \"main\" screen, the Cmd - Tab display (you know the thing: when you hit Cmd - Tab you see the icons of all your active applications) appears on the left-most display, which is the MacBook. Not great. If I'm looking at the right-most display, and want to switch using the keyboard, I've got to look over to the left, as a worst case. That makes for a lot of unnecessary head-swivelling. One quick Google later and Today I Learnt that the following pretty much solves the problem: $ defaults write com.apple.Dock appswitcher-all-displays -bool true $ killall Dock As the name of the setting would suggest: once done, the switcher appears on all displays. That's perfect. Although the work one is manual hand-cranked, not electronic button-push goodness like my new one at home .&#160; &#8617;"},{"title":"Dot Files","url":"/2023/07/11/dot-files.html","date":"2023-07-11","content":"While I'm still in blog-tinkering mode (long may it last!), I thought it might be handy to keep a page kicking around that has links to the small collection of \"dot file\" repositories I have. Like many people, I keep these in a central location (in my case up on GitHub ) so that I can very quickly spin up a familiar work environment on a new machine (new machines are something that doesn't happen too often, but it's always good to be able to get going quickly when it does). So, depending on browser type/size, either above here or off to the side, there should now be a permanent link to a page of links to those repositories . As I look at it now it's actually surprising to me how much of my \"comfortable\" environment is encapsulated in so few tools, and configured with so few collections of files. There are other tools I use a lot too, but most of them either have their own sync systems, or they have so few configuration options (and are likely in a format that isn't easy to grab/store) that it's not worth the bother. This feels like a good thing, really. One thing that's not amongst all of this, partly because it's not that interesting, but also partly because the repository is private, is a single bash script called myenv . On a new machine, once I've got enough of a setup that I can clone from GitHub, I drag this down and run the script and most of the rest of the environment follows. It's quite satisfying when I need to use it."},{"title":"New desk","url":"/2023/07/08/new-desk.html","date":"2023-07-08","content":"I moved into my current place back in August 2019, bringing with me a fairly small desk. Originally, many years back, I'd had a pretty big office with lots of office space but, upon moving up to Scotland back in 2016, I needed to go with something a lot smaller. Which was perfectly fine. Me and that desk wrote a lot of code. Me and that desk transitioned from one job to another , and then another . Me and that desk made it through the pandemic. It's been a good desk. But it was small. I'm in a place where I could spread out a fair bit again, but I also kept putting it off and putting it off. Earlier this year I decided that it was high time I actually upgraded; I also promised the desk to someone else who I know will get a lot of good use out of it; so finally earlier this week I put in the order for something bigger and fancier. Yesterday, with the help of a very good friend (thanks Marille!), I got the desk built and roughly in place, and then today I've been putting the desktop back together and adding extra bits. It's so nice to have more space to spread out, it's also nice to have a black desk again! (the last one was white because... reasons) But what's really exciting is that it transforms into a standing desk at the touch of a button. I've been trying it in the standing configuration today and, while I doubt I could do a whole day of coding with it like that, I'm already really liking it as a way of breaking up the time at the keyboard. On the days I work from home, or the days of my own where I get sucked into a personal project, I can absolutely see me swapping between the two states. All that's left now is to get used to it. The screens are ever so slightly further away, the height is ever so slightly different (although I can adjust it, of course, but what I've done is adjust the sitting position to a nicer one and that's going to take some getting used to), my iPad and Stream Desk are in just a slightly different location, etc, etc... So I'm sure there'll be a few days of sitting here and making small tweaks to the spot where things live. Before I know it I'll be used to it. It'll be \"my spot\"."},{"title":"Dark Waters","url":"/2023/07/06/dark-waters.html","date":"2023-07-06","content":"More than ever I'm listening to music while I work. Despite having grown up in the 80s, and so having a good vinyl collection, and then having got into buying all the CDs in the 90s and 00s, these days I have managed to embrace the \"just stream all the things\" approach. After a long time using Spotify I finally ended up migrating to Apple Music. One of the things I do find Apple Music does well is the whole \"you seem to like this, have you tried this?\" thing; which on occasion has resulted in a pretty neat rabbit hole of discovery. Earlier this year this happened with female-fronted Dutch goth/rock type bands . I don't even remember how that happened, but it's a thing that happened and I gleefully dived right in. I came away with a few names I didn't know before, but one album has really stuck in my head and, now that we're just over 1/2 way through the year, I feel it's the one that gets played more than anything else. This keeps creeping back to the top of things I'm playing; sometimes when I'm in \"bang on the keyboard lots\" coding mode (you know the sort of coding mode: where you don't have to think too much because you have a good plan for what you're doing, but you've got a lot of tapping away to do), plus also often while I'm in the car. I won't be the least bit surprised to find that this ends up being my most-played album this year. According to last.fm it's at the top of the albums I've played (in places where I have scrobbling set up) in the last 365 days."},{"title":"The switch has been made","url":"/2023/07/05/the-switch-has-been-made.html","date":"2023-07-05","content":"Well, it didn't take as long as I expected it to. Just yesterday morning I was giving Pelican a look over as a possible engine for generating my blog, having wanted to move away from Jekyll for a while now. Having tried it and liked what I saw to start with, I wrote about how I liked it and wondered how long it would take me to make the switch. By the evening I was making a proper effort to get the switchover started, and just a wee while earlier, before writing this post, the switch was made! The process of making the switch was roughly this (and keep in mind I'm coming from using Jekyll): Made a branch in the repo to work in. Removed all of the Jekyll-oriented files. Decided to set up Pelican and related tools in a virtual environment, managed using pipenv . Ran pelican-quickstart to kick things off and give me a framework to start with. Renamed the old _posts directory to content . Kept tweaking the hell out of the Pelican config file until it started to look \"just so\" (this is a process that has been ongoing, and doubtless will keep happening for some time to come). Tried out a few themes and settled on Flex ; while not exactly what I wanted, it was close enough to help keep me motivated (while rolling my own theme from scratch would seem fun, I just know it would mean the work would never get done, or at least finished). Did a mass tidy up of all the tags in all the posts; something I'd never really paid too much attention to as the Jekyll-based blog never actually allowed for following tags. Went though all the posts and removed double quotes from a lot of the titles in the frontmatter (something Jekyll seems to have stripped, but which Pelican doesn't). Tweaked the FILE_METADATA to ensure that the slugs for the URLs came from the filenames -- by default Pelican seems to slugify the title of a post and this meant that some of the URLs were changing. All in all I probably spent 6 or 7 hours on making the move; a lot of that involving reading up on how to configure Pelican and researching themes. The rest of it was a lot of repetitive work to fix or tidy things. The most important aspect of this was keeping the post URLs the same all the way back to the first post; as best as I can tell I've managed that. So far I'm pleased with the result. I'm going to live with the look/theme for a wee while and see how it sits for me. I'm sure I'll tweak it a bit as time goes on, but at the moment I'm comfortable with how it looks."},{"title":"Considering Pelican","url":"/2023/07/04/considering-pelican.html","date":"2023-07-04","content":"Since getting my blog editing environment set up on the \"new\" machine a couple of days back I've been thinking some more about moving away from Jekyll. Jekyll itself has served me well since I started this blog back in 2015 , but I was reminded again when installing it on the Mac Mini that it's Ruby-based and I have very little understanding of how to get a good Ruby experience on macOS 1 . Having mentioned on Mastodon that I was thinking about finally looking at moving my blog management/generation to something new , and specifically something Python-based and ideally some sort of site generator, I got a few suggestions. One that looks promising so far is Pelican . At first glance it seems to tick a few boxes for me: Python-based (so easy for me to grok in terms of installing, and also more chance of being hackable). Uses Markdown (curiously as an alternative, to reStructuredText, which looks to be the default). Does article-based stuff as well as page-based stuff. Lots of themes, and themes are Jinja2-based (I'm pretty familiar with Jinja thanks to my Django days and also using the library when kicking off ng2web ). RSS feed generation. Syntax-highlighted code blocks. While I'm not quite ready to dive in and make the move just yet (I am on a \"muck about at home\" holiday this week, but I've got enough planned without losing a day to rebooting my blog), I did do a quick experiment to see if Pelican would work for me. Key to this is can I keep the URLs for all the posts the same? If I can't that's a non-starter. Things got off to a good start with an easy install: $ pipx install &quot;pelican[markdown]&quot; I then used the pelican-quickstart to kick off a test site, copied in my existing Markdown files, dived into the docs and found how to configure the generated URLs and... yeah, within like 10 minutes I had a very rough version of my blog up and going. It looked like garbage, the theme really wasn't to my taste at all, but the core of the blog was working. I've nuked it all for now but a more considered evaluation is now on my TODO list. Things I'll need to drive into properly are: Find a base theme that's to my taste. Get Disqus working it so that any old comments remain in place. Get my image/attachment layout back in place. Go through and tidy up all the tagging (which has been a mess with this blog because I never did get round to getting Jekyll to actually use tags). Figure out the best way to do the publishing to GitHub pages. Likely a bunch of other stuff I've not thought about yet. But, yeah, for a brief \"over first coffee of the day\" tinker to see if I like it... I like! Let's see how long it takes me to actually get around to making the switch. ;-) When setting this up a couple of days back, I had to pin some packages for the blog to older versions because of Ruby version issues; I'm sure that Ruby has virtual environment solutions akin to Python, but diving into that just for one tool... nah.&#160; &#8617;"},{"title":"A new GitHub profile README","url":"/2023/07/03/making-my-github-banner.html","date":"2023-07-03","content":"Ever since GitHub introduced the profile README 1 I've had a massively low-effort one in place. I made the repo, quickly wrote the file, and then sort of forgot about it. Well, I didn't so much forget as just keep looking at it and thinking \"I should do something better with that one day\". Thing is, while there are lots of fancy approaches out there, and lots of neat generator tools and the like... they just weren't for me. Then yesterday, over my second morning coffee, after getting my blog environment up and going again , I had an idea. It could be cool to use Textual's screenshot facility to make something terminal-themed! I mean, while it's not all I am these days, so much of what I'm doing right now is aimed at the terminal. So... what to do? Then I thought it could be cool to knock up some sort of login screen type thing; with a banner. One visit to an online large terminal text generator site later, I had some banner text. All that was left was to write a simple Textual application to create the \"screen\" . The main layout is simple enough: def compose ( self ) -&gt; ComposeResult : yield Label ( NAME , classes = &quot;banner&quot; ) yield Label ( PRATTLE ) yield Label ( &quot;github.com/davep login: [reverse] [/]&quot; ) where NAME contains the banner and PRATTLE contains the \"login message\". With some Textual CSS sprinkled over it to give the exact layout and colour I wanted, all that was left was to make the snapshot. This was easy enough too. While the whole thing isn't fully documented just yet, Textual does have a great tool for automatically running an application and interacting with it ; that meant I could easily write a function to load up my app and save the screenshot: async def make_banner () -&gt; None : async with GitHubBannerApp () . run_test () as pilot : pilot . app . save_screenshot ( &quot;davep.svg&quot; ) Of course, that needs running async, but that's simple enough: if __name__ == &quot;__main__&quot; : asyncio . run ( make_banner ()) Throw in a Makefile so I don't forget what I'm supposed to run: .PHONY: all all: pipenv run python make_banner.py and that's it! Job done! From here onward I guess I could have some real fun with this. It would be simple enough I guess to modify the code so that it changes what's displayed over time; perhaps show a \"last login\" value that relates to recently activity or something; any number of things; and then run it in a cron job and update the repository. For now though... I'll stick with keeping things nice and simple. It was actually kind of annoying when they introduced it because the repo it uses is named after your user name. I already had a davep repo: it was a private repo where I was slowly working on a (now abandoned, I'll start it again some day I'm sure) ground-up rewrite of my davep.org website.&#160; &#8617;"},{"title":"Catching up","url":"/2023/07/02/catching-up.html","date":"2023-07-02","content":"So... erm... yeah... I did it again. I looked away for a moment and somehow almost 7 months passed without a post ! It's so easily done too isn't it? While, when I revived this blog last year , I didn't make a point of intending to write lots and often, I had hope that I'd manage something at least once a week; perhaps at least once a month. Ahh well. There's been two main reasons why it's been quiet around here. The first is that my (now not so) new job keeps me busy (in a good way). It involves a reasonable amount of trekking into town and back (which I don't mind on the whole), and once I'm home in the evening I'm generally (but not always) done with the keyboard and desk. The second reason, which is probably the dafter one, is that a bit earlier this year I finally upgraded my desktop setup from the 2019 Intel MacBook Pro I was using to a recently-released M2Pro Mac Mini (and what an upgrade!). How this plays into blogging being even more quiet is... I needed to set up jekyll again, and I'd forgotten how I got it running in the first place, so I kept putting off getting it going, and... Well, this morning, I sat down with coffee, grepped the history on my previous machine, and got it running in like 5 minutes (of course). So, here I am, back adding another blog post. I'm writing this as much to test that the setup works as anything else. But also, this time, I'm going to try and make a promise to myself: I'm going to try and write more. I can and should write about anything. I can and should write short things as well as long things. I can and should remember that it's not about writing things that are going to be super important or anything like that, it's about just getting stuff down and creating and recording. Note of course I said \"try\" and make a promise. We'll see. ;-)"},{"title":"OIDIA","url":"/2022/12/16/oidia.html","date":"2022-12-16","content":"Another little thing that's up on PyPi now, which is the final bit of fallout from the Textual dogfooding sessions , is a little project I'm calling OIDIA. The application is a streak tracker. I'm quite the fan of streak trackers. I've used a few over the years, both to help keep me motivated and honest, and also to help me track that I've avoided unhelpful things too. Now, most of the apps I've used, and use now, tend to have reminders and counts and stats and are all about \"DO NOT BREAK THE STREAK OR ELSE\" and that's mostly fine, but... To keep things simple and to purely concentrate on how to build Textual apps, I made this a \"non-judgement\" streak tracker. It's designed to be really simple: you add a streak, you bump up/down the number of times you did (or didn't do) the thing related to that streak, for each day, and that's it. No totals. No stats. No reminders and bugging. No judgement. Here it is in action: When I started it, I wasn't quite sure how I wanted to store the data. Throwing it in a SQLite database held some appeal, but that also felt like a lot of faff for something so simple. Also, I wanted to make the data as easy to get at, to use elsewhere, and to hack on, as possible. So in the end I went with a simple JSON file. On macOS and GNU/Linux streaks.json lives in ~/.local/share/oidia , on Windows it'll be in... I'm not sure off the top of my head actually; it'll be in whatever directory the handy xdg library has chosen. and because it's JSON that means that something like this: ends up looking like this: [ { &quot;title&quot; : &quot;Hack some Python&quot; , &quot;days&quot; : { &quot;2022-12-02&quot; : 1 , &quot;2022-12-03&quot; : 1 , &quot;2022-12-04&quot; : 1 , &quot;2022-12-05&quot; : 1 , &quot;2022-12-06&quot; : 1 , &quot;2022-12-07&quot; : 1 , &quot;2022-12-08&quot; : 1 , &quot;2022-12-01&quot; : 1 , &quot;2022-11-30&quot; : 1 , &quot;2022-11-29&quot; : 1 , &quot;2022-11-28&quot; : 1 } }, { &quot;title&quot; : &quot;Brush my teeth&quot; , &quot;days&quot; : { &quot;2022-12-02&quot; : 2 , &quot;2022-12-03&quot; : 2 , &quot;2022-12-04&quot; : 2 , &quot;2022-12-05&quot; : 2 , &quot;2022-12-06&quot; : 2 , &quot;2022-12-07&quot; : 2 , &quot;2022-12-08&quot; : 1 , &quot;2022-12-01&quot; : 2 , &quot;2022-11-30&quot; : 2 , &quot;2022-11-29&quot; : 2 , &quot;2022-11-28&quot; : 2 } }, { &quot;title&quot; : &quot;Walk&quot; , &quot;days&quot; : { &quot;2022-12-02&quot; : 1 , &quot;2022-12-03&quot; : 1 , &quot;2022-12-04&quot; : 1 , &quot;2022-12-05&quot; : 1 , &quot;2022-12-06&quot; : 1 , &quot;2022-12-07&quot; : 1 , &quot;2022-12-08&quot; : 1 , &quot;2022-12-01&quot; : 1 , &quot;2022-11-30&quot; : 1 , &quot;2022-11-29&quot; : 1 , &quot;2022-11-28&quot; : 1 } }, { &quot;title&quot; : &quot;Run 5k&quot; , &quot;days&quot; : { &quot;2022-12-03&quot; : 2 , &quot;2022-12-05&quot; : 1 , &quot;2022-11-30&quot; : 1 , &quot;2022-11-28&quot; : 2 } }, { &quot;title&quot; : &quot;Run 10k&quot; , &quot;days&quot; : { &quot;2022-12-03&quot; : 1 , &quot;2022-11-28&quot; : 1 } } ] Of course, it remains to be seen how well that actually scales; possibly not so well over a long period of time, but this was written more as another way to explore Textual than anything else. Even then, it would be pretty trivial to update to something better for holding the data. If this seems like your thing (and I will be supporting it and onward developing it) you can find it over on PyPi , which means it can be installed with pip or the ever-handy pipx : $ pipx install oidia"},{"title":"New Things On PyPi","url":"/2022/12/01/new-things-on-pypi.html","date":"2022-12-01","content":"An update So, it's fast approaching 2 months now since I started the new thing and it's been a busy time. I've had to adjust to a quite a few new things, not least of which has been a longer and more involved commute. I'm actually mostly enjoying it too. While having to contend with busses isn't the best thing to be doing with my day, I do have a very fond spot for Edinburgh and it's nice to be in there most days of the week. Part of the fallout from the new job has been that, in the last couple of weeks, I've thrown some more stuff up on PyPi. This comes about as part of a bit of a dog-fooding campaign we're on at the moment (you can read some background to this over on the company blog ). While they have been, and will continue to be, mentioned on the Textualize blog, I thought I'd give a brief mention of them here on my own blog too given they are, essentially, personal projects. gridinfo This is one I'd like to tweak some more and improve on if possible. It is, in essence, a Python-coded terminal tool that does more or less the same as slstats.el . It started out as a rather silly quick hack , designed to do something different with rich-pixels . Here's the finished version (as of the time of writing) being put through its paces: Download from here , or install and play with it with a quick pipx install gridinfo . unbored The next experiment with Textual was to write a terminal-based client for the Bored-API . My initial plan for this was to just have a button or two that the user could mash on and they'd get an activity suggestion dropped into the middle of the terminal; but really that seemed a bit boring. Then I realised that it'd be a bit more silly and a bit more fun if I did it as a sort of TODO app. Bored? Run it up and use one of the activities you'd generated before. Don't like any of them? Ignore them and generate some more! Feeling bad that you've got such a backlog of reasons to not be bored? Delete a bunch! And so on. Here's a short video of it in action: Download from here , or install and play with it with a quick pipx install unbored . textual-qrcode This one... this one I'm going to blame on the brain fog that followed flu and Covid jabs that happened the day before (and which are still kicking my arse 4 days later). Monday morning, at my desk, and I'm wondering what to next write to experiment with Textual, and I realised it would be interesting to write something that would show off that it's easy to make a third party widget library. And... yeah, I don't know why, but I remembered qrencode.el and so textual-qrcode was born! I think the most amusing part about this is that I did it in full knowledge that it would be useless; the idea being it would be a daft way of showing off how you could build a widget library as an add-on for Textual. But... more than one person actually ended up saying \"yeah hold up there this could actually be handy!\" If you're one of those people... you'll find it here . FivePyFive While I was on a roll putting stuff up on PyPi, I also decided to tweak up my Textual-based 5x5 and throw that up too. This was my first app built with Textual , initially written before I'd even spoken to Will about the position here. At one point I even did a version in Lisp . It's since gone on to become one of the example apps in Textual itself but I felt it deserved being made available to the world via an easy(ish) install. So, if you fancy trying to crack the puzzle in your terminal, just do a quick: $ pipx install fivepyfive and click away. You can find it over here . PISpy Finally... for this week anyway, is a tool I've called PISpy. It's designed as a simple terminal client for looking up package information on PyPi. As of right now it's pretty straightforward, but I'd like to add more to it over time. Here's an example of it in action: One small wrinkle with publishing it to PyPi was the fact that, once I'd chosen the name, I checked that it hadn't been used on PyPi (it hadn't) but when it came to publishing the package it got rejected because the name was too similar to another package! I don't know which, it wouldn't say, but that was a problem. So in the end the published name ended up having to be slightly different from the actual tool's name. See over here for the package, and you can install it with a: $ pipx install pispy-client and then just run pispy in the terminal. Conclusion It's been a fun couple of weeks coming up with stuff to help exercise Textual, and there's more to come. Personally I've found the process really helpful in that it's help me learn more about the framework and also figure out my own approach to working with it. Each thing I've built so far has been a small step in evolution on from what I did in the previous thing. I doubt I've arrived at a plateau of understanding just yet."},{"title":"Python and macOS","url":"/2022/11/05/python-and-macos.html","date":"2022-11-05","content":"Introduction On Twitter, a few weeks back, @itsBexli asked me how I go about setting up Python for development on macOS . It's a great question and one that seems to crop up in various places, and since I first got into using macOS and then subsequently got back into coding lots in Python it's absolutely an issue I ran into. With my previous employer, while I was the only developer, I wasn't the only person writing code and more than one other person had this issue so I eventually wrote up my approach to solving this problem. That document is on their internal GitLab, but I thought it worth me writing my personal macOS/Python \"rules\" up again, just in case they're useful to anyone else. I am, of course, not the first person to tackle this, to document this, to write down a good approach to this. Before and after I settled on my approach I'd seen other people write about this. So... this post isn't here to try and replace those, it's simply to write down my own approach, so if anyone asks again I can point them here. I feel it's important to stress: this isn't the only way or thoughts on this issue, there are lots of others. Do go read them too and then settle on an approach that works for you. One other point to note, which may or may not make a difference (and may or may not affect how this changes with time): for the past few years I've been a heavy user of pipenv to manage my virtual environments. This is very likely to change from now on, but keep in mind that what follows was arrived at from the perspective of a pipenv user. So... with that admin aside... The Problem When I first got back into writing Python it was on macOS and, really early on, I ran into all the usual issues: virtual environments breaking because they were based on the system Python and it got updated, virtual environments based on the Homebrew-installed Python and it got updated, etc... Simply put, an occasional, annoying, non-show-stopping breaking of my development environment which would distract me when I'd sat down to just hack on some code, not do system admin! My Solution For me, what's worked for me without a problem over the past few years, in short, is this: NEVER use the system version of Python. Just don't. NEVER use the Homebrew's own version of Python (I'm not even sure this is an issue any more; but it used to be). NEVER use a version of Python installed with Homebrew (or, more to the point, never install Python with Homebrew). Manage everything with pyenv ; which I do install from Homebrew. The Detail As mentioned earlier, what I'm writing here assumes that virtual environments are being managed with pipenv (something I still do for personal projects, for now, but this may change soon). Your choices and mileage may vary, etc... This is what works well for me. The \"one time\" items These are the items that need initially installing into a new macOS machine: Homebrew Unless it comes from the Mac App Store, I try and install everything via Homebrew . It's really handy for keeping track of what I've got installed, for recreating a development environment in general, and for keeping things up to date. pyenv With Homebrew installed the next step for me is to install pyenv . Doing so is as easy as: $ brew install pyenv Once installed, if it's not done it for you, you may need to make some changes to your login profile. I'm a user of fish so I have these lines in my setup . Simply put: it asks pyenv to set up my environment so my calls to Python go via its setup. Plenty of help on how to set up pyenv can be found in its README . Once I've done this I tend to go on and install the Python versions I'm likely to need. For me this tends to be the most recent \"active\" stable versions (as of the time of writing, 3.7 through 3.10; although I need to now start throwing 3.11 into the mix too). I use this command: $ pyenv install --list to see the available versions. If I want to see what's available for a specific version I'll pipe through grep: $ pyenv install --list | fgrep &quot; 3.9&quot; This is handy if I want to check what the very latest release of a specific version of Python is. The \"Global\" Python When I'm done with the above I then tend to use pyenv to set my \"global\" Python. This is the version I want to get when I run python and I'm not inside a virtual environment. Doing that is as simple as: $ pyenv global 3 .10.7 Of course, you'd swap the version for whatever works for you. When Stuff Breaks It seems more rare these days, but on occasion I've had it such that some update somewhere still causes my environment to break. Now though I find that all it takes is a quick: $ pyenv rehash and everything is good again. Setting Up A Repo With all of the stuff above being mostly a one-off (or at least something I do once when I set up a new machine -- which isn't often), the real \"work\" here is when I set up a fresh repository when I start a new project. Really it's no work at all. Again, as I've said before, I've tended to use pipenv for my own work, and still do for personal stuff (but do want to change that), mileage may vary here depending on tool. When I start a new project I think about which Python version I want to be working with, I ensure I have the latest version of it installed with pyenv , and then ask pipenv to create a new virtual environment with that: $ pipenv --python 3 .10.7 When you do this, you should see pipenv pulling the version of Python from the pyenv directories: $ pipenv --python 3 .10.7 Creating a virtualenv for this project... Pipfile: /Users/davep/temp/cool-project/Pipfile Using /Users/davep/.pyenv/versions/3.10.7/bin/python3 ( 3 .10.7 ) to create virtualenv...  Creating virtual environment...created virtual environment CPython3.10.7.final.0-64 in 795ms creator CPython3Posix ( dest = /Users/davep/temp/cool-project/.venv, clear = False, no_vcs_ignore = False, global = False ) seeder FromAppData ( download = False, pip = bundle, setuptools = bundle, wheel = bundle, via = copy, app_data_dir = /Users/davep/Library/Application Support/virtualenv ) added seed packages: pip == 22 .2.2, setuptools == 65 .3.0, wheel == 0 .37.1 activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator  Successfully created virtual environment! Virtualenv location: /Users/davep/temp/cool-project/.venv Creating a Pipfile for this project... The key thing here is seeing that pipenv is pulling Python from ~/.pyenv/versions/ . If it isn't there's a good chance you have a Python earlier in your PATH than the pyenv one -- something you generally don't want. It will work, but it's more likely to break at some point in the future. That's the key thing I look for; if I see that I know things are going to be okay. Conclusion Since I adopted these personal rules and approaches (and really, calling them \"rules\" is kind of grand -- there's almost nothing to this) I've found I've had near-zero issues with the stability of my Python virtual environments (and what issues I have run into tend to be trivial and of my own doing). As I said at the start: there are, of course, other approaches to this, but this is mine and works well for me. Do feel free to comment with your own, I'm always happy to learn about new ways!"},{"title":"Build in public, even in private","url":"/2022/10/06/build-in-public-even-in-private.html","date":"2022-10-06","content":"As mentioned yesterday , I'm about to start working at Textualize , and building Open-source software is important to the company. Will -- the CEO -- is all about building in public. If you follow him on Twitter you'll notice that his Python coding adventure tweets actually outnumber is cooking tweets! As someone who has long been a supporter of and fan of Free Software and Open-source software , and has made some small contributions along the way, I've also always made a point of building my own tools in public . In most cases they're things that are likely only helpful to me, but some are more generally useful. The point being though: it's all there in case it's helpfull to someone else. Which means that, as much as possible, when I'm writing code, I write it as if it's going to be visible in public and someone else is going to be reading it. I try and make the code tidy. I try and comment it well. I try (but don't always manage for personal projects) to fully document it. The important thing here being that someone coming to the code fresh should be able to follow what's going on. Against that background, and having just gone through the process of handing off almost 5 years of work to someone else as a left an employer, I got to thinking: we should always \"build in public\", even if it's in private. When I started with my previous employer, and even to the day I left, I was the only software developer there. I worked with a team who wrote code, but being software developers wasn't what they did. Bioinformaticians and machine learning scientists have other things to be doing. But, as I wrote my code, I wrote every line assuming they, or some other developer down the line, would be reading it. Pretty much every line was written for an audience I couldn't see and didn't fully know. This, as mentioned above, meant trying to keep the code clean, ensuring it was commented in helpful ways, ensuring the documentation was helpful, and so on. But it wasn't just about the code. Any non-trivial system will have more to it than code. We had an internal instance of GitLab and I tracked all of my work on there. So, as I planned and worked on new features, or went on bug hunts, I'd document the process in the issue tracker. As much as possible I'd be really verbose about the process. Often I wouldn't just open an issue, go work on it, and then mark it closed; as I worked through the issue I'd add comment after comment under it, documenting my thinking, problems, solutions, cite sources when looking something up, that sort of thing. The whole process was an act in having a conversation with current or future team members if they ever needed to look; with future me (really, that helped more than once -- we all have those \"that the hell was I thinking?\" moments); with any developer(s) who took over from me in the future. I did all this as if I was broadcasting it in public on Twitter or on GitHub , etc. It was in private, of course, but I approached it as if it was in public. There were always three main reasons for this, I felt: Accountability. At any moment someone who I worked with could review what I was doing and why I was doing it; it was an invitation to anyone curious enough to talk with me about what I was building and how I was building it. Continuity of support for unplanned reasons. Life happens, sometimes you may, unplanned, never be available at work again. I never wanted to leave my employer in a position where picking up from such an event was a nightmare. Continuity of support for planned reasons. It was possible, and it became inevitable, that I'd move on to something else. If that was to happen I wanted to be sure that whoever picked up after me would be able to do so without too much effort. In the end item 3 seemed to really pay off. When it came time for me to hand over my work to someone else, as I left, the process was really smooth and trouble-free. I was able to point the developer at all the documentation and source code, at all the issues, and invite them to read through it all and then come back to me with questions. In terms of time actually spent talking about the main system I was handing over I'd say that 4 years of work was handed over with just a few hours of actual talking about it. It remains to be seen if it really paid off, of course. If they get really stuck they do have an open invitation to ping me a question or two; I care enough about what I designed and built that I want it to carry on being useful for some time to come. But... I like to think that all of that building in public, in private, will ensure that this is an invitation that never needs to be called on. I like to think that, if something isn't clear, they'll be able to check the code, the documentation and the issue history and get to where they need to go."},{"title":"On to something new (redux)","url":"/2022/10/05/on-to-something-new-redux.html","date":"2022-10-05","content":"Just over five years ago I got a message from my then employer to say I was going to be made redundant after 21 years working for them. After the 3 month notice period the final day came. Meanwhile, I found something new that looked terrifying but interesting . In the end it was less terrifying and way more interesting than I imagined it would be. It was fun too. But... (there's always a but isn't there?) In the four and change years I've been there the company got bought out, and then the result of that got bought up. As I've mentioned before I'm generally not a \"big company\" kind of person; in all my years I've found that I'm happier working in a smaller place. After a couple of buyouts my employer had gone from being 10s of people in size to 100s of people in size (and technically 10s of 1,000s of people in size depending on how you look at it). This change in ownership and size meant the culture became... well, let's just say not as friendly as you tend to enjoy when it's a smaller group of folk. On top of that I was starting to notice that my efforts were making less of an impact as things got bigger, and I started to feel like my contributions weren't really relevant any more. There were some problematic things happening too: undermining of efforts, removal of responsibilities without consultation or communication, that sort of thing. Plus worse. There's little point in going into the detail, but it's fair to say that work wasn't as fun as it used to be. That felt like a good time to start to look around. If work makes you feel unhappy and you can look around... look around. Thing is, I wasn't sure what to look for. I was in the comfortable position of, unlike last time, not needing to find something, so I could take my time at least. Over the course of the last year I've spoken to many different companies and organisations, some big (yes, I know, I said I don't like big places -- sometimes what's on offer deserves a fair hearing), some small, but none of them quite said \"this feels like me\" . In some cases the whole thing didn't have the right vibe, in others the industry either didn't interest me, or felt uncomfortable given my personal values. In one particular case a place looked interesting until I checked the CTO's socials and OMG NO NO NO AVOID AVOID (that was a fun one). Then I saw Will McGugan saying he was hiring to expand Textualize . This caught my interest right away for two good reasons. I can't remember how long I've been following Will on Twitter; I likely stumbled on him as I got back into Python in 2018 and I also remember noting that he was a Python hacker just up the road from me. We'd vaguely chatted on Twitter, briefly, in that \"Twitter acquaintance\" way we all often do (I remember one brief exchange about fungus on The Meadows ), and he'd seemed like a good sort. A small company run by a \"good sort\" kinda person felt like a damn good reason. The second reason was Textual itself. I'd been watching Will develop it, in open, with great interest. I had (and still have) a plan to write a brand new CHUI-based (okay fine TUI-based as the kids like to say these days!) Norton Guide reader, all in Python, and Textual looked like the perfect framework to do the UI in. The chance to be involved with it sounded awesome. Now, I said two reasons, but there's also a third I guess: Will's pitch for applying to Textualize felt so damn accessible! I'm on the older end of the age range of this industry; for much of my working life as a developer I've worked in isolation from other developers; while I first touched Python in the 90s, I've only been using it in anger since 2018 and still feel like I've got a lot to learn. Despite all these things, and more, saying \"aye Dave this is beyond you\" I felt comfortable dropping Will a line. Which resulted in a chat. Which resulted in some code tinkering and chatting. Which resulted in... Something new. So, yeah, as of 2022-10-10 I'm on yet another new adventure. Time for me to really work on my Python coding as I work with Will and the rest of the team as part of Textualize. Or, as I put it on Twitter a few days ago: I'm going to be a Python impostor syndrome speedrunner !"},{"title":"I must be getting old","url":"/2022/08/23/i-must-be-getting-old.html","date":"2022-08-23","content":"A little earlier this evening I got a new issue raised against boxquote.el . Apparently Emacs 29 (I'm running 28.1 as of the time of writing) is moaning about the likes of: ( setf ( point ) some-location-or-other ) and ( setf ( buffer-string ) &quot;&quot; ) There's a whole background to why I've tended to code like that, that stems from enjoying Common Lisp, my days reading (and sometimes posting to) comp.lang.lisp , and I think some of the stuff Erik Naggum wrote back in the day. I won't get into it all now; I'm not sure I can even remember a lot of how I got there given how far back it was. But... Wanting to quickly get to the bottom of why the above was suddenly an issue, I dived into the NEWS file and found the following : ** Many seldom-used generalized variables have been made obsolete. Emacs has a number of rather obscure generalized variables defined, that, for instance, allowed you to say things like: (setf (point-min) 4) These never caught on and have been made obsolete. The form above, for instance, is the same as saying (narrow-to-region 4 (point-max)) The following generalized variables have been made obsolete: &#39;buffer-file-name&#39;, &#39;buffer-local-value&#39;, &#39;buffer-modified-p&#39;, &#39;buffer-name&#39;, &#39;buffer-string&#39;, &#39;buffer-substring&#39;, &#39;current-buffer&#39;, &#39;current-column&#39;, &#39;current-global-map&#39;, &#39;current-input-mode&#39;, &#39;current-local-map&#39;, &#39;current-window-configuration&#39;, &#39;default-file-modes&#39;, &#39;documentation-property&#39;, &#39;frame-height&#39;, &#39;frame-visible-p&#39;, &#39;global-key-binding&#39;, &#39;local-key-binding&#39;, &#39;mark&#39;, &#39;mark-marker&#39;, &#39;marker-position&#39;, &#39;mouse-position&#39;, &#39;point&#39;, &#39;point-marker&#39;, &#39;point-max&#39;, &#39;point-min&#39;, &#39;read-mouse-position&#39;, &#39;screen-height&#39;, &#39;screen-width&#39;, &#39;selected-frame&#39;, &#39;selected-screen&#39;, &#39;selected-window&#39;, &#39;standard-case-table&#39;, &#39;syntax-table&#39;, &#39;visited-file-modtime&#39;, &#39;window-height&#39;, &#39;window-width&#39;, and &#39;x-get-secondary-selection&#39;. As suggested above... this is my thing, this is how I coded some Elisp stuff. Look through much of my Emacs Lisp code and you'll find me setf ing stuff all over the place. Apparently my style is \"obscure\". Actually, I'm kinda okay with that if I'm honest. This is going to be a bit of a pain in the arse; I'm going to have to go through a whole bunch of code and make it \"less obscure\", at some point. But... This isn't the part that had me thinking I must be getting old. Oh no. The NEWS file had another little surprise in store: ** The quickurl.el library is now obsolete. Use &#39;abbrev&#39;, &#39;skeleton&#39; or &#39;tempo&#39; instead. That.... that's me that is. Well, it's one of the me things. If you run about-emacs , dive into Authors , and search for my name, in any copy of GNU Emacs from the last decade or two, you'll find this: Dave Pearson: wrote 5x5.el quickurl.el quickurl.el was a package I wrote back in the late 1990s, back when I was a very heavy user of Usenet , and often found myself posting the same URLs in posts again and again; especially in comp.lang.clipper . As a fairly quick hack I wrote the code so that I could very quickly insert often-used URLs. Some time later, I got an email from the FSF (I actually think it was from RMS -- but that's an mbox I've long ago lost -- or a backup of it might be in storage back in England, on a DVD), asking if I wanted to contribute it to Emacs proper. This seemed like an odd thing to add to Emacs but, sure, why the hell not? And so I had my second contribution to a body of code I used a lot (the first being 5x5.el -- which itself was my first ever attempt at writing some non-trivial Elisp code). So... yeah... here we are. I'm now old enough to have written some Emacs Lisp code, had it required by the FSF for inclusion in Emacs, had it live in there for something like two decades, and then become obselete !"},{"title":"Failed successfully","url":"/2022/06/03/failed-successfully.html","date":"2022-06-03","content":"A couple of days back (for vague values of \"couple\", of course), first of the month, having my morning coffee, I go and open my bank's mobile app to move a bit of money about and pay a couple of things. This happens every month. This is so routine I do it almost on autopilot. Yeah, yeah, I know, it's banking, pay attention! But still... morning, coffee, routine. I get to the final movement/payment and then notice something: That.... that text! WTF? So then I look back at my payment history and notice that all but one payment hadn't gone through! O_o This alone is fine. Stuff happens. Things fail. I'm okay with that. It's an inconvenience for sure but doubtless whatever the problem is will be fixed and I can make the payments again later. But... That result. There's a tick. A GREEN tick. And a \"Thank you\". It's natural to see that image, know that it's always meant \"shit worked\" and just carry on. In one of my systems at work there's a tool I wrote for checking a repository of code to make sure it conforms to a certain standard. When folk use it they get a night big, bold and bright green thumb-up above the text that says everything is cool. If there's a problem, any sort of problem at all, then the display is red and there's no jolly icon and it's obvious that things are different and you likely want to pay attention to the explanation of what isn't right. This isn't news, of course. This isn't some revelation about UI design or anything. We know this stuff. I think what boggles my mind a little bit about this is that something as important -- and hopefully by this point as mature -- as a mobile banking app should get something as obvious as this right. But here we are, with a nice friendly green icon showing a tick and a friendly big \"Thank you\" followed by smaller text going \"aye shit didn't work pal\"."},{"title":"My VR recording setup","url":"/2022/05/28/my-vr-recording-setup.html","date":"2022-05-28","content":"Introduction For well over a year now I've been recording my VR gameplay and uploading it to YouTube . Less as a \"content creation\" thing, more as a nice record of games I've played and, on occasion, as a little bit of help to others; in the past I've watched other folk play games I like to get ideas for approaches to them, and I've also received the odd comment now and again where my play-through has helped someone else. A question I've had a couple of times is what I use to do the recording, so I thought I'd make an effort to write it all down here. First up, a couple of things to note: I started recording PCVR around April 2021 and the initial setup was a bit trial-and-error and Google searching and blog reading. As such, not all of the details of how to set up will be here, and I may even miss off some stuff I changed and is worthy of note; at the same time I might mention stuff that's just an obvious default. Consider this blog post as being a written version of one of my videos: it's for my own fun and benefit and might also help me in the future should I want to apply some of this again, and if it helps someone else that's a lovely bonus. The Hardware While it's not exactly the point of this post, I guess it's worth mentioning the hardware I use as of the time of writing. Given this is about PCVR, I of course have a PC which is running Windows. The machine information within Windows says it's a: Intel(R) Core(TM) i5-10400F CPU @ 2.90GHz Warning: I don't do hardware. I buy it from time to time, but hardware leaves me bored. It runs VR on a PC. This is fine. The machine itself has 16 GB of memory, is running Windows 10 Home and has a GeForce RTX 3060 for handling the graphics. The headset I'm using is a~~n Oculus~~ Meta Quest 2. I've had this since around November 2020, playing Quest-native games for the first few months, until I cracked and got the PC mentioned here to get into PCVR. The headset is connected to the PC with a USB cable . Finally, for recording voice, I use a USB lapel microphone with a really long cable . It should be said that, yes, sometimes, I do get a little caught up in things with two cables hanging off me. If I could give one tip here it would be that running the microphone cable up your trousers and shirt makes life a ton easier. As a bonus I have the USB cable for the headset running around the headset's strap and connected to it at the back and then running down my back. OBS Studio The core software used is OBS Studio . This has got to be one of the best bits of free software I've ever used, in terms of interface and what it delivers. Years back my son used to record and upload gameplay to YouTube and I can remember him having no end of issues using different recording software; some working with one game but not another, some other working with a different set of games, video and sync issues, etc... Lots of pain quite often. With OBS Studio the only issues I've ever had have been my own mistakes. At this point I have to confess that when I set it up I didn't make a point of keeping a recording of what I changed -- I was experimenting and not expecting much to come of it. So what I note here are the things that feel like they're important, and only the things that relate to recording PCVR, not streaming it (that might end up being a different blog post). That said, here are things I seem to remember as being key: Output Settings The items in the output pane in settings that I have and which might be important are: Output Mode: Simple Recording Quality : High Quality, Medium File Size Recording format : mkv Encoder : Hardware (NVENC) I do remember the recording format being set to mkv as something that's really important. I think it's mp4 by default, or was when I first installed, and if your machine crashes or OBS were to crash or something, you could end up with footage that can't be used. Using mkv means you can still use the footage (as I understand it). It does mean that once you're finished you have to use the \"remux\" option under the File menu, but that's a small price to pay. I can say that at least once I've had to hard-reboot my machine when a game and SteamVR and the like all got upset. I likely saved 45 minutes or more of footage thanks to mkv . Video Settings Nothing really special in here, I simply have both the base and output resolutions set to the desktop resolution. This might be something for me to tinker with in the future, but so far I've not run into any problems. VR Capture Now, of course, all of the above is great and fine and all but there's the issue of how you capture the VR gameplay. I approach this a couple of different ways. The first is I use the OpenVR Capture plugin for OBS . This makes capturing footage from SteamVR really easy. The only downside I found is that out of the box there's no default crop setting for using a Quest 2 (or I guess the Rift, as the Quest 2 sort of appears as a Rift to SteamVR games). As such I remember playing trial and error with that until I was happy I was getting as much footage as possible without having black bars and the like. Something I also like about the OpenVR Capture plugin is you can say if you want to capture the left or right eye. Normally not that big a deal for some things, but if you're playing a shooter and want people to see exactly what your dominant eye is seeing, that matters. Sadly, of course, not every game can be captured with that plugin. So far I've found that any game that can't be has its own mirror window on the desktop. In that case I use a Game Capture source and set it to capture that specific window. I could of course just get it to capture the focused window or something like that but I prefer to know that it's only grabbing what I want it to grab. Conclusion That's pretty much it I think. There's not a lot to it, although on occasion a lot can go wrong. Mostly it's a wonder any of it works. I mean, think about it, I have a computer with two screens strapped to my face, with two controllers in my hands talking to it; it's then connected via the Oculus Link to the Oculus Home; from which I start up SteamVR; and from the SteamVR home I start up the game and then \"live\" inside the game. It's a virtual world inside a virtual world inside a virtual world inside a real world; with lots of software along the way, all talking at once. That is then being recorded. Sometimes, on occasion, it takes a reboot or five to make it all work together. Really, it's a wonder it ever works. ;-)"},{"title":"I'm back!","url":"/2022/05/20/im-back.html","date":"2022-05-20","content":"I'm back! Almost. More or less. In more ways than one. First off, as often happens with blogs (we've all been there right?), I've been away from blogging for a while. I've still been online, still been waffling away on twitter , and have also stumbled into fosstodon as well . Doubtless plenty of other things. A big distraction for me, and one that is ongoing, is mucking about on YouTube . Since the last time I wrote anything on the blog I got myself a VR setup, and then a PCVR setup, and then finally fibre came to the village and I could stream, and... well, you can see how that would go. So, in short, that's where I've been and that's what's been keeping me busy. Now that I'm paying some attention to blogging again (hopefully!) I imagine some of that will end up on here -- I'd quite like to write about VR and gaming amongst other things. Now, I said I'd been away in more ways than one. Another way is explained by this post from back in 2019 , where I said I was going to head over to Hashnode and carry on blogging there, obviously with an emphasis on development and just development. That kept me busy for a while and worked out well, mostly. But... well, see above in part; I sort of ran out of steam when it came to purely-development topics. But I still wanted to write, a bit, and wanted to write about more than just development. Also, something else was bothering me about being over on Hashnode. In the past year, in terms of what they promote themselves, especially blogs and posts they promote on their Twitter feed, they seem to have started to lean really hard into crypto and web3 and NFTs and all that stuff. This left me feeling like that was all a bit icky and it was time to put some distance between that platform and myself. So over the past couple of weeks, low-level and as a background task, I've been back-porting posts from over there back into this blog. Starting with this post all new blog content, be it about software development or anything else, will be on here. If I'm really sensible and don't get distracted by new shiny... this should be how it remains now. Expect some changes over the next few weeks. While I'm aiming to stick with the core tech (Github pages, Markdown and Jekyll, Emacs to edit, etc), I'd like to tinker with the look and layout of the blog. The content will remain the same though. So, yeah, anyway, if you're reading this... hey, it's good to be back. :-)"},{"title":"Reading 2bit files (for fun) - the sequence","url":"/2020/09/26/reading-2bit-files-for-fun-the-sequence.html","date":"2020-09-26","content":"Introduction This post will cover the most important content of a 2bit file: the actual sequence data itself. In the first post I wrote about the format of the file's header, and in the second post I wrote about the content of the file's index. At this point that's enough information to know what's in the file and where to find it. In other words we know the list of sequences that live in the file, and we know where each one is positioned within the file. So, assuming we have our index in memory (ideally some sort of key/value store of sequences names and their offsets in the file), given the name of a sequence we can know where to go in the file to load up the data. So the next obvious question is, what will we find when we get there? Actual sequence data is stored like this: Content Type Size Comments DNA size Integer 4 bytes Count of bases in the sequence N block count Integer 4 bytes Count of N blocks in the sequence N block starts Integer Array 4*count bytes Positions are zero-based N block sizes Integer Array 4*count bytes Mask block count Integer 4 bytes Count of mask blocks in the sequence Mask block starts Integer Array 4*count bytes Positions are zero-based Mask block sizes Integer Array 4*count bytes Reserved Integer 4 bytes Should always be 0 DNA data Byte Array See below Breaking the above down: N blocks As mentioned in passing in the first post: technically it's necessary to encode 5 different characters for the bases in the sequences. As well as the usual T, C, A and G, there also needs to be an N, which means the base is unknown. Now, of course, you can't pack 5 states into two bits, so the 2bit file format solves this by having an array of block positions and sizes where any data in the actual DNA itself should be ignored and an N used in its place. Mask blocks This is where my ignorance of bioinformatics shows, and where it's made very obvious that I'm a software developer who likes to muck about with data and data structures, but who doesn't always understand why they're used. I'm actually not sure what purpose mask blocks serve in a 2bit file, but they do affect the output. If a base falls within a mask block the value that is output should be a lower-case letter, rather then upper-case. The DNA data So this is the fun bit, where the real data is stored. This should be viewed as a sequence of bytes, each of which contains 4 bases (except for the last byte, of course, which might contain 1, 2 or 3 depending on the size of the sequence). Each byte should be viewed as an array of 2 bit values, with the values mapping like this: Binary Decimal Base 00 0 T 01 1 C 10 2 A 11 3 G So, given a byte whose value is 27 , you're looking at the sequence TCAG . This is because 27 in binary is 00011011 , which breaks down as: 00 01 10 11 T C A G How you pull that data out of the byte will depend on the language and what it makes available for bit-twiddling; those that don't have some form of bit field will probably provide the ability to bit shift and do a bitwise and (it's also likely that doing bitwise operations is better than using bit fields anyway). In the version I wrote in Emacs Lisp, it's simply a case of shifting the two bits I am interested in over to the right of the byte and then performing a bitwise and to get just its value. So, given an array called 2bit-bases whose content is this: ( defconst 2bit-bases [ &quot;T&quot; &quot;C&quot; &quot;A&quot; &quot;G&quot; ] &quot;Vector of the bases. Note that the positions of each base in the vector map to the 2bit decoding for them.&quot; ) I use this bit of code to pull out the individual bases: ( aref 2bit-bases ( logand ( ash byte ( - shift )) #b11 )) Given code to unpack an individual byte, extracting all of the bases in a sequence then becomes the act of having two loops, the outer loop being over each byte in the file, the inner loop being over the positions within each individual byte. In pseudo-code, assuming that start and end hold the base locations we're interested in and dna_pos is the location in the file where the DNA starts, the main loop for unpacking the data looks something like this: # The bases. bases = [ &quot;T&quot;, &quot;C&quot;, &quot;A&quot;, &quot;G&quot; ] # Calculate the first and last byte to pull data from. start_byte = dna_pos + floor( start / 4 ) end_byte = dna_pos + floor( ( end - 1 ) / 4 ) # Work out the starting position. position = ( start_byte - dna_pos ) * 4 # Load up the bytes that contain the DNA. buffer = read_n_bytes_from( start_byte, ( end_byte - start_byte ) + 1 ) # Get all the N blocks that intersect this sub-sequence. n_blocks = relevant_n_blocks( start, end ) # Get all the mask blocks that interest this sub-sequence. mask_blocks = relevant_mask_blocks( start, end ) # Start with an empty sequence. sequence = &quot;&quot; # Loop over every byte in the buffer. for byte in buffer # Stepping down each pair of bits in the byte. for shift from 6 downto 0 by 2 # If we&#39;re interested in this location. if ( position &gt;= start ) and ( position &lt; end ) # If this position is in an N block, just collect an N. if within( position, n_blocks ) sequence = sequence + &quot;N&quot; else # Not a N, so we should decode the base. base = bases[ ( byte &gt;&gt; shift ) &amp; 0b11 ] # If we&#39;re in a mask block, go lower case. if within( position, mask_blocks ) sequence = sequence + lower( base ) else sequence = sequence + base end end end # Move along. position = position + 1 end end Note that some of the detail is left out in the above, especially the business of loading up the relevant blocks; how that would be done will depend on language and the approach to writing the code. The Emacs Lisp code I've written has what I think is a fairly straightforward approach to it. There's a similar approach in the Common Lisp code I've written . And that's pretty much it. There are a few other details that differ depending on how this is approached, the language used, and other considerations; one body of 2bit reader code that I've written attempts to optimise how it does things as much as possible because it's capable of reading the data locally or via ranged HTTP GETs from a web server; the Common Lisp version I wrote still needs some work because I was having fun getting back into Common Lisp; the Emacs Lisp version needs to try and keep data as small as possible because it's working with buffers, not direct file access. Having got to know the format of 2bit files a fair bit, I'm adding this to my list of \"fun to do a version of\" problems when getting to know a new language, or even dabbling in a language I know."},{"title":"Reading 2bit files (for fun) - the index","url":"/2020/09/05/reading-2bit-files-for-fun-the-index.html","date":"2020-09-05","content":"As mentioned in the first post , once you've read in the header data for a 2bit file, the next step is to read the index. This is an index into all the different sequences held in the file. Reading the index itself is fairly straightforward. The index comes right after the header -- so it starts on the 17th byte of the file. Each entry in the index contains three items of information: Content Type Size Comments Name length Integer 1 byte How many bytes long the name is Name String Varies Length given by previous field Offset Integer 4 bytes Location in the file of the sequence So, in some sort of pseudo-code, you'd read in the index as follows: index = dict() for seq = 1 to seq_count // seq_count comes from the header name_len = (int) read_bytes( 1 ) name = (string) read_bytes( name_len ) offset = (int) read_bytes( 4 ) index[ name ] = offset end Note, as mentioned in the first post , the index will need to be byte-swapped if the file is in an endian form other than the machine you're running your code on. How you'd go about this will, of course, vary from language to language, but the main idea is always going to be the same. There's a fairly striking downside to this approach though: reading data can often be an expensive (in terms of time) operation -- this is especially true if the data is coming in from a remote machine, perhaps even one that's being accessed over the Internet. As such, it's best if you can make as few \"trips\" to the file as possible. With this in mind, the best thing to do is to read the whole index into memory in one go and then process it from there -- the idea being that that's just one trip to the data source. The problem here, however, is that there's nothing in the header or the index that tells you how large the index actually is. What you can do though is work on the worst case scenario (assuming memory will allow). The worst case is fairly easy to handle: it's going to be 1 byte for the name length, plus 255 bytes for the name (the longest possible name), plus 4 bytes for the offset; multiply all that by the number of sequences in the index and you have the worst-case buffer size. When reading this data in you might also want to ensure you're not going to run off the end of the file (perhaps the names are all quite small and so are the sequences). Recently I've been working on a package for Emacs that can read data from 2bit files , so here's the core code for reading in the index: ( defun 2bit--read-index ( source ) &quot;Read the sequence index from SOURCE. As a side effect `2bit-data-pos&#39; of SOURCE will move.&quot; ( cl-loop ;; The index will be a hash of sequence names, with the values being the ;; offsets within the file. with index = ( make-hash-table :test #&#39;equal ) ;; We could read each name/value pair one by one, but because we&#39;re doing ;; this within Emacs, which means making a temp buffer for every read, ;; that could get pretty expensive pretty fast. So instead we&#39;ll read the ;; index data in in one go. However, there is no easy-to-calculate size ;; for the index. The best we can do is calculate the worst case size. So ;; let&#39;s do that. The worst case size is the maximum size of the name of ;; a sequence (255), plus the size of the byte that tells us the name ;; (1), plus the size of the word that is the offset in the file (4). with buffer = ( 2bit--read source ( * ( 2bit-data-sequence-count source ) ( + 255 1 4 ))) ;; For every sequence in the file... for n from 1 to ( 2bit-data-sequence-count source ) ;; Calculate the position within the buffer for this loop around. Note ;; that the skip is the last position plus 1 for the size byte plus the ;; size plus the length of the offset word. for pos = 0 then ( + pos 1 size 4 ) ;; Get the length of the name of the sequence. for size = ( aref buffer pos ) ;; Pull out the name itself. for name = ( substring buffer ( 1+ pos ) ( + pos 1 size )) ;; Pull out the offset. for offset = ( 2bit--word-from-bytes source ( substring buffer ( + pos 1 size ) ( + pos 1 size 4 ))) ;; Collect the offset into the hash. do ( setf ( gethash name index ) offset ) ;; Once we&#39;re all done.... return the index. finally return index )) This code does what I mention above: it grabs enough data into a buffer in one go that I'll have the whole index in memory to pull apart, and then I work with the in-memory copy. The index is added to a hashing dictionary. Note that, in this case, I don't actually do the test for running off the end of the file because at the heart of the file reading code is insert-file-contents-literally and it doesn't error if you request too much. With that done you'll have a list of all the sequences in the file. The next part, which will come in the next post , is the properly tricky part: the decoding of the sequence data itself."},{"title":"Reading 2bit files (for fun)","url":"/2020/08/30/reading-2bit-files-for-fun.html","date":"2020-08-30","content":"Introduction I've written a bit before about the value of having simple but interesting \"problems\", that you know the solution to, as a way of exercising yourself in a new environment . Recently I've added another to the list I already have, and I used it as an excuse to get back into writing some Common Lisp ; and then went on to use it as a reason to write yet another package for Emacs . Having gone through the process of writing code to handle 2bit files twice in about a month, and in two very similar but slightly different languages, I thought it might be interesting for me to then use it to exercise my ability to write blog posts (something I always struggle with -- I find writing very hard on a number of levels) and especially posts that explain a particular problem and how I implemented code relating to that problem. Also, because the initial version of this post rambled on a bit too much and I lost the ability to finish it, I'm starting again and will be breaking it up a number of posts spanning a number of days -- perhaps even weeks -- so that I don't feel too overwhelmed by the process of writing it. I will, of course, make sure every post links to the other posts. Now, before I go on, I'll make the important point that everything here is written from the perspective of a software developer who happens to work as part of a bioinformatics team; I don't do bioinformatics, I don't claim to understand it, I just happen to sit with (well, used to sit with them -- hopefully we'll all make it back to the office one day!) and work with them, and develop software that supports their work. Anything you see in any of the posts that's wrong about that subject: that's just my ignorance being shown through the lens of a software developer (all corrections are welcome). So, with all those disclaimers aside, I'm going to go on a slow wander through what a 2bit file is, how you'd go about reading it, and related issues. This isn't designed as a tutorial or anything like that, this is simply me taking what I've learnt and writing it down. Perhaps someone else will benefit one day, but the purpose is to simply enjoy cementing it in my own mind and to enjoy the process of putting it all in writing. What is a \"2bit file\"? So what's this new \"problem\" I've added to my list? It's code to read sequence data from 2bit format files . For anyone who doesn't know ( bioinformatics people look away now; a software developer is going to explain one of your file formats ), this is a file format that is intended to hold sequences in an efficient way. As I'm sure you know, DNA is made up of 4 bases , represented by the letters T , C , A and G . So, in the simplest case, we could just represent a genome using those four letters. Simple enough, right? Nice big text file with just those 4 letters in? The thing is, something like the human genome is around 3 billion bases in length . That'd make for a petty big file to have to store and move around. So why not compress it down a bit? That's where the 2bit format comes in. Given this problem I'm sure most developers would quickly notice that, given 4 different characters, you only need 2 bits to actually hold them all (two bits gets us 00 , 01 , 10 and 11 , so four different states). This means with a little bit of coding you can store 4 bases in a single byte. Just like that you've pretty much squished the whole thing down to 1/4 of the original size. And that's more or less what the 2bit format does. If you take a look at the actual data for the human genome you'll see that hg38.2bit is roughly 1/4 of 3 billion bytes, ish, give or take. There is a wrinkle, however. There are parts of a genome where you might not know what base is there. Generally an N is used for that . So, actually, we want to be able to store 5 different characters. But 5 isn't going to go into 2 bits... Damn! Well, it's okay, 2bit has a solution to that too, and I'll cover that later on. How is a 2bit file formatted? As you can see from the format information available online , a 2bit file is a binary file format that is split into 3 key parts: A fixed size header with some key information An index into the rest of the file A series of records that contain actual sequence information In this first post I'll cover the details of the header. Subsequent posts will cover the index and the actual sequence data records. The header The header of a 2bit file is fixed in size and contains some key information. It can be broken down as follows: Content Type Size Comments Signature Integer 4 bytes See below for endian issues. Version Integer 4 bytes Always 0. Sequence count Integer 4 bytes Reserved Integer 4 bytes Always ignored. The signature value is used to test if what you're looking at is a 2bit file, but also tells you some vital information about how to read the file -- see below for more on that. The version value is always 0 -- as such another useful test would be to error out if you get a valid signature but get a version other than 0 . The sequence count is, as you'd guess, the number of sequences that are held within the file -- this is important when loading in the index of the file (more on that in the next post). The signature, big and little endianness, and byte swapping The header mentioned above comprises of 4 32-bit word values. The very first word is important to how you read the rest of the file. This is the signature for the 2bit file and it should always be 0x1A412743 . And this is where it gets interesting and fun right away. The 2bit file format allows for the fact that the file can be built in either a little-endian or a big-endian machine , and the 32-bit word values can be binary-written to the file in the local architecture's byte order. The effect of this is that, from reading the very first value in the file, you need to decide if every other numeric value you read needs to be byte-swapped in some way. The early logic being (in no particular language) something like: if signature == 0x1A412743 then must_swap = False else if byte_swap( signature ) == 0x1A412743 then must_swap = True else raise &quot;This isn&#39;t a valid 2bit file&quot; end Simply put, to read the rest of the file you will need a function that byte-swaps a 32bit numeric value, and a flag of some sort to mark that you need to do this every time you read such a value. Of course, depending on your language of choice, you could do it in a number of different ways. In a language like JavaScript or Scheme, where you can easily throw around functions, I'd probably just assign the appropriate 32bit-word-reading function to a global function name and call that regardless throughout the rest of the code. In other languages I'd probably just check the flag each time and call the swapping function if needed. In something like Python I'd likely just use the signature to decide on which format to pass to struct.unpack . For example, some variation on: # Assuming that &#39;header&#39; is the whole header of the file read as a binary buffer. word_fmt = &quot;&quot; for test_fmt in ( &quot;&lt;I&quot; , &quot;&gt;I&quot; ): if struct . unpack ( test_fmt , header [ 0 : 4 ] )[ 0 ] == 0x1A412743 word_fmt = test_fmt break if not word_fmt : raise Exception ( &quot;This isn&#39;t a 2bit file&quot; ) Now, the Python approach sort of hides the important detail here. With it we'd simply use struct.unpack 's ability to handle different byte orders and not worry about the detail. Which isn't fun, right? So how might code to byte-swap a 32bit value look? Assuming you've got the value as an actual numeric integer, it can be as simple as using a bit of bitwise anding and shifting. Here's the basic code I wrote in Common Lisp, for example: ( defun swap-long ( value ) &quot;Swap the endianness of a long integer VALUE.&quot; ( logior ( logand ( ash value -24 ) #xff ) ( logand ( ash value -8 ) #xff00 ) ( logand ( ash value 8 ) #xff0000 ) ( logand ( ash value 24 ) #xff000000 ))) JavaScript might be something like: function swapLong ( value ) { return ( ( value &gt;&gt; 24 ) &amp; 0xff ) | ( ( value &gt;&gt; 8 ) &amp; 0xff00 ) | ( ( value &lt;&lt; 8 ) &amp; 0xff0000 ) | ( ( value &lt;&lt; 24 ) &amp; 0xff000000 ) } and other variations on that theme in different languages. Up next In the next post I'll write about how the sequence index is stored and how to load it, including some considerations about how to make the loading as efficient as possible."},{"title":"The PEP 8 hill I will die on","url":"/2020/08/23/the-pep-8-hill-i-will-die-on.html","date":"2020-08-23","content":"I first learnt Python back in the mid-to-late 90s, used it in place of Perl once I was comfortable with it, and then we sort of drifted apart when I first met Ruby. It's only in the last couple of years that I've got back into it, and in a huge way, thanks to my (not-quite-so-) new job . Despite the quirks and oddness (as I perceive them), I actually quite like Python and it's one of those languages that just flows off my fingers. I'm sure you know the same thing, perhaps not with Python, but there will be languages that just flow for you, and those that take a bit more effort and concentration. Python... feels okay to me. I also appreciate that there's been a long-standing style guide. I quite like PEP 8 as a read, and think there's a lot of good ideas in there; much of the content sits with how I'd approach things if I was tasked to come up with such a document. With this in mind, I'm a fairly heavy user of pylint and it in turn leans on PEP 8 (amongst other things) and I'm happy to accept most of its judgements. Not all of its judgements, but even when I disagree with it I try and keep track of how far I'm drifting . But there is absolutely one hill I will happily die on when it comes to PEP 8: the concept of \"extraneous whitespace\" in lists and expressions . Just.... no! Oh gods no! To borrow a line of code from the journey problem I dabbled with a while back , PEP 8 would have me write something like this: def perform ( commands : List [ str ], state : State ) -&gt; State : Now, I'm sure plenty of people won't see a problem with this at all; but all I can see is an almost-claustrophobic parameter list. What's with the parameters being jammed up against the opening and closing parens? Why have the dinky little comma lost between two different things? Why have it look like a long stream of letters and punctuation? Why.... No. Just no. I can't. Rightly or wrongly, I just need for the code to breathe a bit. When I type this: def perform ( commands : List [ str ], state : State ) -&gt; State : suddenly if feels like there's fresh air in the code, like it flows gently out of my head, off my fingers, through the keyboard and into the buffer. In my head, and to my eyes, the code is.... relaxed. Do I have a rational reason for this? Nope. Then again I don't see one for doing it the other way either; I can't think of one and I don't see one in the source document. So, that's a warning I always turn off with pylint and it's a style I carry through all my Python code; and I think that's the important point here: anyone reading and working with my code should see the same style all the way through. It might differ from PEP 8 on this point, but at least it's the same all the way. And, really, that's okay: PEP 8 is there to be ignored . ;-) PS: This is a small part of another blog post I was meaning to write, and might still do, about my (still ongoing) experience of getting lsp-mode up and running in Emacs and having it play nice with Python projects. I have that working, but it was a bit of a learning curve and epic battle over a couple of days, and one that had me first encounter pycodestyle . I may still tell the tale..."},{"title":"Swift TIL 12","url":"/2020/07/18/swift-til-12.html","date":"2020-07-18","content":"First a small aside: To be honest, the T part of TIL is getting to be less and less true with this series of posts, but the posts themselves serve a useful purpose for me. As I've been reading the book I'm working through, I've also been making notes on my iPad in the Apple Notes application . I'm not really convinced that that's the best final location for such notes, so early on I made an extra step in keeping track of what I'm doing and trying to reinforce what I'm learning: transfer the notes into Org-Mode documents in my notebook repository. This repository contains lots of Org-Mode files, broken down into subject directories, that hang on to longer-form information I want to keep track of regarding software development and general operating system use. I'm sure you know the sort of thing, the things where you know you know them but you can't always retain all the detail -- so having the detail where you know you'll find it is useful. So I've made that part of the process: read book, find thing worth noting, note in Apple Notes, a wee while later re-read and test out by writing sample code and transfer to the Org-Mode notebook. During that latter step I sometimes also write up something that I really liked or found interesting here to further reinforce the learning process. The \"TIL\" I wanted to note quickly today is how happy I was to see that Swift has something that's a reasonably recent addition to Emacs Lisp: conditional binding. Skipping off into Emacs Lisp for a moment, it would be very common for me to find myself writing something like this (this actually happens in all languages really): ( let (( foo ( get-something-from-elsewhere ))) ( when foo ( do-something-with foo ))) Quite simply: I'd get a value from elsewhere, that value could possibly be nil to mark that there was a failure to get a value, but that failure wasn't in any way fatal or even a problem worthy of note: I just needed to skip along. But that binding followed by the test was always a little jarring. And then, back in 25.1 , if-let and when-let got added (of course, this being Lisp, it would have been very simple to add them anyway ), and it was easier to write the code so it looked just a little nicer : ( when-let (( foo ( get-something-from-elsewhere ))) ( do-something-with foo )) It's a small difference, but I find it a pleasing one. So of course I was pleased to find that Swift has something similar with if and Optional values, where you can write something like: if let foo = getSomethingFromElsewhere () { // Do something with foo but only if it&#39;s not nil } Which means you can do things like this (not that I'd really do things like this, but it was a handy test on the command line): func oddRand () -&gt; Int ? { let n = Int . random ( in : 0. .. 99 ) if n % 2 == 0 { return nil } return n } for _ in 0. .. 10 { if let n = oddRand () { print ( n ) } else { print ( &quot;Nope&quot; ) } } As usual... of course that's horrible code, it was just thrown together to test/experience the language feature on the command line. I like it though. I figure all the best languages have conditional binding . ;-)"},{"title":"Swift TIL 11","url":"/2020/07/11/swift-til-11.html","date":"2020-07-11","content":"This is one of those things, especially this little play to help appreciate the feature, that I'm filing under \"kinda cool, but I am never doing this in production\". So Swift has operator overriding, and then some. Moreover, operators are, in effect, functions, just with some extra syntax support. None of this is new to me, I've worked in and with other languages that have this ability, expect... I don't ever recall working in a language that, at the time I did, supported creating brand new operators (okay, fine, Lisp is a bit of an outlier here and there's all sorts of fun conversations to be had there -- but still, let's stick with more \"conventional\" syntax here). Support always seemed to be about extending the ability of an existing operator. Swift though... yeah, you get to pick from a huge character space when it comes to creating operators. Which got me thinking... How cool would it be to have a prefix operator that turns a floating point number into a currency-friendly number (you know, the sort of number type that can be used for currency-friendly calculations). Swift has the decimal type which, at first glance anyway, looks to be a sensible candidate; even if it isn't (and, really, how to actually sensibly handle currency is a whole series of blog posts in their own right, that I have no wish to write myself because such things are a previous working life for me, and other people have doubtless done a very comprehensive job elsewhere over the years) it will serve as a good stand-in for the little bit of horror I'm going to write next. So... Let's say we want to use  as a prefix operator to say \"see this number? make it a decimal \", we could do something as simple as this: import Foundation prefix operator  prefix func  ( n : Decimal ) -&gt; Decimal { n } print (  1.20 +  0.75 +  0.01 ) Horrifically and delightfully, it works: $ swift run [ 3 /3 ] Linking opover 1 .96 I know, I know, I feel bad for even trying. But it's also kinda cool that the language has this. It gets better though... While reading up on what characters can and can't be used as operators, one thing that stood out was the fact that, more or less, any character that isn't a valid identifier can be used as an operator. So... hang on, we can use \"emoji\" as identifiers? Like this? import Foundation prefix operator  prefix func  ( n : Decimal ) -&gt; Decimal { n } let  =  1.20 +  0.75 +  0.01 print (  ) Why yes. Yes we can. "},{"title":"When the man page fibs","url":"/2020/07/10/when-the-man-page-fibs.html","date":"2020-07-10","content":"Earlier this week something in my development environment, relating to Homebrew , Python, pyenv and pipenv , got updated and broke a handful of repositories. Not in a way that I couldn't recover from, just in a way that was annoying, got in the way of my workflow, and needed attention. (note to self: how I set up for Python/Django development on a machine might be a good post in the future) Once I was sure what the fix was (pretty much: nuke the virtual environment and recreate it with pipenv , being very explicit about the version of Python to use) the next step was to figure out how many repositories were affected; not all were and there wasn't an obvious pattern to it. What was obvious was that the problem came down to python in the .venv directory pointing to a binary that didn't exist any more. So... tracking down problematic repositories would be simple enough, just look for every instance of .venv/bin/python and be sure it points to something rather than nothing; if it points to nothing I need to remake the virtual environment. I quickly knocked up a script that was based around looking over the results of a find , and initially decided to use file to perform the test on python . It seemed to make sense, as I wrote the script I checked the man page for file(1) on macOS and sure enough, this exists: -E On filesystem errors (file not found etc), instead of handling the error as regular output as POSIX mandates and keep going, issue an error message and exit. Given that file dereferences links by default, that should get me an error for a broken link, right? Bit hacky I guess, but it was the first thing that came to mind for a quick bit of scripting and would do the trick. Only... $ file -E does-not-exist file: invalid option -- E Usage: file [ bcCdEhikLlNnprsvzZ0 ] [ -e test ] [ -f namefile ] [ -F separator ] [ -m magicfiles ] [ -M magicfiles ] file... file -C -m magicfiles Try ` file --help &#39; for more information. Wat ?!? But it's right there! It says so in the manual! -E is documented right in the manual page! And yet it's not in the valid switch list as put out by the command, and it's an invalid option . The hell? So I go back and look at the man page again and then I notice it isn't in the list of switches in the synopsis. SYNOPSIS file [-bcdDhiIkLnNprsvz] [--extension] [--mime-encoding] [--mime-type] [-f namefile] [-m magicfiles] [-P name=value] [-M magicfiles] file file -C [-m magicfiles] file [--help] I then did the obvious tests. Did I have file aliased in some way? No. Was some other thing that works and acts like file in my path? No. Was I absolutely 100% using /usr/bin/file ? Yes. Long story short: it seems the man page for file , on macOS, fibs about what switches it supports; it says that -E is a valid option, but it's not there. What's even odder is the man page says it documents v5.04 of the command, but --version reports v5.37. Meanwhile, if I check on a GNU/Linux box I have access to, it does support -E , reports it in the switches, documents it in the man page (in both the synopsis and in the main body of the page) and it is v5.25 (and so is its man page). So that was something like 20 minutes lost to a very small problem, for which there was no real solution, but was time that had to be spent to get to the bottom of it. In the end I went with what I probably should have gone with in the first place: stat -L . for venv in $( find . -name .venv ) do if ! stat -L &quot; $venv /bin/python&quot; &gt; /dev/null 2 &gt; &amp; 1 then echo &quot; $( dirname $venv ) &quot; fi done And now I have that script in my ~/bin directory, ready for the next time Homebrew and friends conspire to throw my day off for a while."},{"title":"Helping myself change the default git branch","url":"/2020/07/09/helping-myself-change-the-default-git-branch.html","date":"2020-07-09","content":"This is something I've being meaning to do for a couple or so years now, and unsurprisingly it's bubbled up again recently: the business of swapping the name of the master branch in git out for something better. Because it's one of those jobs that's simultaneously simple and also laborious, I kept putting it off. Changing up the local configuration so that main (or whatever name you prefer) is used \"out of the box\" is simple enough ; the laborious part is updating all of the repositories that live in the \"forge of choice\". In my case, over on GitHub , I have getting on for 200 repositories -- 142 of which are public (as of the time of writing). At work we use GitLab as our internal forge and I've got a non-trivial number of repositories on there too. The obvious first step to tackling this is to knock up a little tool to help find the repos that still need swapping. That was simple enough : #!/bin/bash # Quick and dirty tool to find repositories that still make use of a # &quot;master&quot; branch. Helps with tracking down the ones that need # updating/improving. for repo in $( find . -name .git ) do ( cd &quot; $( dirname $repo ) &quot; if git branch | grep master &gt; /dev/null 2 &gt; &amp; 1 then echo &quot; $( dirname $repo ) &quot; fi ) done ### git-archaic ends here It's not meant to be clever, just something I can run when I'm in a \"default branch swapping\" mood so find a repository or two to tackle. The idea being that it uses find to pull out any instance of .git in or below the current directory, changes to it (inside a sub-process to ensure the PWD gets put back after the cd that happens, before the next iteration of the loop), gets a list of the branches and, if master is one of them, prints the directory name. Using this, I can now slowly work through my more active repositories and make the swap -- the idea being that if I currently have them cloned down to my machine, they're obviously some level of \"active\". At some point I imagine I could get more clever and use the APIs of the forges to look at all the repositories I own; that's another job for another day. This gives me enough to be going on with. :-)"},{"title":"Swift TIL 10","url":"/2020/07/05/swift-til-10.html","date":"2020-07-05","content":"My leisurely journey into getting to know Swift by reading and then making notes to myself in my blog continues, and this weekend I encountered defer . As I was reading about Swift I did keep wondering when something like try (it has try ), catch (it has catch ) and finally (it doesn't have finally , but...) might crop up. This weekend I hit the part of the book that covered this sort of thing. Given Swift's apparent general reliance on not throwing errors but instead using Optional and nil to signify issues, it sort of came as no surprise that its approach to implementing something like try ... finally is actually divorced from try . I'm not sure how I feel about it yet, but defer makes sense. Here's an utterly useless bit of code that demonstrates how it works: func add ( _ n1 : Int , _ n2 : Int ) -&gt; Int { defer { print ( &quot;Huh! We did some adding!&quot; ) } print ( &quot;About to do the add and then return&quot; ) return n1 + n2 } print ( add ( 2 , 2 ) ) When run, the output is this: $ swift run [ 3 /3 ] Linking try-defer About to do the add and then return Huh! We did some adding! 4 A defer (and there can be multiple) is tied to the block that it's declared in, and is executed when the block exits. This is, of course, going to be really handy for things like resource-management where you don't want to be leaking something, although I can imagine a few other uses too (none of which are really going to be novel for someone who's coded in other languages with similar constructs). What I find interesting about this is that one or more defer blocks can be declared at various locations within a block of code; this obviously makes sense in that you might not want to be handling the tidy-up of something you've not got around to creating yet. But there's also part of me feels uneasy about the \"exit\" code being declared further up the body of code, rather than down towards the end. On the other hand I think I do appreciate the idea of, up front, writing \"look, any time there's a GTFO in the code that follows, this will happen\" -- you're made aware pretty quickly of what to expect. Anyway, it's good to know Swift has something similar to a finally ."},{"title":"Swift TIL 9","url":"/2020/06/30/swift-til-9.html","date":"2020-06-30","content":"Some may be happy to know that the frequency of these little notes to myself may reduce real soon, as I'm sort of caught up with my notes, mostly, and I'm unlikely to pick up the book that I'm reading for a couple or so days now I'm used to the idea of structures and classes from other languages, going way back, but as I first started reading about Swift it wasn't obvious to me why it had them both too. At first glance they appeared to be very similar. It was only as I got a little further into reading that I found out one huge difference (there are others, that pretty much stem from this one): objects created from classes are reference types (which you'd expect, of course), structures on the other hand are value types . A quick illustration of the difference, in my head anyway, can be found if I go back to using an observer . Take this daft bit of illustrative code for example: class Person { var name : String = &quot;No name&quot; } var dave = Person () { didSet { print ( &quot;dave was set&quot; ) } } dave . name = &quot;Dave&quot; If I run that, I get no output. That makes sense. The variable dave is initialised to an instance of a Person but is never subsequently set to anything else. The following assignment is to a property of the object. We're working on a reference to an existing object. But simply change Person to being a struct : struct Person { var name : String = &quot;No name&quot; } var dave = Person () { didSet { print ( &quot;dave was set&quot; ) } } dave . name = &quot;Dave&quot; and the output looks like this: $ swift run [ 3 /3 ] Linking ref-vs-val dave was set That's because the assignment to dave.name means a new value is created. This, of course, is just the tip of the iceberg; there are all sorts of other things to keep in mind that follow on from this, generally relating to mutability (or the lack thereof). I also imagine this means that, when there's no obvious benefit either way, the choice of using class vs struct is something that could have performance implications. That's something for me to look into more another day; but this is a note here to myself that it's a thing to keep in mind."},{"title":"Swift TIL 8","url":"/2020/06/29/swift-til-8.html","date":"2020-06-29","content":"Although I read up on it a few days back, it was only this evening that I fired up Emacs (well of course I'm testing Swift with Emacs, what did you think I'd do?!?) and dabbled with some code to really get a feel for how casting works in Swift. Swift seems to be one of those languages that does it with a keyword rather than a non-keyword approach. The two main keywords being as? and as! . I kind of like how there's a polite version and a bossy version. Having the two makes a lot of sense from what I read too. To try and illustrate my understanding so far (and do keep in mind I'm not writing this with the express purpose of explaining it to anyone else -- I'm writing this to try and retain it all in my head by working through it), here's a bit of utterly pointless and highly-contrived code that defines three classes in a fairly ordinary hierarchy: class Animal {} class Dog : Animal {} class Cat : Animal { func beAdorable () { print ( &quot;Purrrrrr!&quot; ) } } So, so far, so good: we have animals, we have dogs which are a kind of animal, and we have cats, which are also a kind of animal, but they have the special ability of actually being adorable.  Now, for the purposes of just testing all of this out, here's a horrible function that makes little sense other than for testing: func adore ( _ a : Animal ) { ( a as ! Cat ). beAdorable () } Given an animal, it forces it to be a cat (by casting it with as! ), and then asks it to be adorable (because, of course, cats always do as they're asked). So, if we then had: adore ( Cat () ) we'd get what we expect when run: Purrrrrr! So far so good. But what about: adore ( Dog () ) Yeah, that's not so good: ~/d/p/s/casting$ swift run [ 3 /3 ] Linking casting Could not cast value of type &#39;casting.Dog&#39; ( 0x10a1f8830 ) to &#39;casting.Cat&#39; ( 0x10a1f88c0 ) . fish: &#39;swift run&#39; terminated by signal SIGABRT ( Abort ) One way around this would be to use as? , which has the effect of casting the result to an Optional . This means I can re-write the adore function like this: func adore ( _ a : Animal ) { ( a as ? Cat )?. beAdorable () } Now, if a can be cast to a Cat , you get an optional that wraps the Cat , otherwise you get an optional that wraps nil (hence the second ? before attempting to call the beAdorable member function). So now, if I run the problematic dog call above again: ~/d/p/s/casting$ swift run [ 3 /3 ] Linking casting In other words, no output at all. Which is the idea here. I think I like this, I think it makes sense, and I think I can see why both as! and as? exist. The latter also means, of course, that you can do something like: func adore ( _ a : Animal ) { let cat = a as ? Cat if cat != nil { cat !. beAdorable () } else { print ( &quot;That totally wasn&#39;t a cat&quot; ) } } which, in the messy dog call again, now results in: ~/d/p/s/casting$ swift run [ 3 /3 ] Linking casting That totally wasn &#39; t a cat Or, of course, the same effect could be had with: func adore ( _ a : Animal ) { if a is Cat { ( a as ! Cat ). beAdorable () } else { print ( &quot;That totally wasn&#39;t a cat&quot; ) } } It should be stressed, of course, that the example code is terrible design, so given the above I'd ensure I never end up in this sort of situation in the first place. But for the purposes of writing and compiling and running code and seeing what the different situations result in, it helped."},{"title":"Swift TIL 7","url":"/2020/06/28/swift-til-7.html","date":"2020-06-28","content":"This post is very much a case of me writing it down to try and get it all straight in my head, and to make sure it sticks. The other day I was reading about Swift's types and type-equality checks, and as I'd expect from plenty of other languages I've worked with, there's a way for checking that two types are the same, such that super/subclasses aren't taken into account, and a way where they are. So, given this silly code: class Animal {} class Cat : Animal {} print ( Cat . self == Animal . self ) // False print ( Cat . self is Animal . Type ) // True print ( type ( of : Cat () ) is Animal . Type ) // True it's made clear that == checks for strict equality and a super/subclass relationship isn't taken into account. On the other hand is does take it into account. Only... what's with this whole .self sometimes and .Type other times business? That took a little bit of writing code and playing to get comfortable with. Here's how I understand it now (and do feel free to correct me below if I'm way off): Given the above code, Animal.Type is the type of a value that expresses the type of Animal . On the other hand, Animal.self is a value that is the type of an Animal . Yeah, I know, that still reads oddly. But written as code: let feline : Cat . Type = Cat . self I think it makes a lot more sense. And having got there I felt I better understood it. I'm not 100% sure I'm 100% with it, but I'm getting there."},{"title":"Swift TIL 6","url":"/2020/06/27/swift-til-6.html","date":"2020-06-27","content":"I'm going to file this one under \"it seems really unnecessary, but it's also kinda cool\". While reading up about protocols the book I'm reading introduced the ExpressibleBy*Literal protocols, where the * is one of a number of obvious literals. For example: ExpressibleByStringLiteral . As you might imagine, it lets you create a class that can be initialised with a literal value, as opposed to needing to appear to call the constructor for a class. So, for a silly example: class Hello : ExpressibleByStringLiteral { private let what : String required init ( stringLiteral what : String ) { self . what = what } func say () { print ( &quot;Hello, \\( self . what ) !&quot; ) } } You could, of course, write this: let v1 = Hello ( &quot;world&quot; ) v1 . say () but because of ExpressibleByStringLiteral you can also write: let v2 : Hello = &quot;universe&quot; v2 . say () Now, sure, in this case it saves you nothing, but this does also mean that parameters of functions whose type uses one of the `ExpressibleBy*Literal protocols can be passed a literal, rather than a \"long-hand\" instantiated object. For example: func Greet ( _ h : Hello ) { h . say () } Greet ( &quot;davep&quot; ) I can see that being quite handy."},{"title":"Swift TIL 5","url":"/2020/06/26/switch-til-5.html","date":"2020-06-26","content":"I'm going to file this one under \"it makes perfect sense, but I don't think it aids in making the code readable\" -- something which I'm finding is a bit of a theme with Swift. In Swift self gets used and gets used in a way you'd expect from many other languages. So far so good. But, it seems, Self is also a thing too, and it's different from self . Whereas self is the current instance, Self is the current type. So consider this: class Greeting { class func message () -&gt; String { &quot;Ayup!&quot; } func message () -&gt; String { &quot;Well hello there&quot; } func emit () { print ( Self . message () ) print ( self . message () ) } } Greeting (). emit () When run, the output is: Ayup! Well hello there It makes sense that that's the case. I actually really like the ability to use Self rather than having to use Greeting , but damn that's really setting things up for either mistyping or misreading code. You're going to want to hope that your development environment makes it super obvious what's a value and what's a type when it comes to using font choices."},{"title":"Swift TIL 4","url":"/2020/06/25/swift-til-4.html","date":"2020-06-25","content":"Some languages favour a \"one way to do it\" approach, some favour \"there's more than one way to do it\" . I'm not sure I'm at a point where I have a feel for what Swift's approach is, but I'm getting the impression it's more the latter than the former. If there was one thing that made me think that, it was when I found out that Swift's bool type has a toggle method. var cool = false print ( cool ) cool = ! cool print ( cool ) cool . toggle () print ( cool ) giving: $ swift run false true false I can see a number of reasons why that's actually going to be handy -- the main one being when you want to throw around a toggling method -- but it still struck me as rather odd on first reading. I also think it's worth me making a personal note about it because foo.toggle() isn't going to stand out as much as foo = !foo when reading code. At least not for a short while."},{"title":"Swift TIL 3","url":"/2020/06/24/swift-til-3.html","date":"2020-06-24","content":"Today's little \"Swift TIL\" is observers. While reading up on the language I was delighted to find that it has observer support baked right into the language, for any sort of variable. So code like this: var name = &quot;David&quot; { willSet ( new ) { print ( &quot;About to change name from \\( name ) to \\( new ) &quot; ) } didSet ( old ) { print ( &quot;Name changed from \\( old ) to \\( name ) &quot; ) } } name = &quot;davep&quot; Does what you'd imagine: About to change name from David to davep Name changed from David to davep Not only can I see how that'd be useful for the main sorts of purposes that Swift is put to, I can think of many times when I'd have benefitted from that in my general day-to-day work. Of course, you can create an observer approach in any language really, but having an idiom that's part of the language feels nice and tidy."},{"title":"Swift TIL 2","url":"/2020/06/23/swift-til-2.html","date":"2020-06-23","content":"Following on with writing little notes to myself so I remember some key things as I learn about Swift... I sort of feel like this will make reading code a little harder, so it's one I want to keep in mind. When calling an instance method, if it's not ambiguous, you can omit self. from the call. For example: class Foo { private func inner () -&gt; String { &quot;Foo&quot; } func outer () -&gt; String { inner () + self . inner () } } print ( Foo (). outer () ) This makes me feel a little uneasy, and I strongly suspect I'll always use self. when writing such code: I'm a big fan of the idea that we write code for people, not for compilers."},{"title":"Swift TIL 1","url":"/2020/06/22/swift-til-1.html","date":"2020-06-22","content":"As I mentioned yesterday , I'm going to make a small series of posts where I write down things that I've stumbled on while getting to know Swift that are, for me personally, worthy of note, different, unusual, cool, or just simply \"WTF!?!\". Because learning new stuff is fun. My first one is that you can use keywords as identifiers if you \"escape\" them with backticks. Kind of like this: let ` let ` = &quot;let&quot; print ( ` let ` ) I'm struggling to imagine a situation where I'd ever want to do this. I'm still unsure if my reaction is \"that's cool\" or \"WTF?!?\"."},{"title":"A second attempt to learn Swift","url":"/2020/06/21/a-second-attempt-to-learn-swift.html","date":"2020-06-21","content":"It's five years ago this month that I bought myself my first macOS (then OS X) device. After many years of having a Windows machine as my daily driver, which was also my work machine (I worked from home), I decided it was high time that I returned to having a Unix-a-like system on my desk too. For a decade or so, starting in the later-90s, I'd had a GNU/Linux desktop. I still had a Windows desktop (until a couple of years ago most of my work was on DOS and Windows), but thanks to the wonders of a KVM, and later an X server that ran on Windows, my personal hacking was done on a GNU/Linux desktop. But as things moved around, priorities changed, as life moved on, the GNU/Linux boxes got retired and never quite replaced. Eventually, in 2015, I found myself with the means and desire to recover that sort of setup. Long story short, after a lot of reading up and weighing up options I decided that the best option for a desktop Unix was... an iMac! I loved it. Sure, there were lots of little things on the surface that were different or annoying or just plain not as cool as the Mac fans would tell you , but under the hood I found what I needed: a Unix CLI with all the things I knew well. And, of course, it ran GNU Emacs just fine; that was the really important thing for me. Pretty much right away I decided that it might be fun to learn the tools necessary to develop native Mac apps, and perhaps even iOS apps. I downloaded XCode, bought a book, and started working through it. Having got that book, I decided it might be interesting to own an iOS device too. So, sort of needing an MP3 player, and having no wish to get an iPhone, I got myself an iPod Touch . So I was all set to devour the Swift book, write some stuff for OS X, create an iOS app or two, and... life happened. Stuff cropped up that distracted me from taking that further and I never really returned to working through the book. Fast forward to now and that initial iMac and iPod purchase spiralled a wee bit. Next after the iPod was an iPad Mini, when my Nexus 7 was starting to show its age and it was obvious that Google wasn't going to produce any more good Android tablets. Then, when I needed a very portable Unix-a-like machine for trips between where I was living and Edinburgh, I got myself a MacBook Air . Since then the iPod Touch has been replaced once, as has the iPad Mini. I now also own an iPad and a MacBook Pro. Unless Apple screw up and turn Macs into something unusable for developers (there are rumours), I imagine I'll be using Apple devices for some time to come now. And then, last month, having finally got frustrated with where Google were going with Android and the Pixel series, I jumped ship to the iPhone 11. As of right now I'm in a situation where I'm all about the Apple ecosystem regarding hardware and operating systems (including for my work machine), all of which is there to support my heavy use of the Google ecosystem (actually, the one bit of Google hardware I still lean on heavily is the Google Home -- I have 3 around my home). So... given all of that, I thought it was time to look at returning to learning Swift, with a view to writing some native macOS and i(Pad)OS stuff. I soon realised that the book I'd bought back in 2015 was rather out of date. It covers Swift 1.2 -- we're now up to 5.2 ! Given this, and given I've forgotten pretty much everything I'd read at the time, I decided I should start again from scratch. This weekend I've started reading my way though iOS Programming Fundamentals with Swift . While this obviously has an emphasis on iOS, I'm already finding that the first part of the book is a really great introduction to the Swift language in general. The pace seems just right, and the way topics are grouped makes it easy enough for me to skip over what's obvious (I don't need to know what objected-oriented programming is, and what the difference between a class and an object is, etc) and read up on the detail of this particular language when it comes to general concepts I know (knowing the differences between a class, struct and enum in the language is important, for example). I've yet to write a line of code, but I'm fine with that. The book is spending a lot of time introducing the language before encouraging you to fire up XCode, and I'm okay with that. I'm never a fan of being asked to write out code that I can't properly follow -- that just makes stuff look like magic when it's far more educational to know what's going on. What I am finding is I'm making lots of notes that are either \"oh, yeah, this is cool, I like this idea!\" or \"WTF are you kidding me?!?\" . Which is really nice -- it's always great to learn a new language that's a bit different from what you normally use. My plan then, over the next few weeks, it to keep at this and hopefully document my journey. I think I'd like to write a short series of TIL-type posts; nothing too long, just some new thing I read or discovered and my reaction to it. So, if you happen to follow this blog, I apologise in advance for any Swift-spam. You have been warned. ;-)"},{"title":"My journey to the dark side is complete","url":"/2020/06/14/my-journey-to-the-dark-side-is-complete.html","date":"2020-06-14","content":"Ever since the whole business of \"light mode\" and \"dark mode\" really kicked off in the mobile OS world, I've been a fan of the dark modes. On both Android and iOS/iPadOS, when apps became available with dark modes, I'd switch to it. When the operating systems themselves adopted the switch, that's what I went for. As well as having a love for all things black (anyone who knows me personally will know that), I think it just looks better on mobile devices. I can't quite say why, but it just works best for me. So, when macOS got a supported dark mode, I instantly switched it on, obviously. Then, within a day, I switched it back to light mode. Surprisingly it just didn't work for me, and I wasn't sure why. Since then I've tried living with it a few times and it's rarely lasted more than a few hours. There was something, something I couldn't quite put my finger on, that didn't sit right. Last Monday I decided to give it another go. This time, however, I thought I'd figured it out. The \"problem\" was Emacs! As mentioned back in January , for as long as I've used it (so since the mid-1990s), my Emacs has always had a light background -- probably because that's how it came \"out of the box\" (I'm talking Emacs in graphical mode here; I started with it on OS/2 Warp and then moved to a GNU/Linux X-based desktop). I figured that the contrast between the colour scheme of Emacs, and the rest of the machine, was the issue here. I spend most of my working day either in Emacs, or in iTerm2 -- often rapidly switching between the two. I've always run iTerm2 in the usual dark background mode with light text. So I figured the problem was having a dark OS desktop, dark terminal, and then a light editing environment. Eventually that'd feel wrong. So I decided that, for the first time in about 25 years, I should give Emacs a go with a dark mode. Taking a quick look at popular dark themes I noticed sanityinc-tomorrow-night looked easy on the eye, so I gave that a go (actually, I gave each of the themes in that set a go, initially starting with sanityinc-tomorrow-eighties , but I finally settled on sanityinc-tomorrow-night ). To start with it didn't look too good; not because of a problem with the theme itself, but because, over time, I'd made changes and tweaks to my setup that assumed I'd be using my usual light theme. After some dabbling and tinkering and trying things out, I got it looking \"just so\". Having got that working, I then thought it would be nice to be able to have Emacs -- at least on restart -- adapt to me switching between dark and light mode on macOS. It turns out that detecting if macOS is in dark mode is easy enough, the command defaults read -g AppleInterfaceStyle will emit Dark if in dark mode. So, knowing that, I updated my personal package for checking things about the environment that Emacs is in to use that information : ( defconst is-a-macOS-dark-mode-window-p ( and is-a-macOS-window-p ( string= ( shell-command-to-string &quot;defaults read -g AppleInterfaceStyle&quot; ) &quot;Dark\\n&quot; )) &quot;Are we running in a macOS window in dark mode?&quot; ) So, as of now, my Emacs setup is such that, if I'm in graphical mode on macOS and I'm in dark mode, Emacs will use a dark theme, otherwise it'll do what it did before -- with a light background in a graphical mode and a more Borland-a-like blue background when in CHUI mode . This seems to have made a difference. Almost one week on my work Macbook is still in dark mode, and I've switched both of my personal Macbooks, and my iMac, into dark mode too. I think it's sticking this time. Next up is to give some serious consideration to darkening the web in general. Only now am I noticing just how damn bright most of it is! As a slight aside to the above, I've also made one other change to Emacs: I've finally dropped the display of scroll bars. In the themes I'm using they didn't look so great, appearing to be distracting. For the past 25 years I've had the scrollbars there, but never actually used them; all they've ever done is serve as a visual aid to where I am in a file. Thing is, I'm not sure I ever really pay that much attention to that either. So, as a test, I've also been running with them turned off and, so far, I'm really not noticing them been gone. The habits we form that we convince ourselves make sense..."},{"title":"Some more ~/.emacs.d evolution","url":"/2020/06/07/some-more-dot-emacs-dot-d-evolution.html","date":"2020-06-07","content":"When I started with this version of the blog on Hashnode 1 , my plan was to try and write something at least once a week. I managed to do that as far as January this year, give or take, but then things got a little busy, the world got trickier, and... Well, you don't need me to tell you about that . Anyway, I'm back to write some more and, hopefully, try and keep up with writing. I feel it'll do me good. I have been busy since January. Work has, as far as possible, carried on as normal. The only big difference being I'm back working from home. It's an odd turn of events personally given that I'd worked from home for 21 years, then (with some trepidation) went back to working in an office . Having got used to being in an office and being around people, it took some adjusting to working alone again. So, on to the main point of this post... During that period I've spent a lot more time at my machine than I would normally, and so it was inevitable that I'd end up tinkering with my Emacs configuration . While it's true that there's hardly a week goes by where I don't tinker with some small thing , I try not to make huge changes too often. Huge changes do happen though. A handful of weeks back was another one of those times where I made a big change. After I burnt my original ~/.emacs file back in 2016 I've had an approach where I've tried to make things as modular as possible, and as easy to clone down to a new machine as possible. The design I came up with, especially once I moved over to using use-package , has served me well. But there was always one thing that bothered me: the files that handled the loading and configuration of packages were, in effect, still three large monolithic files . While this was better than a single monolithic ~/.emacs , it still didn't feel quite right. Giving it a bit of thought, I decided that what I really wanted was a single directory in which I could drop lots of small .el files that would handle the loading and configuration of all sorts of packages. While it didn't gain anything concrete, the idea felt tidier. Tidy is good. Feeling like the code smell is good, is good too. First though I needed a way to load multiple files, ideally within a whole directory hierarchy, without needing to know in advance what files would be there. After a little bit of tinkering I settled on this bit of code that revolves around the use of directory-files-recursively : ( let (( source ( expand-file-name &quot;init.d/packages.d/&quot; user-emacs-directory ))) ( when ( file-exists-p source ) ( cl-loop for use in ( directory-files-recursively source ( rx &quot;.el&quot; eol )) do ( load ( file-name-sans-extension use ))))) Simply put, this code finds every file in and below ~/.emacs.d/init.d/packages.d/ whose name ends in .el (note the use of a regular expression, using rx to create it), removes the extension from the name, and loads it with load (dropping the extension means load can decide if it wants to load the compiled version of the code, or the source, depending on what's available). After writing that I could then start to populate ~/.emacs.d/init.d/packages.d/ with lots of smaller files that handled the loading of packages. In some cases there's a file just for one package, in other cases there's a file that handles a logical grouping of packages (where there are obvious direct dependencies, or where one package is designed to extend the other, etc). For now I've decided to break things down into three directories that map to the three monolithic files I had before: However, I'm not totally wedded to this design and I may change this as time goes on. While I've not spent any time properly testing it out, I've also not really noticed any obvious impact on startup speed. However, this tends not to be a real concern for me. I seldom start Emacs anyway. I always have it running and use emacsclient as my editor in most places so files open instantly in the running version of Emacs . Note from future me: we're now back over on blog.davep.org of course.&#160; &#8617;"},{"title":"dnote.el - A wrapper for the dnote CLI","url":"/2020/01/19/dnote-el.html","date":"2020-01-19","content":"Late on last year I stumbled on an article about dnote . Annoyingly, I can't recall now where I saw it, but I made a reminder to look at it over my Christmas break. Dnote looked like a tool that would fill a hole I had in how I work. When it comes to making notes about things, and keeping things for future reference, I use a few tools, each one being just right (for me) for the job in question. I use Evernote to track documents and other household type things. I use Keep to make notes about stuff I need to remember short-term (say, the size of a space in my bedroom that I want furniture to go in) and also to record notes while in meetings at work. I use Journey to keep a journal about... anything, really. Finally, I use Pinboard to keep hold of URLs I might want to go back to (I also use it to create a to-read list). Amongst all of this, however, I felt I was missing something for keeping track of things that don't really fall into any of the categories above. Mostly this would be work-based or hacking-based things that are short and sweet but I don't always use enough to easily remember. I wanted just the right tool that would let me ferret away useful one-liners, remind myself of obscure switches that get used once or twice a year, etc. After reading up on dnote it seemed pretty clear that this was just such a tool. After getting back to the office at the start of this month I decided to make use of it and see how it went. My idea was simple: I'd record any \"TIL\" stuff that I might want to remember in the future, as well as recording things I need now and again but can't always remember. So far it's working quite well. I like that it has a simple CLI. I like that it's got a backend that you can use to sync between different machines. I like that it's got a web interface that's mobile-friendly. I like that it's Free Software and so you can host your own server if you wish. I found I liked it enough that, of course, I felt the need to start a simple Emacs wrapper for the CLI . At the moment dnote.el is designed to be a simple capture system. There are commands for capturing a one-liner (entered in the Emacs mini-buffer), for capturing the content of the current buffer, and for capturing freshly-entered multi-line text, entered in a buffer that uses markdown-mode . There's also a command for syncing notes if you have configured dnote to talk to a backend. What I don't have right now is the ability to navigate and view notes. So far I've not really felt the need for that because the CLI approach works so well. Longer-term though I can see my tweaking this and adding in commands for searching, viewing, editing and deleting notes. But, for now, if you've not had a look at dnote, I'd highly recommend having a play and seeing if it makes sense for you. And, if it does, and you're an Emacs user, perhaps dnote.el will be useful too?"},{"title":"Where I live and work","url":"/2020/01/11/where-i-live-and-work.html","date":"2020-01-11","content":"It's no surprise that I spend a lot of time in Emacs. Especially when I'm developing software, either for work or for personal fun, most of my time is time spent in Emacs. While I do obviously flit over to Chrome, and mostly do my CLI stuff in iTerm2 (I really like eshell but it just can't replace a good terminal for me), I spend a lot of time looking at Emacs. Here's what my Emacs looks like: Key elements for me are as follows: Light background Something I've never really got on with when it comes to code editing is dark themes and dark backgrounds. I find it too much of an eye strain. Oddly, I tend to prefer dark themes everywhere else, but not when it comes to working in Emacs. The theme I use is the built-in adwaita theme . Less boring mode line I make use of powerline to make the mode line a bit less boring-looking . While the colour scheme is such that it's kept in line with the light look, the style is nice in that it sort of matches the style of prompt I use in my shell. Full screen I always run Emacs as a full-screen application, then splitting it into different tiled windows using its own internal window handling. This is something I've done from way back when I got started with my first GNU/Linux desktop machine, and still like to do on macOS. I also run Emacs as a server and then use a little wrapper around emacsclient to open files (both locally and remotely) from the command line in that Emacs session. Comfortable eshell when I need it Although I say above that I generally don't use eshell , preferring to use a full-featured terminal application, in combination with fish , I do sometimes dip into eshell for quick things. So of course I have that configured to feel comfortable too. I do this easily thanks to eshell-git-prompt ."},{"title":"nuke-buffers.el -- Tidy up open buffers in Emacs","url":"/2019/12/14/nuke-buffers-el.html","date":"2019-12-14","content":"Both at work and at home I use Emacs by keeping a copy running all the time , and use emacsclient to open files inside it (including on remote machines thanks to a bit of ssh and heavy use of tramp -- I might write this up at some point). This works really well, but does mean I tend to build up a lot of buffers over time. Having lots of buffers open isn't generally an issue, and if I'm working on lots of different files in a project during the course of a hacking session it's actually a good thing. But, quite often, I want to tidy up the buffer list, clearing it back to near-zero buffers open. Many years ago, when I had a \"proper\" tower system running 24/7, with Emacs open all the time, I'd use clean-buffer-list as part of midnight . Along the way that fell out of favour with me, likely because I drifted into using machines that had Emacs open all the time but where the machine wasn't awake all the time. Eventually I decided to have some fun rolling my own solution, and nuke-buffers was born. Rather than try and do things in an automated way, this was designed to be bound to a key (or two) and then be run when I wanted, being as harsh as possible about cleaning up the buffer list. Since first writing it it's worked well for me. These days I tend to let the buffer list build up as I work on a new feature, or chase down a bug, etc. Then, once I've made the final commit for that period of focus, I'll hit the nuke-buffer key combo as the final act of confirming that I've done the job. So not only does this help tidy my Emacs session a bit, it also feels like a physical form of punctuation -- back in less sensible days, when I had some terrible habits, it would have been when I'd reach for the celebratory cigarette; buffer-tidying feels far more wholesome. ;) The way the code works is, of course, mostly directed at how I work -- it's highly likely it wouldn't make sense for many other people. The main aim is to kill as many buffers as possible, but without disturbing anything else. The list of buffers it gathers for nuking avoids buffers that are visiting files but have unsaved content , avoids the minibuffer (obviously), avoids any \"special\" buffer (one that starts with a space then an asterisk), avoids the current buffer and also avoids any buffer in a list of names to avoid . I've being using this on a daily basis for around 2.5 years now and it's done the job without ever losing me any work."},{"title":"git2gantt -- Simple tool to visualise coding runs","url":"/2019/12/08/git2gantt.html","date":"2019-12-08","content":"At the start of this year, as part of a much bigger process to review the work that had taken place over the previous 12 months, I was asked (at work) to provide some information about how much time I'd spent on various projects. Now, for me, there's really only one project, but there's lots of different tools and libraries that I've written to support the main work I do. All of these are split into different repositories in the company-internal instance of GitLab . This meant that getting a rough idea of what I was working on and when would be easy enough -- it's all there in the commit history. Given that this information would make up a couple of slides at most during a far bigger presentation, I wanted something that would be snappy and easy for non-developers to follow and understand. I spent a bit of time pondering some options and decided that (ab)using a gantt chart layout would make sense. That choice was made all the more easier given that GitLab supports the use of mermaid charts within its Markdown. This meant I could quickly write some code that took the git log of each repository, turned it into mermaid code, and then render it (by hand, this was all about getting things done quickly) via GitLab. This sounded like it could be a fun personal project. The result was some Python code called git2gantt . As mentioned above, the output isn't anything too clever, it's just code that can be used to create a plot via mermaid. For example, running git2gannt over itself: gantt title git2gantt output dateFormat YYYY-MM-DD section git2gantt Development: devgit2gantt20190208, 2019-02-08, 2019-02-13 Development: devgit2gantt20190214, 2019-02-14, 2019-02-15 Development: devgit2gantt20190303, 2019-03-03, 2019-03-04 Development: devgit2gantt20191203, 2019-12-03, 2019-12-04 Usage is pretty straightforward: As you can see, it can be run over multiple repos at once, and there's also an option to have it consider every branch within each repository. Another handy option is the ability to limit the output to just one author -- perhaps you just want to document what you've done on a repo, not the contributions of other people. Also especially handy, if you don't want to bore people with too much detail, is the \"fuzz\" option. This lets you tell git2gannt how relaxed you want it to be when it tries to decide how long a run of work on a repo lasted. So, perhaps, you're working on and off on a library that supports some other system you're documenting, but you might only be making changes every other day or so. With the correct fuzz value you can make it clear you were working on the library for a couple of weeks, despite there only being a commit every other day. An example of running the output over a handful of projects would look something like this: This is one of those tools I knocked up quickly to get a job done, and haven't quite got round to finishing off fully. One thing I'd really like to do is add mermaid support directly within it, so that it actually has the option to emit plots, not just mermaid code (or, perhaps, drop the mermaid approach and use something else entirely). Meanwhile though, if you're looking for something quick and dirty that will help you visualise what you've been working on and when for a good period of time... perhaps this will help."},{"title":"Being phony, and Lispy regular expressions","url":"/2019/12/01/being-phony-and-lispy-regular-expressions.html","date":"2019-12-01","content":"While it does seem that they're a little out of fashion these days, in some circles anyway, I'm still an avid fan of make and make files. Even in environments where I don't need a Makefile to actually build anything, I'll use one (or more) to help create handy shortcuts for getting stuff done. Looking at the main Makefile for one of my major work projects, there's 45 targets that help fire off various jobs (all of them self-documenting using a variation on an approach I read a while back ). In most cases the targets aren't real targets. That's to say, they don't build the thing they're called. They are phony targets . So, as makes sense, I make a point of marking them all as such. I follow the convention that has the .PHONY marker appear on the line before the target; this feels cleaner to me and easier to follow and maintain. But.... I'm lazy. And I use Emacs. Typing out .PHONY foo all the time feels like far too much work. So, some time ago, I quickly threw together make-phony.el . With this I could be really lazy. I could type out the Makefile target and then, with my cursor on it, press a key combination and have the .PHONY marker put in place. Does it save much time? Yeah, probably not really. But it was a fun little exercise and an excuse to write a little bit of Emacs Lisp. There's one thing I made a point of doing in the heart of this too: using rx . For anyone who doesn't know of it, think of it as a very Lispy way of writing regular expressions. I won't even try and explain it all here because others have done an excellent job already . What I will do is say this: if you're in the habit of writing some Emacs Lisp, or even tinkering with your configuration, and you find yourself writing a regular expression, consider looking at rx -- it's well worth the time to get to know it. Slowly, as time goes on, I'm weeding out \"vanilla\" regular expressions from my config and code and moving over to using rx . I feel, quite rightly I think, that something like this : ( rx ( or ;; Ignore hidden files. ( group bol &quot;.&quot; ) ;; I never want to edit the desktop. ( group &quot;Desktop/&quot; eol ) ;; Ignore compiled files. ( group &quot;.&quot; ( or &quot;pyc&quot; &quot;elc&quot; ) eol ) ( group &quot;.egg-info/&quot; eol ))) is much easier to write, read and maintain, than this: &quot;\\\\(^\\\\.\\\\)\\\\|\\\\(Desktop/$\\\\)\\\\|\\\\(\\\\.\\\\(?:\\\\(?:\\\\(?:el\\\\|py\\\\)c\\\\)\\\\)$\\\\)\\\\|\\\\(\\\\.egg-info/$\\\\)&quot; I mean, even if the regular expression above can be written in a more efficient way (and I imagine it can), as someone working in a Lisp environment, I'd much sooner write and work with the rx version."},{"title":"EmacsConf 2019 videos are out","url":"/2019/11/24/emacsconf-2019-videos-are-out.html","date":"2019-11-24","content":"At the start of this month I spent a very enjoyable Saturday afternoon watching EmacsConf 2019 . If you missed it, or even if you didn't, you might like to know that the announcement has gone out that almost all of the videos are now available for watching . While I mean nothing negative about any other video, I think the two that stand out the most for me, in terms of things that grabbed my interest, were How a Completely Blind Manager/Dev Uses Emacs Every Day and Emacs as my Go To Script Language . I seem to recall that both those talks were hit with technical issues (many talks on the day were -- part of the enjoyment for me was how the whole conference was an experiment in using Free Software to host the whole thing), but they're well worth a watch despite this. If you have any sort of interest in Emacs I'd highly recommend dipping into the whole collection. I really hope there's going to be a 2020 EmacsConf."},{"title":"Visual evolution of ~/.emacs.d","url":"/2019/11/23/visual-evolution-of-emacs-config.html","date":"2019-11-23","content":"As detailed in a blog post I wrote back in 2016 , I first got into using Emacs in the mid 1990s, starting with it on OS/2 and then moving over to GNU/Linux. It's been my often-used and much-loved development environment for most of those years (I even have a couple of packages that are part of Emacs itself). For most of that time my configuration was a single ~/.emacs file, which was around 1,000 lines in length (including comments and whitespace). It'd grown over the years, having special configuration sections for versions of Emacs I didn't use any more, and operating systems I didn't work on any more (yes, really, there were things in there specific to MS-DOS, for example). On top of that I always hand-installed packages I used -- Emacs' package management system having turned up long after I first got into using Emacs. Then, in early 2016, I decided to nuke the whole thing and start from scratch. As mentioned above, the start of this is detailed in an older post . Another big round of changes happened round a year later -- which included the birth of delpa to manage my personal packages. A couple or so months later there was one last big round of changes , mostly killing off my enthusiastic embracing of customize and instead going back to hand-set settings, only this time done via use-package . The full history of this can be found over on GitHub , starting with the first \"throw everything away and start again\" process and all the steps between then and where my Emacs configuration is now. Which brings me to the fun part of this blog post. Earlier this week I stumbled on Gource . It's a tool that's primarily designed to visualise changes in repositories, although it can be used to visualise anything that has a tree structure and changes over time (this week I produced a video of the growth of my employer's electronic lab notebook by hooking up the Benchling API with Gource, for example). So I got curious. What did it look like as I reworked and tweaked and changed and tinkered with my Emacs configuration? This is what it looked like:"},{"title":"Getting started","url":"/2019/11/17/getting-started.html","date":"2019-11-17","content":"By coincidence, in a couple of different places over the last couple of weeks, the subject of \"how do I progress in leaning to program?\" has cropped up. For me, I think the approaches and solutions tend to be the same for when I want to get my head around a new language: read good examples of idiomatic code, read other related materials, find a problem you care about and implement a solution (ideally something you'll directly benefit from, or at least others may benefit from). Hence the 5x5 puzzle and Norton Guide reader projects I mentioned in my previous post . Of course, not everyone has problems that they need solving in a way that would work for this approach. So another approach I've recommended in the past is to go looking on somewhere like GitHub and find projects that promote \"low-hanging fruit\" issues in a way that's designed to be friendly for those who are new to development, new to contributing or new to the problem domain. While looking for examples of this yesterday I stumbled on Awesome for Beginners . This looks like a great list and one I'm going to keep bookmarked for future reference . Now, this particular list does seem to have an emphasis on pulling in people who are new to contributing to a project rather than new to development, but it does strike me as a good place to start looking no matter where you're coming from. I know I'm going to start having a wander around that list. It's always nice to contribute and I feel there's real personal benefit in actively solving a problem that someone else has and welcomes help with."},{"title":"Going on a journey","url":"/2019/11/10/going-on-a-journey.html","date":"2019-11-10","content":"It's hardly a revelation to say that learning a new programming language, or even learning software development at all, is even more difficult if you don't have an actual problem to solve. I know I'm not alone in having pet projects that, when faced with a new environment, I'll code up a version of that project as a way to get familiar with and understand a language's idioms while implementing something I know well. Personally, my two favourites are a puzzle called 5x5 ( here , here , here , here , here , here and here ), and writing a library or even a full application to read Norton Guide database files ( here , here , here , here , here , here , here and here ). Both are fun to work on, have practical uses, and both have the benefit of being solved problems (for me) that let me concentrate on the \"how do I do X in this language/toolkit/environment/framework/etc?\". Even with those two as my goto projects, I'm always open to new small problems that might be fun to apply to languages I do know, or languages I want to get to know (internally at work we have a fun \"league\" of sorts, writing a particular hamming distance calculation tool in different languages , for example). A few days ago, via this repo on GitHub , I discovered this fun little problem . Right away I could see the benefit in it. As a \"go away and code up a solution\" interview question it strikes me as near-perfect. It's obviously not hard to solve, but it touches on some basic but important aspects of software development and so will allow the developer to show off how they approach things. There's so many different approaches to it too. Even in a single language, I could imagine having some fun writing the smallest code to solve the problem, the most idiomatic code to solve the problem, the most supportable and well-documented code to solve the problem, etc. And then there's the thing I talk about above: knowing the solution and knowing it's easy, you can then use it to learn the idiomatic way of solving the problem in new languages. Even better, the README of the original repo links to solutions others have written . Knowing the problem, and knowing the solution, you can then go and read other people's code and learn something about different styles and different languages. Over the next few weeks, as I get free time, I think I might just do this. Take the \"Journeys\" problem and write versions in different languages I work with, or know, and also use it to get to know languages I've yet to know or use heavily (I'm especially keen to try a version in Julia -- a language I really like the look of and want to find a reason to use). Meanwhile, yesterday, I had a quick go at a first version in Python (aimed at Python 3.8 or higher): https://github.com/davep/journeys.py I set out to try and write something that was fairly idiomatic Python, which uses tools that I tend to employ when working on Python projects (pipenv, make, etc), and which also used something I've never quite found a need for so far in my usual coding, but which I can see being useful and helpful. I even threw in a couple of uses of PEP 572 ! I can see me tinkering with this some more over the next few days. I can even see me writing a very different implementation in Python, just for the fun of it. I think that's what I like about this little problem. It's a good way to do a bit of programming exercise; it's like the perfect way to do the programming equivalent of going for a short run."},{"title":"My Pylint shame","url":"/2019/11/04/my-pylint-shame.html","date":"2019-11-04","content":"I first got into Python in the mid-to-late 1990s. It's so far back that I think the copy of Programming Python that I have (sadly in storage at the moment) might be a first edition. I probably fell out of the habit of using Python some time in the early 2000s (that was when I met Ruby). It was only 22 months ago that I started using Python a lot thanks to a change of employer . As you might imagine, much had changed in the 15+ years since I'd last written a line of Python in anger. So, early on, I made a point of making Pylint part of my development process. All my projects have a make lint make target. All of my projects lint the code when I push to master in the company GitLab instance. These days I even use flycheck to keep me honest as I write my code; mostly gone are the days where I don't know of problems until I do a make lint . Leaning on Pylint in the early days of my new position made for a great Python refresher for me. Now, I still lean on it to make sure I don't make daft mistakes. But... Pylint and I don't always agree. And that's fine. For example, I really can't stand Pylint's approach to whitespace, and that is a hill I'll happily die on. Ditto the obsession with lines being no more than 80 characters wide (120 should be fine thanks). As such any project's .pylintrc has, as a bare minimum, this: [FORMAT] max-line-length=120 [MESSAGES CONTROL] disable=bad-whitespace Beyond that though, aside from one or two extras that pertain to particular projects, I'm happy with what Pylint complains about. There are exceptions though. There are times, simply due to the nature of the code involved, that Pylint's insistence on code purity isn't going to work. That's where I use its inline block disabling feature . It's handy and helps keep things clean (I won't deploy code that doesn't pass 10/10), but there is always this nagging doubt: if I've disabled a warning in the code, am I ever going to come back and revisit it? To help me think about coming back to such disables now and again, I thought it might be interesting to write a tool that'll show which warnings I disable most. It resulted in this fish abbr : abbr -g pylintshame &quot;rg --no-messages \\&quot;pylint:disable=\\&quot; | awk &#39;BEGIN{FS=\\&quot;disable=\\&quot;;}{print \\$2}&#39; | tr \\&quot;,\\&quot; \\&quot;\\n\\&quot; | sort | uniq -c | sort -hr&quot; The idea here being that it produces a \"Pylint hall of shame\", something like this: 12 wildcard-import 12 unused-wildcard-import 8 no-member 6 invalid-name 5 no-self-use 4 import-outside-toplevel 4 bare-except 2 unused-argument 2 too-many-public-methods 2 too-many-instance-attributes 2 not-callable 2 broad-except 1 wrong-import-position 1 wrong-import-order 1 unused-variable 1 unexpected-keyword-arg 1 too-many-locals 1 arguments-differ To break the pipeline down: rg --no-messages &quot;pylint:disable=&quot; First off, I use ripgrep (if you don't, you might want to have a good look at it -- I find it amazingly handy) to find everywhere in the code in and below the current directory (the --no-messages switch just stops any file I/O errors that might result from permission issues -- they're not interesting here) that contains a line that has a Pylint block disable (if you tend to format yours differently, you'll need to tweak the regular expression, of course). I then pipe it through awk : awk &#39;BEGIN{FS=&quot;disable=&quot;;}{print $2}&#39; so I can lazily extract everything after the disable= . Next up, because it's a possible list of things that can be disabled, I use tr : tr &quot;,&quot; &quot;\\n&quot; to turn any comma-separated list into multiple lines. Having got to this point, I sort the list, uniq the result, while prepending a count ( -c ), and then sort the result again, in reverse and sorting the numbers based on how a human would read the result ( -hr ). sort | uniq -c | sort -hr It's short, sweet and hacky, but does the job quite nicely. From now on, any time I get curious about which disables I'm leaning on too much, I can use this to take stock."},{"title":"EmacsConf 2019","url":"/2019/11/02/emacsconf-2019.html","date":"2019-11-02","content":"For anyone who doesn't know, today is the day for EmacsConf 2019 . As you might gather from the name, it's a conference all about Emacs, the joys of Emacs, Emacs Lisp and other Emacs-related things. Better still, it's an online conference (although there do appear to be a couple of related physical gatherings around the world). I've got snacks and drinks in and no plans for my Saturday, and I hope to follow the whole thing from start to finish. If Emacs is your thing, or knowing more about Emacs is your thing, be sure to check it out!"},{"title":"pydscheck -- A quick hack that keeps slowly growing","url":"/2019/10/26/pydscheck.html","date":"2019-10-26","content":"Something I always try to do when I'm coding is be consistent. I feel this is important. While people's coding standards may differ, I think different approaches are easier to handle if someone has been consistent with their style across all of their code. This also stands for documentation too. In my current position, I do a lot of Python coding, and one of the things I like about Python (there are things I don't like too, but that's not for now) is that it has doc-strings (just like my favourite language ). I use them extensively, ensuring every function and method has some form of documentation, and generally I use Sphinx to generate documentation from those doc-strings. Early on I was bothered by the fact that, just by the simple act of making typos, I wasn't keeping the form of the doc-strings consistent. And in this case it was a really simple thing that was bugging me. Normally, if I'm writing a single-line doc-string, I'll write like this: def one_liner (): &quot;&quot;&quot;Here is a one-line doc-string.&quot;&quot;&quot; So far, so good. But, if the doc-string is a multi-liner, I prefer the ending quotes to be on a line of their own, like this: def multi_liner (): &quot;&quot;&quot;Here is the first line. Here is another line. Here is the final line. &quot;&quot;&quot; &quot; But, sometimes, by accident, I'd leave a doc-string like this: def multi_liner (): &quot;&quot;&quot;Here is the first line. Here is another line. Here is the final line.&quot;&quot;&quot; &quot; While it's really not a big deal, it would bug me and every time I found one like this I'd \"fix\" it. Eventually, it bugged me enough that I decided I was going to write a little tool to find all such instances in my code and report them. My first approach was to think \"I could just do this with some regexp magic\", which was really a bad idea . Then I though, I know, I should use this as an excuse to to play with Python's ast library . That worked really well! I had the first version of the code up and running in no time. It was simple but did the job. It ran through Python code I threw at it and alerted me to both missing doc-strings, and doc-strings with the ending I didn't like. That served me for a while, until one day I realised that it wasn't quite doing the job correctly; it was only really looking at top-level functions and top-level methods in classes. Sometimes, not often, but sometimes, I'll define functions within functions, and I feel they deserve documentation too. So then I modified the code to ensure it walked every part of the AST. Since then, when I've run into new things and had new ideas, pydscheck has grown and grown. I've added checks that all mentioned parameters have a type; I've added checks that any function/method that returns something actually documents the return value; I've added checks that any documentation of a returned value includes its type; I've added checks that any function or method that yields a value documents that fact; I've added checks that ensure that every parameter is documented in some way. Each time I've done this it's helped uncover issues in my code's documentation that could be cleaner, and it's also given me a pet project to slowly better understand Python's AST. It could be that there are better tools out there, I'd have thought that a good doc-string linting tool would be something someone had already written. But this time around I was happy to NIH it because I needed a fun learning exercise that would also have some benefits for my day-to-day work. I'll caveat this with the fact that it's very particular to how I work and how I like my documentation to look, but if it sounds useful, here it is: https://github.com/davep/pydscheck . There's still lots I could do with it. First off I should really properly package it up so it can be installed as a command line tool via pip. Other things that would be handy would be to allow some form of customisation of how it works. I'm sure there's other fun things I can do with it too. That's part of the fun of having a pet project: you can tinker when you like and also get benefits from it as you use it."},{"title":"Why I really like fish abbreviations","url":"/2019/10/23/why-i-really-like-fish-abbreviations.html","date":"2019-10-23","content":"I'm filing this as a TIL because, while it wasn't T, I did L it very recently and it was a new trick that impacted on around 25 years if prior working practice. I think it must have been around 1991 when I first encountered 4DOS . While I'd used the odd Unix shell here and there previously, it'd only been in passing. It was 4DOS that first introduced me to the power of aliases on the command line. Many of the aliases I set up and used in 4DOS still remain with me to this day, on GNU/Linux and macOS, in some form or another. I'm sure I don't need to tell anyone reading this why aliases and cool and handy and pretty much vital if you do lots of work on the command line. And then, a couple or so weeks ago, as a very recent convert to fish , I discovered the abbr command. At first glance it didn't seem to make much sense. It was like alias , only it expanded what you typed rather than acted as a command in its own right. I did a bit of digging and some of it started to make sense. One thing that really won me over -- and while it's something that doesn't directly impact on me -- was the argument that it allows for a far more transparent command history; especially if you're likely to use a transcript of a shell session in a place where people might not know or have access to your aliases. Imagine being in a position where you have loads of handy and cool aliases, but you also need to record what you've done so other people can follow your work (does it show that I sit amongst people who maintain lab notebooks?); it seems like it would be a bit of a bother needing to record all of the aliases in your own work environment up front. Without that information few people will be able to make sense of the recorded commands, with that information they'd still need to double-check what each command does. So imagine an alias that, when used, expands in place. Then you'd get all of the benefit of aliases while also having a full and readable record of what you actually did. Seems neat! Here's a silly example. For a long time I've carried around an alias called greedy that runs something like this: du -hs * | sort -rh It's pretty straightforward: I'm using du to get a sense of which directories are using what space, and then using sort to make a worst-to-best-offender list out of it. So I could use an alias: alias greedy = &quot;du -hs * | sort -rh&quot; The only downside to this is that, any time I run it, if I were to record the shell session and make it available for someone else to read, they'd just see: ~/develop$ greedy 1 .1G JavaScript 824M C 699M rust 93M python 33M fonts 33M elisp 3 .4M zsh 3 .0M misc 1 .1M bash 840K ocaml 428K C++ 316K lisp 172K Swift 152K git 132K ruby 28K ObjC Now, with an abbreviation rather than an alias, I'd type greedy but as soon as I hit Enter it'd get expanded to something anyone could read and follow: ~/develop$ du -hs * | sort -rh 1 .1G JavaScript 824M C 699M rust 93M python 33M fonts 33M elisp 3 .4M zsh 3 .0M misc 1 .1M bash 840K ocaml 428K C++ 316K lisp 172K Swift 152K git 132K ruby 28K ObjC This is far from the only benefit of abbreviations; for most people it probably isn't one of the most important ones, but I find it neat and compelling and this alone drove me to rework almost all of my aliases as abbreviations. Having done that, I get other benefits too. For example, fish (like other shells) has good support for argument completion for well-known commands. The problem is, if you alias such a command, you don't get that completion. With an abbreviation though you do! All you need to do is type the abbreviation, hit space and it'll expand to the underlying command and then the full range of completion can happen. There's also one last reason why I like abbreviations over aliases, and it's kind of a silly one, but in a good way. It's actually fun to see what you type magically expand as you do things, it makes you look like you can type even faster than you normally can! ;-) PS: If you've never tried fish before and you're curious, it's easy to try in your browser ."},{"title":"gitweb.el -- Quickly visit a repo's forge from Emacs","url":"/2019/10/21/gitweb-el.html","date":"2019-10-21","content":"gh.fish , which I wrote about yesterday , actually sprang from something I initially wrote for Emacs. I'm often spending my time switching between Emacs and the command line (which is fast and easy -- I normally work on macOS and have Emacs and iTerm2 running full screen, and I can switch between them without ever taking my hands off the keyboard), so it makes sense to have some handy commands repeated in both places. So, originally, I'd written gitweb.el to open the current repo's \"forge\" in the web browser. As with the fish version, how it works is quite simple. I use shell-command-to-string to call git and find the origin URL for the current repo, and then manipulate it a bit to turn it into a normal browser-friendly URL. Finally, if I get something workable, I use browser-url to have the resulting page open in the browsing environment of choice. I have the command bound to a key combination that's similar to the ones I use with magit and forge , so in terms of muscle-memory it's easy for me to remember what to press when I quickly want to skip over from a magit view to the repo forge itself. Similar to what I wrote a couple of days back , I think this again illustrates how handy Emacs is as a work environment. While it's absolutely true that there are other development environments out there that offer similar extensibility, Emacs is the one I'm comfortable with, and it has a long history of offering this."},{"title":"gh.fish -- Quickly visit a repo's forge","url":"/2019/10/20/fg-fish.html","date":"2019-10-20","content":"These days fish is my shell of choice. I started out with bash back in the 1990s, went through a bit of a zsh / oh-my-zsh phase, but earlier this year finally settled on fish. At some point I might write a post about my fish config, and why fish works well for me. But that's an idea for another time. In this post I thought I'd share a little snippet of code that can come in handy now and again. Sometimes I find myself inside a git repo, in the shell, and I want to get to the \" forge \" for that repo. This is most often either on GitHub , or in a company-local installation of GitLab . To get there quickly I wrote gh.fish : ############################################################################## # Attempt go visit the origin hub for the current repo. function gh -d &quot;Visit the repo in its origin hub&quot; # Check that there is some sort of origin. set origin (git config --get remote.origin.url) # If we didn&#39;t get anything... if not test &quot;$origin&quot; # ...complain and exit. echo &quot;This doesn&#39;t appear to be a git repo with an origin&quot; return 1 end # Open in the browser. open &quot;https://&quot;(string replace &quot;:&quot; &quot;/&quot; (string replace -r &#39;\\.git$&#39; &quot;&quot; (string split &quot;@&quot; $origin)[ 2 ])) end ### gh.fish ends here The idea is pretty simple: I see if the repo has an origin of some description and, if it has, I slice and dice it into something that looks like the URL you'd expect to find for a GitHub or GitLab repo. Finally I use open to open the URL in the environment's browser of choice."},{"title":"pypath.el -- A little Emacs hack to help with Django","url":"/2019/10/19/pypath-el.html","date":"2019-10-19","content":"One of the things I really like about coding with Emacs is how I can easily identify a repeated task and turn it into a command in my environment, saving me a load of work down the line. pypath.el is one such example. In my day job I write a lot of Django code. As part of that, I write a good number of unit tests too. Sometimes I'll write the tests as I'm writing the code they test, other times I'm writing them afterwards; it all really depends on where my head's at and how the code is flowing. When I'm writing those tests, I often want to test them as I go. Given that starting up a test session can take a while, and given that running all the tests in the system can take a while, it's really handy if I can run that single test I'm working on. This is easy enough with Django. In my work environment it's normally something like: $ pipenv run ./manage.py test -v 2 app.test.some.sub.module.TestClass.test_method Only... typing out the: app . test . some . sub . module . TestClass . test_method part is a bit of a pain. Sure, once you've typed it the once you can use your shell of choice (mine being fish and on occasion eshell ) to recall it from history, but typing it out the first time is the annoying part. So this was the point where I took 1/2 hour or so to code up pypath.el to solve the problem for me. It gives me two commands: pypath : which simply places the dotted path of the current \"defun\" , within the context of being part of a Django system, into the clipboard buffer. pypath-django-test : which works similar to the above but places the whole Django testing command into the clipboard. With the above, I can work on a test, hit the latter command above, flip to my command line, paste and I'm running the test. Of course, I'm sure there's plenty of other handy ways to do this. Doubtless there's work environments where the test can be run right there, in the edit buffer, without flipping away, and which takes into account the fact that there's a pipenv-managed virtual environment involved, etc. If there is, that's great, but I don't think it'd work with how I work. And that's one of the things I really love about Emacs, and why it's still my work environment after almost 25 years of on and off use: with very little work on my part I can create a couple of commands that work exactly how I need them to. While it's great to create generally-useful code for Emacs that lots of people benefit from , sometimes the real value is that you can code up your own particular quirk and just get on with stuff . To conclude: this post isn't to show off pypath.el ; really this post is to sing the praises of Emacs and why it still works so well for me after all these years."},{"title":"Time to move on","url":"/2019/10/18/time-to-move-on.html","date":"2019-10-18","content":"It's well over a year since I last wrote something on this blog. As mentioned in the last post (and the one before), it's not for bad reasons or anything like that. Being in a new job, which actually isn't all that new now, has kept me busy in all the best ways possible. There's been other stuff going on too which has drawn on my attention and the time and motivation to blog, either random stuff, or more development-related stuff, just hasn't been there. Also... blogging via GitHub, using Jekyll, has lost a lot of its shine. It sort of makes sense, well, sort of made sense, but in the end it felt like more work than it should. Whereas most blogging systems tend to encourage just diving in and banging on the keyboard, there's just a bit more faff with the GitHub pages approach. So, with that in mind, and with no desire right now to roll my own (which would be fun, it has to be said), I'm going to skip off over to Hashnode's blogging system . It seems to have everything I'd want and I can slap it on a domain of mine. Most of my random musings about random things really happen on Twitter, so I can't imagine I'll be wanting to blog about normal/mundane things. What I would like to do is write about development-related things from time to time. So that would seem to fit even better. Anyway, enough of all this waffle. If you land here and it looks kind of quiet, that's because it has been quiet for a while and I'm now going to try and concentrate elsewhere, with a wish to do some coding-related writing now and again."},{"title":"A little speed issue with openpyxl","url":"/2018/06/02/a_little_speed_issue_with_openpyxl.html","date":"2018-06-02","content":"It's been very quiet on the blogging front, I'm afraid, mostly for the reasons I wrote about back in December last year . In that time I've been really very busy with work (in a good way, in a very good way) and there's not a whole lot of time to be toying with pet projects at home. However, finding myself with a spare hour or so, I wanted to write about something I did run into as part of some development at work, and which I thought might be worth writing about in case it helps someone else. Recently I've needed to write a library of code for loading data from Excel Workbooks. Given that the vast majority of coding I do at the moment is in Python, it made sense to make use of openpyxl . The initial prototype code I wrote worked well and it soon grew into a full-blown library that'll be used in a couple of work-related projects. But one thing kept niggling me... It just wasn't as fast as I'd expected. The workbooks I'm pulling data from aren't that large, and yet it was taking a noticeable number of seconds to read in the data, and when I let the code have a go at a directory full of such workbooks... even the fan on the machine would ramp up. It didn't seem right. I did a little bit of profiling and could see that the code was spending most of its time deep in the guts of some XML-parsing functions. While I know that an xlsx file is pretty much an XML document, it seemed odd to me that it would take so much time and effort to pull the data out from it. Given that I had other code to be writing, and given that the workbook-parsing code was \"good enough\" for the moment, I moved on for a short while. But, a couple of weeks back, I had a bit of spare time and decided to revisit it. I did some more searching on openpyxl and speed issues and almost everything I found said that the common problem was failing to open the workbook in read_only mode. That can't have been my problem because I'd being doing that from the very start. Eventually I came across a post somewhere (sorry, I've lost it for now -- I'll try and track it down again) that suggested that openpyxl was very slow to read from a workbook if you were reading one cell at a time, rather than using generators. The suggestion being that every time you pull a value form a cell, it has to parse the whole sheet up to that cell. Generators, on the other hand, would allow access to all the cells during one parse. This seemed a little unlikely to me -- I'd have expected the code to cache the parsing results or something like that -- but it also would explain what I was seeing. So I decided to give it a test. openpyxl-speed-issue is a version of the tests I wrote and ran and they absolutely show that there's a huge difference between cell-by-cell access vs generator access. Code like this: for row in range ( 1 , sheet . max_row + 1 ): for col in range ( 0 , sheet . max_column ): value = sheet [ row ][ col ] . value is far slower than something like this: for row in wb [ &quot;Test Sheet&quot; ] . rows : for cell in row : value = cell . value Here's an example of the difference in time, as seen on my iMac: $ make test pipenv run time ./read-using-generators 1 .59 real 0 .44 user 0 .04 sys pipenv run time ./read-using-peeking 25 .02 real 24 .88 user 0 .10 sys As you can see, the cell-by-cell approach is about 16 times slower than the generator approach. In most circumstances the generator approach would make most sense anyway, and in any other situation I probably would have used it and never have noticed this. However, the nature of the workbooks I need to pull data from means I need to \"peek ahead\" to make decisions about what I'm doing, so a more traditional loop over, with an index, made more sense. I can easily \"fix\" this by using the generator approach to build up a two-dimensional array of cells, acquired via the generator; so I can still do what I want and benefit from using generators. In conclusion: given that I found it difficult to find information about my speed issue, and given that the one off-hand comment I saw that suggested it was this wasn't exactly easy to find, I thought I'd write it all down too and create a repository of some test code to illustrate the issue . Hopefully someone else will benefit from this in the future."},{"title":"On to something new","url":"/2017/12/12/on_to_something_new.html","date":"2017-12-12","content":"Today is a fairly significant day for me. For the past 21 (and a bit) years I've worked for the same company. I know that, for lots of people in my industry, that's a hell of a long time to be in one position. It was a setup that served me pretty well; the company was small (I'm not much of a big company person), I generally got to dictate the development tools and direction, and I also got to work from home. The working from home part was especially helpful as other life events involved me and happened around me. The job I've been in has seen a marriage come and go, and a move from Hampshire to Lincolnshire, and then from Lincolnshire to Midlothian. There's been a few adventures along the way. But, three months ago, I got a call to say that I was to be made redundant. This sucked, obviously. It also appeared pretty stupid on the part of my employer: a company that is based around software had decided it no longer wanted an in-house software developer. A bold, and I think unwise, choice. From this point on they've decided to only go with contract developers and only contract developers from overseas (or so the story goes). As it goes, things have turned out okay. Today is my last day with my old employer and, as I'm sat here typing this out while having some lunch, I'm actually glad that it's coming to a close and that I can get to move on. I have a new employer, and will be starting in my new position during the first week of January. It'll be very different. It'll all be different. Not only will I be back working in an office (one where jeans and t-shirts are the norm, thankfully!), I'm also going to be working in an industry (as a developer still, of course) that I have no background in and no real knowledge of. It's going to be a seriously exciting challenge. Over the next couple of weeks I've got a fair amount of background reading (and video watching) to be doing. This isn't so much that I can get on with the job of development (although there will be a good bit of that to do too -- who doesn't want to be trying to understand new options for development?), it's more about understanding the language of the industry I'll be in and so that I can understand the needs of my users. Goodbye fashion retail and all related things. Hello genetics and... well, I don't know, I'm going to find out. :)"},{"title":"More revamping of my Emacs config","url":"/2017/07/13/more_revamping_of_my_emacs_config.html","date":"2017-07-13","content":"I've been pretty quiet on here since I last wrote about how I'd done a further revamp of my Emacs config, so I thought that subject would be a good reason to write another blog post. It'll be a mostly short one, and one to muse over something that's been bugging me for a while now: my decision to lean heavily on customize to set all sorts of settings. Initially, when I nuked my original config over a year ago , it seemed to make a lot of sense. Let all the tweaks and set values \"hide\" in a file of their own and try and keep the hand-edited config files as small and as clean as possible. Recently though I've got to thinking that this obscures too much, hides too much detail, and removes the ability to actually document what I'm doing and why. It also does make it tricky to adapt some settings to different platforms or even environments on a single platform. Another problem I've run into is this: when I made the second round of changes and decided to lean heavily on use-package , I soon ran into the minor issue of some packages not making sense, or even being needed, on some platforms (stuff that's useful on my macOS machines isn't always useful on my Windows machines, that sort of thing). While use-package can handle this easily thanks to the :if keyword, I'm still left with the fact that package-selected-packages still gets populated. Having package-selected-packages contain a list of installed packages likely makes sense if you're using just the Emacs package system and you're not doing the installing with use-package and :ensure . But with use-package and :ensure I feel like I've got far more control over things and can adapt what gets installed when depending on which Emacs I'm running where. But, because I'm syncing my ~/.emacs.d/.custom.el to all my machines too, any use-package that has a :if to not bother using a package has little effect because the package still ends up being listed/loaded/seen as part of the installation. Ideally, I think, I'd like to be able to have package-selected-packages held in its own file, or I'd only ever use ~/.emacs.d/.custom.el for local stuff (and so stop syncing it). Starting today I'm going about a process of moving as much as I can out of ~/.emacs.d/.custom.el and into hand-edited files. In some respects I guess I am going back to how I used to manage Emacs configuration, but this time it's not a massive monolithic file-of-Lisp, it's neatly broken down into sensible sections and it's also biased towards a \"grab and config this package\" approach. Meanwhile, I've not seen any good discussions online about customize vs \"hand-edit\", which strikes me as a little odd as it feels like the perfect \"religious issue\" for people to have endless disagreements over. I guess, over the next couple or so weeks, I'll find out if switching back was a good idea."},{"title":"Another revamp of my emacs config","url":"/2017/04/01/another_revamp_of_my_emacs_config.html","date":"2017-04-01","content":"Just under a year ago I decided to totally rewrite my GNU emacs config . As I wrote at the time, it'd been following me around all sorts of machines since the early 1990s, starting life on an OS/2 Warp machine and travelling via MS-DOS, GNU/Linux, Windows and, these days, macOS. The changes I made last year have served me really well, but there were two related issues with it that bothered me a little: the fact that I was maintaining a local library of elisp code in the repository and, worse still, I was storing the packages I'd installed from elpa and melpa in the repository as well. While this did mean it was pretty easy for me to start up a new installation of emacs on a machine -- all I had to do was clone the repo and run up emacs -- I wasn't happy with the duplication involved. I didn't like holding code in my .emacs.d repo that was already held in package archives. The solution I saw was in two parts: Get some of my code, that might be useful to others, into melpa. Somehow sort my own package archive for my personal code. Over the past week or so I've worked on this approach. It initially started with me tackling item 1 above: I tidied up and submitted obfusurl.el , protocols.el , services.el , thinks.el and uptimes.el . This was a really helpful process in that it allowed me to brush up on my elisp and emacs knowledge. It's a good 15+ years since I last wrote any significant elisp code and things have moved on a little in that time. Having done that I'd managed to move a handful of my own packages out of my local library of code, and so out of my .emacs.d repo, but it left me with the problem of what to do with the rest of it. That's when I discovered package-x and: ,----[ C-h f package-upload-buffer RET ] | package-upload-buffer is an interactive compiled Lisp function in | package-x.el. | | (package-upload-buffer) | | Upload the current buffer as a single-file Emacs Lisp package. | If package-archive-upload-base does not specify a valid upload | destination, prompt for one. `---- (plus package-upload-file too, of course). This meant I could, in effect, start my own personal package archive and look at tackling issue 2 above. This did give me one small problem though: how and where would I host the archive? I did consider hosting it on a DigitalOcean droplet, but that felt a little like overkill for something so simple. And then I realised: GitHub Pages ! All I needed to do was keep the package archive in its own repo (which I would have done anyway) and then make the whole repo the source for a GitHub Pages site. A quick test later and... it worked! So, by this point, I'd farmed some of my code off to melpa, and now had the rest of it in \"delpa\" (which I'd called my personal archive). I could now use the emacs package management system to install third party packages and also my own. But I was still left with one issue: I was still holding the installed packages inside my .emacs.d repo by way of ensuring that all machines were in sync in terms of what was installed. Now I needed to work out how to solve that. Around this time, as luck would have it, @tarsius had suggested I look at a package called use-package by @jwiegley . This was the bit I was missing. With use-package I would be able to declare which packages I needed, how they'd be installed and, most important of all, it could be set to handle the fact that the package wasn't even installed. If a package is requested and there is no local install use-package is smart enough to get the emacs package system to install it. So, given that, all I need to do was create a startup file that would declare the packages I use and I'd have a setup that should, once I'd cloned .emacs.d , self-install. Except... yeah, one more issue. use-package isn't part of GNU emacs yet so I'd need a method of getting it to auto-install so it could then handle everything else. As it was that was as easy as adding this to the start of my init.el . ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Make sure the package system is up and running early on. ( require &#39;package ) ( add-to-list &#39;package-archives &#39; ( &quot;melpa&quot; . &quot;http://melpa.org/packages/&quot; )) ( add-to-list &#39;package-archives &#39; ( &quot;delpa&quot; . &quot;http://blog.davep.org/delpa/&quot; )) ( package-initialize ) ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Bootstrap `use-package&#39; ( unless ( package-installed-p &#39;use-package ) ( package-refresh-contents ) ( package-install &#39;use-package )) With that in place I was able to nuke all my config on a machine, clone a fresh copy of .emacs.d (having now ceased tracking and storing the installed packages in that repo), run up emacs, wait a few moments and then find that everything was installed and ready to use. Perfect! My .emacs.d is now a lot smaller than it was before and, I think, even easier to maintain. Right now I think I'm very close to the ideal emacs config that I wanted to create when I did the complete rewrite a year ago."},{"title":"I want to like Gboard","url":"/2017/03/13/i_want_to_like_gboard.html","date":"2017-03-13","content":"I want to like Gboard. On paper it looks really rather good. It's a keyboard from Google, it ties in with your account, it syncs things, it has clever searching for emoji and gifs and the like... what's not to like? Problem is, I've been a user of SwiftKey since around 2011 (I think it was). I'm very used to how SwiftKey works and it also contains a lot of handy things. I like that it has smart completion, that it learns how I type a bit skewed and that it takes this into account, that I can turn off the fancy swipe typing and instead make use of handy gestures like swipe-left to delete a word. I like some of the themes a lot. Into the mix comes my iPad, which I use on occasion. The standard Apple keyboard is horrible and, sadly, I find SwiftKey on iOS just as frustrating. It seems to lack enough key features there (especially the word deletion gesture, as far as I can tell) that it's also a bit annoying. My dream of a consistent typing experience across all devices just wasn't happening -- until I found Gboard on iOS. That felt almost right. And from what I could tell it worked almost exactly the same on iOS and Android. So it felt like a good time to try and force myself to use Gboard on my Google Pixel and Nexus 7. Sadly, though, I'm just not getting on with it. It's okay. It's not bad. It's just... not good. I'm finding that it lacks enough useful things that it's a frustrating experience. Little things like: when I enter Google Search, there's no word completion in the keyboard (SwiftKey has that); the word deletion gesture (swipe left from the backspace key) seems very hit-and-miss; the most obvious completion for a word sometimes appears in the middle slot but, other times, in the left slot. And so on. Nothing huge. Nothing that's a show-stopper. But a handful of a little things that make me miss the comfortable home that is SwiftKey. Don't get me wrong, it does have some very handy and cleaver features too. The searching for emoji -- including showing them up as word completions -- is rather clever. The gif-search thing is all kinds of fun too (mostly used to annoy the hell out of my son on twitter ). None of those quite make up for the bits I miss from SwiftKey though. All that said, I've being making a point of pushing on with Gboard, thinking that most of my issues might just be because I'm too used to my \"old home\". Mostly this was working well, until I noticed something this morning. While reading the description for Gboard I noticed this handy thing in the \"Pro Tips\" section: Sync your learned words across devices to improve suggestions (enable in Gboard Settings Dictionary  Sync learned words). Useful! I'd assumed that this was the case anyway -- it's Google after all -- but it's good to know I can ensure it's turned on. So I went to turn it on. This is what I found: What the hell Google? Sure, I do have a Gsuite account on my phone -- as in various apps have access to a Gsuite account (Gmail, Drive, etc...) -- but it's not the primary account on my phone and it's not the account I'd really want to be doing the dictionary sync with anyway. If I've got dictionary sync I want it tied to the keyboard no matter the app I'm in, and no matter the account I'm using in that app. I want the keyboard to be tied to a specific account when it comes to sync (just like SwiftKey does it). This, I think, is a show-stopper for me. I can overlook the other niggles, I can learn to cope with it not being quite so perfect in some situations; but the blanket inability to do something as simple as cloud-sync the predictions and learn from how I type -- things that are, these days, central to what Google's about -- it's frankly stupid. I guess I'm going to have to keep Gboard as a backup keyboard for those times when I need to find the perfect gif."},{"title":"Google Now Achievements?","url":"/2017/03/12/google_now_achievements.html","date":"2017-03-12","content":"Over the past couple or so weeks I've been having some issues with Google Now. It first seemed to start on my Nexus 7, then appeared on my Nexus 6. More recently, even as of today, I've seen it on my Google Pixel . The problem is that, in the Google Now launcher (or on the Pixel, in the Pixel launcher), the Google Now page (that you swipe to the left for) sits empty for ages. All I see is the little animated waiting circle and nothing else. Once or twice I've had the Google app die and restart or, more often than not, after quite some time it finally loads up. The latter happened a little earlier and I noticed something I'd not seen before: What's with that \"Achievements\" menu option? You'll notice that the whole of the menu is blank -- no profile picture or anything and none of the menu options seemed to work. Eventually, after I'd left it for a while, it ended up working. And, once this happened, no \"Achievements\" option. Presumably this is some back-end server issue, I'm being served up something I'm not supposed to be seeing and it's confusing the client app. Okay, I don't know that's the case, but it has that sort of feel. So now I need to go looking for what this Achievements thing is all about. Using Google, obviously."},{"title":"jsNG","url":"/2017/03/10/jsng.html","date":"2017-03-10","content":"Like many programmers, I have a couple of \"Hello, World\" projects that I've carried with me over the years. One is 5x5 (which has been used to get to grips with things as diverse as the Palm Pilot and GNU emacs). Another is Norton Guides database readers . I've made Norton Guides tools that have allowed web servers to serve guides ( w3ng ), that have allowed you to convert guides to HTML ( ng2html ), that have let you read guides on OS/2 and GNU/Linux ( eg ) and also have let you read guides in Microsoft Windows ( weg ). It's a problem I know fairly well and one where I know the solution well enough so I can concentrate on learning the new language or environment. Recently I wanted to get to grips with some \"pure\" ES6 coding while also getting to know node.js . A new version of the Norton Guide code, written for this environment, seemed like a good thing to do. And so jsNG was born. At its core is a library of code for opening and reading data from Norton Guides databases . While I doubt it's good ES6 code, or even good node.js code, it's been very useful in giving me a fun problem to solve and it'll carry on being something I'll tweak and tinker with by way of trying new things out. On top of this I've built a handful of tools for working with Norton Guides databases. The most useful one at the moment (the others are more in the \"test the library\" than the \"make something handy with the library\" category) is ngserve . This is designed as a simple Norton Guides database HTTP server. When run, you give it a list of guides to serve: and it does the right thing. It has a small number of command line options that help configure what it does: Possibly the most useful are the ones that let you change how it handles \"higher\" DOS characters and, if you don't like the default colours and stuff, the option that lets you point to your own style sheet (note for now you'll need to host the stylesheet somewhere else -- ngserve won't serve it for you; I'm aiming to change that in some way in the near future). jsNG does have a fairly basic design compromise at its heart. In the very early version I started out using the async functions for opening and reading the guides. This got very tedious very quickly and I could see that it was going to make for a very messy library with a very messy interface. While it might not be in the spirit of node.js programming I decided to go with the sync version of the file IO functions and code up the core library based around this. This approach also means that I took another leap that I never have done with Norton Guides before: rather than doing the traditional thing of keeping an open handle into them and reading direct from the file as you navigate the guide, I simply read it all into a buffer in one go and keep it in memory. This is a \"guides are small, memory is cheap, things will go faster\" approach. It does mean that when you load up a load of guides into ngserve they're all sat in memory. The upside of this is that things should be a lot faster and the code is a lot easier to follow (I think). To put this in some perspective: I have a directory here that contains 110 Norton Guides files. They total 36M in size. If that seems like a lot of stuff to hold in memory... remind me how much is being used by your web browser so you can look at some hilarious kittens. ;) Anyway, that's where I'm at with it right now. The code is mostly settled and mostly tidy. I need to write up some documentation for it (and so I need to take a look at good JavaScript documentation tools) and perhaps tinker with ngserve a little more. I'd also like to do a new version of ng2html with this -- a version that makes it far easier to control the style of the output. I'm also tempted to do a CLI-based reader in pure ES6; something similar to EG or WEG . All in good time."},{"title":"Hello Google Pixel","url":"/2017/03/08/hello_google_pixel.html","date":"2017-03-08","content":"For the past two years I've, mostly, being happily using a Google Nexus 6 as my phone. In the past six months or so I've started to notice that it hasn't been quite as good as it was. The main problem, for me, was that the camera was starting to play out. The issues were the ones that I've seen reported elsewhere: use of the camera would quickly make the phone laggy, very slow response times on pressing the shutter, occasional failure to save an image, etc. This was generally frustrating and, even more so, because I'd got back into photoblogging . Meanwhile... I've been lusting over the Google Pixel ever since it was originally shown off. I was some way off my phone contract renewal and the price of a new Pixel was something I just couldn't justify. Last week though an offer cropped up that meant I could renew early and get a Pixel (including a free Daydream headset thrown in). Fast forward to Monday just gone and... So far I'm liking it rather a lot. It is odd that it's smaller in my hand than the Nexus 6 was (the XL wasn't an available option and I was also starting to think it was time to drop down in size a little again) but I'm also finding it a little easier to work with; it's also nice that it fits in trouser pockets as well as jacket pockets. It feels very fast (although every Android phone and tablet I've ever had have felt fast to start with) and smooth to use. I especially like the default feedback vibration -- it's a lot smoother yet also more reassuring than any I've felt before. The Google Assistant is proving to be very handy. I'm sort of used to it anyway thanks to having owned an Android Wear watch for a couple of years but having it on the phone like this seems like a natural next step. Another thing I'm getting very used to very quickly, and really liking a lot, is fingerprint recognition. I didn't think I needed it but now I'm wondering how I ever managed without it. Combined with the notification pull-down gesture that the recognition area supports it seems like a perfect way to open the get going with a phone. There's a couple of niggles with it, of course. The main one for me is the lack of wireless charging. That was something I really liked about the Nexus 6: I could be sat at my desk and have the phone sat on top of a charging pad, staying topped up. No such handy setup with the Pixel. The other thing is the lack of water resistance. To be fair: it's not something I've ever really felt I needed with other phones and I'm not in the habit of sticking them under water; but knowing that it doesn't matter too much if it gets exposed to rain would be nice. Other than that... there's not much else to say right now. It works and works well, the move from the N6 to it was pretty smooth and the Pixel has fallen perfectly into my normal routine."},{"title":"Seen by davep (the return)","url":"/2016/11/15/seen_by_davep_(the_return).html","date":"2016-11-15","content":"A few years back, not long after I got my first smartphone (a HTC Magic), I started maintaining a photoblog that was based around photos I took on that phone. The blog itself was very important to me as it covered a pretty difficult time in my life -- many of the images on it contained and conveyed feelings and emotions that seem a world away now, but which I never want to totally forget. It served as a visual diary, a note to future me. And, hopefully, it provided some entertainment for those who viewed it. Sadly the company who hosted it closed down and the whole thing was lost, except for a hasty (and only partially successful) backup to a Wordpress blog . After the blog died I sort of lost interest in trying to maintain one and, to some degree, lost interest in active photography in general. Between the blog disappearing and another disappointing event relating to photography I sort of lost confidence in myself and my ability to dare to publish photos online. This year, despite how shitty it's been for the world in general, has been a really good one for me. Lots of positive changes have happened and continue to happen and I noticed that I was starting to do the phone-based photoblog thing again, albeit only via twitter . Finally, this week, I've cracked and decided to make it \"official\". My old \"Seen by davep\" blog is reborn, with new content and the same old purpose. You can find it here: seenbydavep.blogspot.com The blog itself is still driven by twitter and the posts will still appear on twitter. In the background I have an IFTTT process running, watching for any tweet of mine with the #photoblog tag and creating a post on the blog from it. As for how often and what the content will be... simple: it'll be when I see something that I need to capture."},{"title":"A bit of a backlog at the Apple store","url":"/2016/11/03/a_bit_of_a_backlog_at_the_apple_store.html","date":"2016-11-03","content":"Over the past couple or so weeks my Macbook air has started to develop a minor, but irritating, hardware problem. Simply put, the left shift key fails now and again. I can press it and it does nothing. It's irritating because it messes with the flow of typing (especially when writing code) and the key also feels like it's sticking or clicking in a way that's different from all the other keys. Given that I pass through Edinburgh on a pretty regular basis I thought I'd drop in and have a quick chat with someone about it. While I didn't expect a fix there and then (although finding out it was a trivial issue would have been nice) I was hoping someone could take a quick look and let me know what might be going on. So, this morning, on the way to Waverley Station, I dropped in to the Apple store on Princes Street. I walked in and looked for a member of staff, all seemed to be busy to start with but one soon noticed that I looked a little lost and asked me if they could help. I explained the issue and she said I needed to pop upstairs to chat with the staff up there. So far so good. So, I headed up to the first floor and caught the attention of another member of staff. Having explained the exact same thing to them I was told I needed to speak with yet another staff member. The chap I needed to speak to had a queue (yes, a physical queue of people) waiting to speak to him. I joined the queue. About five minutes later I got to speak with him. I, again, explained the problem and was told that looking at it would be no problem and they could do so at around 4pm. This was at about 10am. Having gone through 3 people and spent 10 minutes doing so I found out that there was a six hour queue to have someone actually take a quick look at the issue. By that time I wouldn't even be in the same country, let alone the same city. So I had to say thanks but no thanks. So now it looks like I have to make an appointment for some point in the future and make a special trip into Edinburgh just so someone can check out a sticky key on my Macbook. Remind me again how the nice thing with Apple gear is that it \"just works\"..."},{"title":"Virgin East Coast 21","url":"/2016/11/03/virgin_east_coast_21.html","date":"2016-11-03","content":"Yesterday I got the call about the Virgin East Coast Ticket Wallet app that I was promised last week (well, actually, promised a couple of months back). It didn't go well. Well, I say \"didn't go well\", the conversation itself went very well, the chap I spoke to was polite and apologetic and helpful, but the outcome wasn't really very brilliant. It didn't get off to a brilliant start when I was first told that the solution to my problem was that I needed to uninstall and then reinstall the app (something I've done more than once while trying to get to the bottom of the problem). I asked if that was really necessary and I was informed that it was the only way to fix the problem of the tickets not showing. Problem is... that wasn't my problem. So I then had to explain the exact nature of the fault I was experiencing (and also explained my guess as to what the cause of the problem was). After that, much of the content of the conversation involved vaguely confidential information (nothing too terrible or that big a secret -- just stuff that isn't generally known yet) which I'm not going to repeat here. The upshot of the chat though is this: they can't do anything for me. Simply put: they acknowledge there's a problem with the app, the problem is at their end, it's a problem that needs to be fixed and there's nothing they can do to fix it any time soon. The causes of this will sound familiar to anyone with experience of large companies who outsource much of their development and get involved in areas that they might not have much experience with. I also found out the cause of some of the delay in actually getting back to me: the person who was supposed to originally call me went on maternity leave just after they'd first tried to call and, it seems, nobody thought to pick up their workload. This left me in the bizarre position of trying to call someone who was off work for an extended period of time, and whose phone wasn't being answered in any way. Of course, it doesn't explain why that person's boss, who I was promised a call from a short while after, never bothered to call. So, I think, to some degree, that's the end of this silly saga. Their software is buggy, they can't fix it any time soon, and I'm out of luck. As for the extra free tickets I was promised a couple of weeks back now... they've still not appeared. Time for me to chase that up again ."},{"title":"Evernote's confusing menu","url":"/2016/10/31/evernotes_confusing_menu.html","date":"2016-10-31","content":"The other day I stumbled on a tip about Evernote. It was a snippet of information in a bigger post on the Evernote blog so I saved it to Evernote (obviously) to take a look at later. The tip was that Ctrl-Cmd-B in Evernote (on the Mac) will format a body of text as source code. While I'm not in the habit of using Evernote to store code, not even snippets of code (that's something far better served by Gist ), it seemed like something worth committing to memory. This morning, while finally in front of a suitable machine, I took a look. Sure enough, there's the menu option. Handy! So I created a test note with some code in it so that I could see how it formatted it. I was curious to see if it just did simple fixed text or if it offered options to highlight various languages (I didn't hold out much hope for the latter, but it was worth a look). That's when it got odd. After I created a note and went to format some code, the menu option disappeared! From what I can tell, once it's gone, there's no way to get it back. At least, not until you actually close down Evernote and start it up again. Frustratingly, none of this is the case in the Windows version. While the key combination is different there, the menu option is available and stays available. The version of Evernote I have (on my iMac and my Macbook) is 6.9.2. The version number on Windows is 6.4.2 (after checking for updates -- I'm going to guess that the Mac and Windows version numbers don't match on purpose). Goodness knows what's going on here. All I can imagine is that it has something to do with a thread I found on Evernote's support forum that suggests that code block formatting is some sort of test/beta feature and can only be enabled via a settings option that isn't available via the version downloaded from the Apple App Store. So, at some point, I guess I'm going to have to uninstall Evernote from the Macbook and the iMac, reinstall from the Evernote website itself, and try this again. All of which seems a bit silly when the menu option is there and visible when I run Evernote up! Edit to add: Sure enough, removing the App Store version and installing the version from Evernote's own website, and then going into preferences and enabling the option, sorted it. It's still really odd they'd promote the facility via the blog and not mention it, and also very odd that the option would always show until the first time you're in a position to use it, and then it'd disappear."},{"title":"Virgin East Coast 20","url":"/2016/10/29/virgin_east_coast_20.html","date":"2016-10-29","content":"After my last post I sent off an email to chase up what was happening with the promised phone calls about the Ticket Wallet app and the general delays with getting things sorted. Here's what I wrote: Hi again Mike. It's now a week since you replied and, I think it's fair to note, it's no longer \"early\" this week. I've had no call -- neither form yourself nor from anyone related to the Ticket Wall App -- and I've not received the promised tickets either. While I do try to be patient I have to admit that it's starting to get very frustrating, being made lots of promises about progress that simply never happen. This has been going on for months now and I'm always having to chase things up. I'd very much appreciate it if you could explain to me what's going on, and why. A while later I got a reply. He said he'd be getting the tickets in the post the following day (so a Friday, which I think I can safely say isn't the start of the week) and would also phone me. The following day he did keep his promise. He called (I managed to miss him the first time, but when I was finally free I called back and we got to chat). He promised I'd get some more tickets early next week and also that someone with technical knowledge would finally call about the app problem. I have, of course, been here before. This is exactly the promise that was made a couple of months ago. It's easy to make the promise, apparently not so easy to deliver on it (or address the issue of not delivering on it). So now I wait. Again. I'll be sure to update when something happens (or doesn't)."},{"title":"Virgin East Coast 19","url":"/2016/10/27/virgin_east_coast_19.html","date":"2016-10-27","content":"I think I need to rethink the meaning of the word \"certainly\". Anyone still bothering to read this blog will recall that, last week , the Customer Relations Manager at Virgin East Coast said: If you can leave this with me I will certainly be in contact early next week to try and get this resolved once and for all. In the meantime I will pop a further couple of tickets in the post for you, just so you have them incase you need to travel urgently. That email was received last Thursday evening. It's now the following Thursday. Personally I'd take \"certainly\", in the above, to mean that there's little to no chance that I won't be contacted in the early part of this week, and that there's little to no chance that the tickets won't arrive in the early part of this week. I'd have thought that \"certainly\" would be used to create a huge contrast between what has gone on before, and what will follow. But, like I say, it's Thursday the following week and I've had no call from anyone about the Ticket Wallet app, I've had no call or email from Mike (the Customer Relations Manager) and the tickets haven't tumbled through the door. I'm not surprised. I'm not in the least bit surprised. I am, however, rather disappointed. And, of course, I'm now going to have to chase things up again ."},{"title":"Virgin East Coast 18","url":"/2016/10/24/virgin_east_coast_18.html","date":"2016-10-24","content":"Late on last week some progress was made with the issue of no longer being able to contact Mike at Virgin East Coast . After chasing up via twitter (mentioning the MD as well as the normal support account) I finally got a reply from the support account, saying they'd get a message to Mike and let him know what was going on. I wasn't really very hopeful about it, if I'm honest. If I couldn't get a reply from him via the channels I'd normally used what hope was there that I'd get a reply this way? The following day was mostly spent traveling but my phone was on and always to hand. I never received any call. However, late in the day I did get an email! This was the first direct contact, that replied to an attempt to contact him on the current issue, I'd had from the Customer Relations Manager since the previous month. Here's what he said (quoted in full): My sincere apologies for the silence, I have been away and it was remiss of my not to advise my regular contacts, of my colleagues details. If you can leave this with me I will certainly be in contact early next week to try and get this resolved once and for all. In the meantime I will pop a further couple of tickets in the post for you, just so you have them incase you need to travel urgently. My apologies again David, and I look forward to chatting early next week. I am, of course, a little skeptical of this at the moment. A few times before I've been told they'll be in contact \"early next week\", or something similar, and nothing has happened. It'll be interesting to see if this will be different. Will I get an update? Will I finally get a call about the Ticket Wallet app? Will the extra tickets turn up?"},{"title":"Virgin East Coast 17","url":"/2016/10/19/virgin_east_coast_17.html","date":"2016-10-19","content":"The Virgin East Coast Trains saga gets more and more odd. Following on from yesterday's update I thought I'd give Mike an actual call. As in, a call on the phone. I don't generally like calling people. I'm one of those people who gets a little anxious about using the phone and much prefer email. I'll use a phone as a last resort and, given how long this was going on for, I thought it time to break my normal \"no phone\" rule and pick mine up and call to find out what the hell is going on. Turns out the number is no longer available! The last email I have that was sent from Mike was on September 25th. The number I used was the one in the footer of that email. It doesn't work. There's also a land line given. Calling that gives the same result. As of now, if I try and call the customer relations manager for Virgin East Coast Trains, someone who I was referred to by David Horne (the MD), I get a message that the phone isn't available. I... Erm... What?!? So, given that, I thought I'd drop David a direct message on twitter. We'd spoken that way back on August 9th when he requested my contact details. Nope. Can't send him a DM any more. Guess I got unfollowed. So I've tried tweeting him instead: Dear @DavidHorne , I seem to no longer be able to contact the @Virgin_TrainsEC customer relations manager (your idea originally). What next? &mdash; Dave Pearson (@davepdotorg) October 19, 2016 This did get a reply from @Virgin_TrainsEC and I let them know what I was after. They say they've sent him an email too now: @davepdotorg @DavidHorne I have just sent an email Mike and asked for him or one of the team to contact you asap. ^SH &mdash; Virgin Trains EC (@Virgin_TrainsEC) October 19, 2016 Really, this is a silly mess again. My query is simple and straightforward. I'm simply chasing up two promises that were made by Mike, on behalf of Virgin. All I seem to be getting now on those two points is complete silence. I'm really not in the business of telling people how to do their jobs but... wouldn't customer relations involve actually talking to customers and delivering on promises made to them when you do talk to them? That strikes me as the sensible thing to do."},{"title":"Virgin East Coast 16","url":"/2016/10/18/virgin_east_coast_16.html","date":"2016-10-18","content":"It's now almost 2 weeks since I last posted an update here and, frustratingly, I don't really have much progress to write about. What had been a promising start (well, middle; the actual start of this process was as frustrating as hell; it was only when the MD got involved that things actually started to happen) has turned into more of the same: broken promises and lack of actual results. Only, this time, I'm not dealing with some call center. This time I'm dealing with the office of David Horne . Since I last wrote I've emailed Mike Ross three times. The first time was to chase up what was happening with the promised phone call regarding the Ticket Wallet app. Here's what I wrote 12 days ago (on 2016-10-06): Hi Mike. Just wanted to try and chase up what's happening with being able to speak with someone about the original problem with the Ticket Wallet app. It's now around 2 months since I missed the single call from Katie Fisher (which I attempted to return every day for a week after, and a couple of times the second week after -- never able to leave a message because there was no voicemail system). It's now also over a month since you said that a David Ridley (you you said was Katie's boss) would contact me and I've still not had any sort of call. With respect, this is exactly the sort of thing that I initially found frustrating about dealing with Virgin East Coast Trains: the promises of calls to get things sorted that never happen and the constant need, on my part, to chase things up to even try and get something happening. It's also nearly 4 months since I first ran into the original problem and I'm still no nearer getting an explanation as to what the problem is or any nobody would initially believe the problem I was reporting. Could I please get an honest update on what's happening with this? This got no reply whatsoever. Now, I appreciate that people can be busy, but when you have an ongoing issue to resolve with someone it makes sense you at least say something like \"I'm sorry, my attention is elsewhere at the moment -- I promise I'll get back to you as soon as possible\". That's not an ideal thing to do, especially if your job us customer relations, but at least it lets the customer know you're there and listening. But, no, nothing. So 5 days ago I replied to the above, with a little chaser: Hi Mike. Sorry to trouble you but given it's a week since I wrote, I wanted to chase this up. And still nothing. Later this week I'll be on the trains again and, despite getting no sort of reply whatsoever from Mike, I decided to drop a line anyway and ask for seat reservations to be made (as had originally been offered). These were done in no time at all. While that is great it also tells me something rather odd: my emails are being read and acted upon -- at least when they're a request for a seat reservation -- but they're not being replied to. And here's the thing that's even more frustrating about this. The email where I requested the seat reservations had this on the end as a PS: PS: Did you receive the catch-up email I sent last week? Seeing as how I'm about to use the last set of tickets you provided me I'm very keen to get to the bottom of the Ticket Wallet app problem so I can finally resolve the problem of getting WiFi on the train and working without having to spend 10 extra every time. That has to have been read and... given the lack of reply I can only conclude that it was ignored. I like to think it wasn't really ignored but a lack of reply looks exactly like you're being ignored. At this point I don't know what to make of this any more. It's a simple problem I'm trying to get to the bottom of. I've been made plenty of good promises, almost all of them broken. On top of that I can't really escalate the issue any more because I'm already receiving the best help that Virgin East Coast's MD can offer, apparently. Anyone got Richard Branson's phone number?"},{"title":"Virgin East Coast 15","url":"/2016/09/29/virgin_east_coast_15.html","date":"2016-09-29","content":"It's now a week since I last wrote an update and, given that I'm sat on a Virgin East Coast train right now, I thought I'd do another. As mentioned last time, I'm currently waiting for a call from someone at Virgin East Coast regarding the ongoing situation with the Android Ticket Wallet application. It's now over 3 months since I first ran into the problem (and, of course, ran into all the issues of trying to get some sensible help and response from them) and nothing has really improved: It's now around six weeks since I was promised a call from someone who works on the application; a call that did come the once but I couldn't answer at the time (I'm not the sort of person to fiddle with a phone while driving) and which I attempted to return for the better part of 2 weeks afterwards but never even got an answer to the calls. It's now also 3 weeks since I was told that I'd get a call from the boss of the person who was originally supposed to call me. I've yet to receive a call from them too. I've mentioned this to Mike Ross on a couple of occasions now and haven't had any sort of direct reply as to what's going on with that situation. While I am enjoying the benefits of the tickets I was provided as compensation from the earlier troubles (and also very much appreciating Mike's reserving of seats for me when I need them -- I do find that booked seats take a lot of stress out of traveling) I'd really love to get to the bottom of the problem with the Ticket Wallet app. Frustratingly and amusingly I suspect I'll finally get an answer around the time I don't need to use the train quite so much."},{"title":"Virgin East Coast 14","url":"/2016/09/22/virgin_east_coast_14.html","date":"2016-09-22","content":"It's now about 3 weeks since my last post about my exploits in getting a problem solved with Virgin East Coast so now's a good time for a little update. Two things were \"outstanding\" the last time I wrote about this. One was that Mike (the customer relations manager in the Virgin East Coast MD 's office) wanted us to meet up for a coffee and a chat about my issues and how things were progressing, etc. Sadly I wasn't able to make the original date we'd picked out as a possible so another date was arranged. At least, it was kind of arranged. It was noted that this week might be a good time to meet and I'd written back to him to say that Wednesday 21st would be good. Since then I've had no reply at all. The second thing that is outstanding is having someone call me about the issues with the Ticket Wallet app. I've yet to receive a call from the person who originally phoned me and who I missed (and who I chased up every day for a week afterwards). I was then told by Mike, about 2 weeks or so back, that that person's manager would call me instead and that I should expect a call early last week. That call didn't happen. Didn't happen early last week, late last week, at all last week. It's now Thursday this week and I've still not had a call. Just this morning I've chased up both of the above. It's now over 3 months since I first reported the Ticket Wallet app problem and I seem to be no closer to seeing it resolved, or even having an explanation as to the cause of the problem."},{"title":"Virgin East Coast 13","url":"/2016/09/02/virgin_east_coast_13.html","date":"2016-09-02","content":"It's just over 3 weeks now since I wrote about how I was finally getting somewhere with my problems with Virgin East Coast , so now seems like a good time to update on what's happening. Here's the things that the PR manager in the MD's office said he'd be sorting, along with what happened afterwards: Virgin would BACS me the value of the cheque they kept failing to send This happened and happened quickly too. The money turned up in my account (actually rounded up a little) without any fuss or bother. That said... I did receive a cheque from them anyway that is written to a value that has no relation to the refund I was entitled to and isn't even similar to the rounded-up value that I received via BACS. I've not done anything with the cheque yet; there was no accompanying letter to say what it was for, nothing to explain why it differed by around 10 (more) from what I was expecting and what turned up in my account, nothing to explain why I was getting it at all. I emailed Mike (the customer relations manager) last Friday and got a reply last Saturday so say he'd look into it when he got back to his desk this last Tuesday (Monday being a Bank Holiday in England and Wales). I'm writing this on Friday morning and haven't had that update yet (so I have sent off an email to chase this up). In the mean time I'm doing nothing with the cheque. It seems unfair to cash it if it was a simple error on their part. Someone with knowledge of the Ticket Wallet App would phone me direct This happened. Sort of. The day after things started to get resolved I received a call. Sadly I was driving at the time and was in no position to take it. When I finally got home and tried calling back there was no answer. Since then I've tried calling the number every day for the first week and a couple of times in the second week; I've had no answer at all. Neither have I received a call from the person who originally tried calling. I let Mike know about this in an email about a week back and he said he'd chase it up. So far I've had no word on the subject since (again, I've sent off an email chasing this up this morning). They'd send me 4 First Class return tickets by way of an apology This happened and happened quickly. I've no complaints on this score. Also, Mike has been very kind in allowing me to email him direct to arrange seat reservations each time I've needed to use a ticket (once so far, second request went off this morning for the use of the second of the tickets). The CR manager would keep in contact to update me on how things are being improved This one not quite so much, but I didn't see this as quite so important and it wasn't something I was looking for. What mattered to me was that the refund I was owed got to me and that the apparent problem with the Ticket Wallet app got fixed. That said... back in the early 1990s a lot of software that I developed was designed for complaints handling departments (used in some pretty well-known companies too). It was all about keeping customers happy, keeping in contact with them, keeping track of how well you're doing, keeping track of promised contact dates and ensuring they were met (that whole thing of a call to say you've failed is better than no call so you appear to have failed twice), that sort of thing. I guess, from this point of view, I do have an interest in how Virgin East Coast handle their customer relations and what systems they have in place so they appear to be competent. As for getting to chat: Mike did name a couple of dates when he'd be close to where I tend to be working and suggested we get together for a coffee and a chat about this subject. Given we've both got fluid diaries (his far more than mine, I'm sure) it's all a little up in the air but I think there's a possible date in the next week. So that's where I'm at: one problem solved (with an offshoot curiosity that I'm trying to get to the bottom of) and one outstanding. Not perfect. Not terrible either."},{"title":"Virgin East Coast 12","url":"/2016/08/10/virgin_east_coast_12.html","date":"2016-08-10","content":"Just one day on from yesterday's update post where I wrote about how pretty much every promise made by Virgin East Coast had (once again) been broken and it looks like it's all change (or at least looks a lot more promising now). After I wrote the post I did the usual thing of tweeting it and I then went about the business of sending off yet another set of chase-up emails. The first to come back was from the person dealing with the compensation cheque. I'd pointed out that it was now a week since the sending of the cheque via recorded delivery was supposed to have happened and that nothing had turned up. This was the reply: I am sorry to hear this still has not happened. Would it be possible for you to send me your address so that I can track the cheque and I will find out as soon as possible where this is. I apologise for the delay, but rest assured my number one goal is to get this issue resolved for you. I look forward to hearing from you. This actually annoyed me a little. I'd asked when the cheque had been sent and also how it'd been sent so that I could see if the original promise had been kept. The answer appeared to be avoiding that question. On subsequent replies I was told that it had been issued the week earlier but hadn't been dealt with in person: I followed it up with our fulfilment department and they told me that they had it in the office with them. It is the one that was originally sent out on the 2nd August and for some reason had not been issued by that department. Our fulfilment is outsourced and so when we raise letters or cheques we phone them to check on the progress. I am sorry that they did not issue it but rest assured it has been sent now as I made it a case of urgency due to the delays you have already experienced. I can only apologise for the further delay. Given all the previous conversations where I was told about how they were moving some systems that dealt with this -- which were previously outsourced -- in-house (although apparently not the part that involves actually sending cheques) I'm even more strongly suspecting that the first couple of attempts to send the cheque never actually happened. Anyway, long story short(ish): after a bit of back and forth to get to the bottom of what was actually going on I was assured that the cheque had finally been sent. Frustratingly this wasn't quite what I wanted. I'm unlikely to be around to receive an item of post sent via recorded delivery so I'd have liked it to be sent elsewhere (it should be no surprise that people who use Virgin East Coast's services a fair bit are also quite likely to be away from their normal address quite a bit during \"normal\" hours). That said... some progress there. While it'd taken far too long to get it resolved, it was finally starting to appear like it was being resolved. This approach was, however, being rendered moot by other events. Backing up again to yesterday: after I'd tweeted about the blog post, and mentioned @Virgin_TrainsEC so they could have a chance to see and respond (they didn't this time), my adorable girlfriend did a bit of checking in the background and did a little retweet: For goodness sake, sort this out @DavidHorne @AliWatson23 https://t.co/JibgmfZwjD - 8 weeks, 11 blogs, no progress! https://t.co/iUTCApBnC7 &mdash; Jo (@0rangelic) August 9, 2016 I was sceptical that this would have any effect. I'd been promised a call or something from the \"MD's Office\" by the customer support people over a week ago and nothing had happened. Even when I'd sent them a follow-up DM near the end of the week I got no reply at all. I'd got to the point where I'd assumed I was just being fobbed off. I was wrong to think so though . While the request to email the details of the issue was slightly frustrating (you'd think 11 blog posts would document the issues in enough detail, and a link was provided) it was heartening to see something happening. I did point this out to David: @DavidHorne @0rangelic You&#39;ll find all the details on the linked blog post (and previous 10). Plus in @Virgin_TrainsEC systems (hopefully). &mdash; Dave Pearson (@davepdotorg) August 9, 2016 and also point out that if the details weren't in their system, that might be a brilliant illustration of the cause of the issues: @DavidHorne @0rangelic @Virgin_TrainsEC If not, there&#39;s the real problem. ;-) &mdash; Dave Pearson (@davepdotorg) August 9, 2016 I didn't hear much more until around 18:30 when, all credit to him, David did check that I'd had someone contact me: @DavidHorne Not from your office, as far as I&#39;m aware of (which was promised for last week but never happened), if that&#39;s what you mean. &mdash; Dave Pearson (@davepdotorg) August 9, 2016 At that point he asked me for some contact details (again, a slightly frustrating indication of an organisation that doesn't have joined-up systems) which I provided (my main email address and my mobile number). I didn't hear anything more that evening but, earlier today, I had an email from a Mike Ross (\"Customer Relations Manager - MD's Office\" according to the bottom of the email). He said he'd like to have a chat and could I let him know when would be a good time to call. I replied saying any time during normal business hours would be good for me. That call made all the difference. As well as obviously offering an apology for all that had happened so far, Mike was kind enough to both explain what was likely happening and why (they inherited a setup that involved a lot of outsourced contracts for lots of parts of the business -- something they're fixing by bringing many systems back in-house) while also actually listening to what I was saying. More to the point though, he made very clear promises on how he was going to get my issues solved. Here's the outcome of that conversation: Any and all cheques raised to try and get the refund to me will be stopped and the payment sent to me via BACS (something they're not set up for doing in general but which they're working on fixing). Someone with good knowledge of their Ticket Wallet App and their website will give me a call in the next day or so to go over the issues and try and get things working (or at least ensure there's a good understanding of the cause of the problem). By way of saying thanks they're going to send me four first class open return tickets for use on the East Coast line. I think that's a very kind and generous gesture and one that's going to be very useful to me over the next couple of months. (the tickets come with the offer of being able to email Mike's office and have them sort the booking of an actual seat for each journey). Mike has also said he wants to stay in touch and keep me informed of how things are changing in Virgin East Coast so that the issues I've experienced have less chance of happening in the future. Related to the above he's also said he'd like to meet up for coffee once or twice to go over things and have a chat about how the company appear to a paying customer. While I'd never hold myself up as a typical customer, and especially not one who has any particular insight, I think it's an impressive approach to take. I am, of course, feeling cautious about all of the above. It is \"just\" another set of promises that could be easily broken and, so far, VEC don't have a brilliant track record of doing that. But the promises appeared genuine and to think otherwise would be to not allow them to fix the issues. I'll write more about it on the blog as things happen."},{"title":"Virgin East Coast 11","url":"/2016/08/09/virgin_east_coast_11.html","date":"2016-08-09","content":"It's now another Tuesday morning. It's the Tuesday morning after the previous Tuesday morning when I was waiting on some sort of call from Virgin regarding the missing refund. After I wrote that last post I dropped the chap I'd spoken to an email to chase up what was happening. This was his reply: I am sorry that I was not able to contact you yesterday as this system switchover is happening we are going through an extremely busy period in the business. I have looked into your case and have reissued the cheque that you did not receive and that should be with you shortly. Under normal circumstances I'd imagine a cheque sent in the post would arrive within a couple of working days. Given that was last Tuesday I think it's fair to say that it should have turned up by last Friday. Thing is, when I'd spoken to that chap the week before he'd assured me that they'd send this cheque by recorded delivery to ensure that it got through. I still don't have the cheque. I guess this means one of 3 things has happened: He said he'd sent it, but he hadn't. He did send it, but not via recorded delivery, and it's disappeared into whatever black hole snail mail from Virgin East Coast seems to be disappearing into. He did send it, via recorded delivery, and we now have some clue as to where the above black hole is located. Whatever the cause, I'm going to have to drop him a line again and find out what's happening. On a previous post about this issue my friend Mark raised an interesting issue: if Virgin had lost access to the required data because they'd ceased using the services of some third party (as was claimed), what did this mean in data protection terms? I'd not really considered this but it was a fair question. When I last emailed Virgin I asked about this too: As an aside, could I also ask who's a good person to speak to about what was happening with my data during the period Virgin East Coast didn't have access to it? Thanks. That question got this reply: The data is still with us as a company it is just in the process of being uploaded onto our systems. The information has never left our company it is just in the process of being updated onto our systems. For now, at least, I'm happy enough with that as an explanation. I'm going to apply Hanlon's Razor to this and assume it was just clumsy wording when the subject first came up. So, to summarise this situation so far: a late journey that happened back on June 2nd, for which compensation was confirmed in email on June 6th, the cheque for which was supposed to turn up early July at the latest, still hasn't appeared by August 8th. Worse still, I've been told 3 times now that \"the cheque is in the post\" and on at least one of those occasions it appears to have been an outright fib due to the closing of some of their systems. On top of the above, there's another contact I'm awaiting that has yet to happen. Last week, when I tweeted about the previous post, the Virgin East Coast twitter people asked me to provide them with my contact details. @davepdotorg Dave, can you DM us your contact details? ^AD &mdash; Virgin Trains EC (@Virgin_TrainsEC) July 29, 2016 I checked with them why they needed the details (given that they're obviously already on the system) and they said that they'd escalated it to the \"Managing Director's office\" and that they wanted my contact details so that office could contact me. I provided them and also pointed out that email is normally the best way to contact me -- they then asked for the best email address to contact me on and I provided that too. Having done that I was told they'd be in touch \"next week\". In this case \"next week\" was any time last week (as of the time of writing and publishing). Nobody got in contact last week. Nobody from a \"Managing Director's Office\", nobody at all from Virgin East Coast. So, as of right now, I'm waiting on the following from Virgin East Coast, all promised by them: A reply as to what's happening with the inability to log in with the Ticket Wallet application (outstanding since 2016-07-15, although really outstanding from a while before then). A cheque that was supposed to have been sent via recorded delivery on 2016-08-02. Some form of contact from the \"Managing Director's office\" that was promised on 2016-07-29 and which was supposed to have happened some time between 2016-08-01 and 2016-08-05. This contact to, in part, deal with the two contact failures above. The unwillingness or inability to stay in contact with a customer who has problems does seem to be a persistent pattern. One that seems to go to the top. Right, time to publish this and start sending out even more chase-up emails. I guess it gives me something to keep me busy when I'm on the train."},{"title":"Virgin East Coast 10","url":"/2016/08/02/virgin_east_coast_10.html","date":"2016-08-02","content":"It's Tuesday morning. That means it's the day after Virgin said they'd call me back to deal with the refund issue from last Friday . I've not had a call back. That's the second time now I've been told they'll call me back on a specific date and I've had nothing. Right now I'm missing a callback about the refund and some sort of update on the ticket wallet issue (which was promised \"very soon\" back on July 15th ). I'm also waiting for some sort of contact from another party in the organisation that I was promised via DM on twitter last Friday. No sign of that either (although no timescale was given for that). It's starting to get a little tedious, always having to be the one to chase things up. But chase them up I will..."},{"title":"Virgin East Coast 9","url":"/2016/07/29/virgin_east_coast_9.html","date":"2016-07-29","content":"Given it's been a couple of weeks, I thought I'd write a little update on the fun and games with Virgin East Coast. I'll also add another little \"problem\" into the mix in this post -- something that has been happening in the background and didn't seem to be an issue to start with. As mentioned a couple of weeks back , I dropped them a line to chase things up (pointing out that the scheduled callback was long overdue) and got this reply on the 15th: Thank you for your email reply and apologies that I did not call you on the 11th I must have missed my Outlook reminder. I have today again tried to call our second line support team to query this again and see how far they are with this however they have not picked up so I have emailed them once again. Last time I spoke to them on the phone the person said that it should only be a few more days so hopefully I will be emailing you again very soon with some more substantial information on this for you. As I write this it's the 29th and I've had no update. I guess this is the problem with phrases like \"very soon\" -- you're never quite sure if you should read it to mean in the next couple of days, or if 14 days later still falls within \"very soon\". Personally, if it was me, I'd be dropping a line along the way to say \"it's taking longer than I'd like, but I'm still on it\". You know, that thing of ensuring the customer doesn't feel like they've been forgotten about. So, very soon 1 , I guess I'll be sending another follow-up email to try and find out what's going on. I'll update when I do. Meanwhile.... there's another issue that's brewing. Back at the start of June I was on a train that was delayed by more than half an hour. This is the first time this has happened to me since I've been using the trains a lot and I was delighted to find that they make a point of letting you know that you're entitled to a refund on your ticket, depending on how late you are . That struck me as very sensible and very civilised. So, when I finally got home, I put in my claim and on June 6th I got an email confirming I was entitled to a 50% refund and that it would be sent as a cheque to me within 28 days. Of course, 28 days later, nothing had turned up. I called them shortly after that to find out what was going on. They claimed the cheque had been sent and suggested it had got lost on the way (in the 2 years I've been at this address it's the first time I've knowingly had mail disappear). Anyway, they cancelled that cheque and issued another, apologising for the hassle and promising that the new one would be with me within a week. As it was I wasn't around for a couple of weeks after that so I got home yesterday, expecting to see the cheque on my doormat. I expected incorrectly. I've called them about it again today and was told the most interesting story: apparently they can't help me right now because they've closed down a call centre down in Plymouth (I think it was), which was \"outsourced\", and they now no longer have access to the \"computer system\" with all the cases in it. They assured me that they'd get access to it within the next week or two. Let that settle in for a moment: they apparently arranged to close down a call centre without ensuring that the computer systems that contain (some of?) their customers' data were handed over in some way, shape or form. That's a touch worrying. As you might imagine, I wasn't terribly pleased by this news. I'm a couple of months on from when the delay happened and I still don't have the cheque. On top of that, not having received the second attempt at sending it, I find out that nothing was likely being done about it because they'd (apparently) dropped the staff/company who would have been dealing with it. And I had to phone them (again) to find out. I imagine that if I'd just left it to them to get in contact and let me know, I'd have waited and waited and never got anything at all. Anyway, long story short, after pointing out that it was a bit much to ask me to let them hold onto my money even longer, just because of their system and business issues, I was passed to someone else who was able to suggest a far better and far quicker method of resolving this. So: I'm expecting a call back from them on Monday to get that process under way. I wonder if this callback will happen? Do you see what I did there?&#160; &#8617;"},{"title":"Virgin East Coast 8","url":"/2016/07/14/virgin_east_coast_8.html","date":"2016-07-14","content":"Remember this ? I will schedule in a contact back for you for Monday 11th July and after chasing them about this again I will contact you to let you know what is happening with this now. Well, it's now Thursday 14th and I've not had a peep out of them. I'm on a train today. I'm actually writing this on a train. I guess I'll have to think about chasing them up tomorrow (or perhaps at least chasing them up in email today)."},{"title":"Virgin East Coast 7","url":"/2016/07/08/virgin_east_coast_7.html","date":"2016-07-08","content":"Little update on the Virgin East Coast Ticket Wallet app saga. After my previous reply to them I got a reply back yesterday: Dear Mr Pearson Many thanks for your email dated 6th July 2016 regarding the fact that you cannot sign into your Virgin Trains ticket wallet app after registering on the desktop version of our website with the email address davep.org+virgin@gmail.com. I firstly apologise for the lack of understanding on the part of our Virgin Trains East Coast Web Support team with regards to this, the Mobile ticket issue on our app that you have described is one that has not occurred very frequently at all for any of our customers and as such this is what is causing the difficulty in resolving this for you. I have today spoken to our second line support team and asked them the question of if there is soon to be a fix for this for you to which they have stated that they need a few more days to get this fixed. I will schedule in a contact back for you for Monday 11th July and after chasing them about this again I will contact you to let you know what is happening with this now. While it's taken quite a while, it looks like I'm finally making some progress. If I'm reading it right they finally acknowledge that there is a problem and that it needs fixing. It's frustrating that I've had to go backwards and forwards a few times to get to this point. Monday will be interesting."},{"title":"Virgin East Coast 6","url":"/2016/07/06/virgin_east_coast_6.html","date":"2016-07-06","content":"It's been over a week now since I last had contact with customer services and there's still been no word. So, earlier today, I sent off an email. Short and sweet, requesting that I possibly get an answer to the questions I'd asked them: Hi, it's over a week now since I answered the couple of questions you asked and asked a couple of my own. Is it possible to get a reply and an update on what's happening? Later on in the day I got a reply: Dear Dave Thank you for your email dated 6th June 2016 concerning the tickets that you have not booked with us yet and the fact that your Mobile App ticket wallet is not able to show you anything after you have installed it. I am sorry to hear that there has been a mix up with the confirming to you if your email address has been registered or not and a such I wish to clarify this for you, also that there has been such a delay in responding to you. I can now confirm that your email address davep.org+virgin@gmail.com is registered on our website and that you have signed up for our Ticket wallet app successfully. We apologise for telling you that it was not but this could well have been that we were searching your email address that you have been emailing us from and this is what has caused the confusion. With regards to the use of our Ticket Wallet app before you have made a booking with us either on that or on our desktop site, it is believed that you will not be able to see much at all within the app before you make a booking with us however we have made the raise about this for you and we chased this up on the 27th June when you emailed us previously. I will chase this up again however if possible please confirm what page you get to in the ticket wallet app at the moment so that we can identify if this is normal for a customer has no booking allocated to the app. At this point I'm starting to seriously consider the idea that I'm being trolled. To start with, there's this bit: concerning the tickets that you have not booked with us yet It's hard not to read that as sarcasm. Any way I look at it it comes across as sarcasm. Sure, of course I've not booked any tickets direct with them (although I have booked lots of tickets with them this year via other websites) because of the issue -- that's the damn issue! Anyway, possible over-sensitivity on my part aside... The reply still seems to think that the problem is that I'm not seeing tickets I've not booked inside the Ticket Wallet app. That isn't the problem. The problem, as I clearly stated from the very start, is that I can't even log into the app. I. CAN'T. LOG. IN! I've said this plenty of times. I've made it very clear that this is the problem. And still I'm being asked: please confirm what page you get to in the ticket wallet app I'm really wondering what part of \"I can't even log into the app\" is so hard to understand. On the other hand, at least I've now got my second confirmation of the fact that I do actually have an account on their website, after being told I don't. I suppose that's something. Meanwhile.... the Ticket Wallet app is still telling me that my user name or password are incorrect. PS: \"Thank you for your email dated 6th June 2016\" -- it's July, not June."},{"title":"Virgin East Coast 5","url":"/2016/06/28/virgin_east_coast_5.html","date":"2016-06-28","content":"Quick update on where things are at with the attempt to get help with the apparent inability to log into the Virgin East Coast Ticket Wallet app using an otherwise perfectly valid account... As mentioned yesterday I had an email from them. I replied (after writing yesterday's blog post): I'm very concerned and very confused by your question about if I've even registered with the main website. Yes, I have. I've confirmed this more than once now. During my first phone conversation with support I was told I wasn't in the system and then, when I demonstrated that I had to be, I was magically \"found\" after some magic \"fix\" was applied on the fly. Now I'm being told I don't exist again. I seem to be going backwards with this rather than going forwards, and what's even more frustrating is that any question I ask seems to get ignored while I keep being asked the same basic questions time and again. Yes, I did register with the main website. That's how I found there was an Android app that works with it. That's how I followed the link to it. That's how I found the support report form and managed to drop you a line in the first place. So, just so I'm 100% clear on this: which email address are you looking for? How are you looking for it? Where are you looking for it? How come someone looked for it before, didn't find it, and then found it when looking again? If I'm not in the system how is it possible for me to log into the main website? I also added a couple of screenshots, with explanation, that shows me logging in with the address they claim doesn't exist in their system. I've had no reply to my questions so far. I've had no reply at all so far. After posting yesterday's post I did the usual thing of tweeting it and, obviously, mentioned @Virgin_TrainsEC in the tweet. Good 10 days into the @Virgin_TrainsEC support saga and theres no end in sight: https://t.co/ZfV0lR4DQL &mdash; Dave Pearson (@davepdotorg) June 27, 2016 This lead to a little exchange on twitter where I mentioned that the main reason I was trying to switch to Virgin's own system, rather than use someone line TheTrainLine, was so that I could get the free WiFi and save myself a tenner each trip. All credit to Virgin East Coast: they contacted me directly and have provided me with 10 one-use WiFi access codes to keep me going while this gets sorted out. It's not a solution to the problem, but it does remove the extra cost I was trying to get rid of for the next 5 standard class round trips (I sometimes sneak in a first class journey if the price is too good to ignore). So.... no still no solution, but some welcome help from them to be going on with. Can't grumble at that."},{"title":"Virgin East Coast 4","url":"/2016/06/27/virgin_east_coast_4.html","date":"2016-06-27","content":"Yesterday, realising it had been a week since I'd last had any contact with Virgin East Coast support , I dropped them a line to find out what was going on. Given that they'd generally been pretty quick to reply and deal with things initially (albeit in ways that didn't really seem to fix the problem) it seemed odd that they'd gone so quiet. I've had a reply this morning: Dear Dave Thank you for your email chaser today with regards to the Mobile app that you registered on and now cannot sign into it to test the device before you book. I am sorry to hear that you have not been in receipt of a reply with regards to this and as such I will try and solve this for you now. We did not receive anything back from our second line support team and as such we may need to do more troubleshooting before we chase this with them. Please can you confirm if you have actually registered on the desktop version of our web site please? I know that you stated that you have signed up for the mobile app and registered on this but your email address does not show on our system as being registered so we just want to ensure that we have explored all areas. Once we have this from you we can then add this to the valuable information that you have already provided and chase this up for you. Honestly, this is starting to get silly now. I don't mind so much that they've been slow in getting back to me on the problem because they've been waiting on \"second line support\" to get back to them, but that doesn't seem to really make sense in the light of them saying afterwards that my email address doesn't even show in their system. Really, if they can \"see\" that I'm not even registered in their system, why would they have passed things to \"second line support\"? That makes no sense. But, actually, it gets even worse. During my original phone conversion with them the lady I spoke to made the exact same claim. She told me that my email address wasn't even in the system, hadn't been registered via the website. Of course it had (I even sent the initial message for support from their website, while logged in). I pointed this out and she went off to look into it; she came back to say it was there now. When I asked what had happened she mumbled something about how there'd been a problem and she'd got someone to fix it. No, I have no exact details about it, but quite simply she said I wasn't in the system, I provided her good evidence I was and then she made \"magic\" happen and suddenly I was visible. But, now, apparently, I'm not visible again. Either someone at Virgin East Coast is fibbing to me, or their system has a bad habit of losing people's details. It's not like I'm so stupid to think I've registered but actually haven't. I can log into the website with the details I registered with. I've had a member of staff confirm I'm in the system. I've had subsequent support chats take place where the person I'm dealing with is satisfied that I exist in the system. I even had them ask me to try and reset my password -- something I imagine isn't possible if you've not even registered with the system yet! This is getting really silly now. This is possibly getting beyond silly. The serious side of this is, of course, I can't trust the Virgin East Coast website or their booking system, so I have to continue using a third party, which means Virgin still get to grab an extra tenner off me on every trip so I can have WiFi and get some work done."},{"title":"Virgin East Coast 3","url":"/2016/06/20/virgin_east_coast_3.html","date":"2016-06-20","content":"Another update to the saga of trying to get the Virgin East Coast Ticket Wallet app up and running. Late on yesterday afternoon (a Sunday, it has to be said, so that's some dedication to solving the problem) I got a reply to the email I'd sent them previously . It didn't contain anything in response to what I'd written (so it looks like I'm never going to find out what a TOC is! sadface ) but it did say this: To Dave Pearson, Thank you for your response. Please attempt to change your password via the forgotten password process. Once you have amended your password, please attempt to sign into your Virgin Trains East Coast Ticket Wallet App. I apologise for the inconvenience, and thank you for your patience. I'll admit that I wasn't convinced by this plan. There was no explanation as to why I'd want to change my password, or why I'd want to pretend that I'd forgotten my password (I hadn't forgotten it, obviously), there wasn't a suggestion that something had been changed or fixed such that this would tickle a solution into working. It appeared to imply that I'd actually forgotten my password and that I should go about setting it again. Fair enough... I did. It didn't make a jot of difference. Same problem. I've written back to say so. The actual act of saying I'd forgotten my password was a little odd. I did the obvious thing of going to the main website and saying I wanted to sign in. Once clicked, that took me to the actual login page, which has the link to say you've forgotten your password. When you click on that link you get taken to.... a login page! There you then have to say, again, that you've forgotten your password. Only once you've done that do you get somewhere where you can say you've actually forgotten your password. Not horrific, of course, but a rather odd route, needing to click pretty much the same link twice to say the same thing. Anyway, I tried it, it didn't work, they've had an email to say as much. Now I wait for the next step."},{"title":"Virgin East Coast 2","url":"/2016/06/18/virgin_east_coast_2.html","date":"2016-06-18","content":"This morning I called back on the number I'd been given yesterday evening . I explained briefly why I was calling and how I was returning someone's call but, sadly, ended up back in support script-following hell: they started asking for booking reference and all that stuff again. I stopped them, explained the issue again , and they then started to ask for ticket details and so on. Deeply frustrating. The problem I had was that I was trying to set everything up so I could even stand a chance of booking a ticket. How could I have a ticket I could tell them about if I'd not even got to that part? When I made this clear, in as polite but firm way as possible, I was passed onto that person's supervisor. As luck would have it he was the person who'd called and left a message last night. He quickly filled me in on what was happening, saying they weren't sure what the problem was but that the details had been passed to the tech people. He also asked if he could send me an email with some questions in it that would help get to the bottom of things; he said it would ask things like OS type and version, device type, etc. It all seemed to make sense I said I'd be happy to and we left it at that. I've had the email. This is what it asked: 1 - Origin and Destination Gah! Here we go again. The whole support thing appears to be predicated on the idea that you're having a problem getting somewhere. They seem to not understand that if you can't even use the system in the first place you can't even have booked a ticket. 2 - Date and Time Without a ticket, there can be no date and time. 3 - Number of passengers and railcards if any Seeing a pattern here? 4 - Ticket name and price I... erm... hello? 5 - Browser name &amp; version Finally! We're getting somewhere! Only... my problem isn't in a web browser. My problem is with logging in with their Android app. I'm sure I mentioned this to them at least once. 6 - Screenshot if possible showing the error Yay! Finally! We're getting somewhere! I pasted in the screenshot that was included in yesterday's blog post. You know the one. The one where it's just some text that says the username and password are invalid. Because... images are better than the text in them, right? 7 - Name of the TOC I have no clue what this means. TOC? What the heck is a TOC? 8 - Email address of the user This I can do! I know this one! (I still suspect that this is the cause of the problem). 9 - Booking ref Gaaarrrrrggghhhhhh! 10 - Screen shot showing exact error and exact steps to recreate the error Wait... didn't I get asked that in question 6? How is this screenshot going to be different from the other screenshot? Still, at least it asks for the steps to recreate now. So I answered that: Create a new account on the Virgin East Coast website. Ideally use an email address that contains both a full stop and a plus sign, as mine does. Also ensure that you use a password that is the same length as mine. Log in and look at registered devices. See there are none and follow the links it provides to the applicable app that will result in a device being registered. In this case the Ticket Wallet. Download and install on a suitable Android device. Attempt to log in and, likely, find that you're told that the username and password is incorrect. So that's all sent off now. Now I wait for another call back at some point in the near future. Curious how the thing it didn't ask was what app I was using, what version it was, what mobile device it was being used on, what OS, what OS version, etc..."},{"title":"Virgin East Coast","url":"/2016/06/17/virgin_east_coast.html","date":"2016-06-17","content":"This year has seen me travelling up and down the east coast of England (and into Scotland) quite a bit. Unsurprisingly this means I've been using Virgin East Coast a lot. While I'm no stranger to the rail network (I grew up in York, my father worked for what was once called British Rail, etc) I've not been a regular user since the mid 1990s (when I used to travel from Winchester to London every day). Much has changed since the last time I used the trains a lot; the big (good) change being that you can do a ton of stuff online and, even more usefully, you can do most things on your mobile phone. Being able to buy tickets from my desk or sofa, and being able to carry all the useful info (times, seat numbers, etc) inside an app makes for an almost stress-free journey. Up until now I've being using TheTrainLine to do all the booking. The website is uncluttered and easy to use. The same is true of their Android app. I have no complaints at all about how their system works. But there is one small downside... The journey I do takes about 4 hours so it makes sense that I settle down and get some work done. Working, of course, requires that I have some sort of Net connection. Ideally I'd just connect via my phone but I find that the signal can't be relied on for large parts of the journey. But that's okay, the trains have WiFi. It's not cheap though. On Virgin, if you're not travelling first class (something I do do if I can get the right sort of deal) you need to pay 10 to get enough WiFi time to last the trip. Not horrific, but over a few journeys it adds up. Recently though Virgin East Coast have been doing this thing where, if you book direct via them, you get the WiFi for free. So, while I have no complaints about TheTrainLine, it makes sense for me to book direct with Virgin and hopefully save myself a tenner on the WiFi. A couple or so weeks back I finally created an account with VEC. I did my usual thing that I do and used a variation on my Gmail email address. You know the sort of thing, make use of the fact that anything after the + in the address doesn't \"count\" but can be useful to filter things and keep track of who's selling on your contact details. So I registered as davep.org+virgin@gmail.com. The website accepted it just fine. The next job was to install their wallet app. According to the website this lets you travel without even needing to faff around with printed tickets: you can do it 100% with your phone (something TTL now do too, I believe). So I downloaded the app, went to log in, and... I tried a few times, just to be sure that I wasn't being an idiot and messing up but... nope, it just wasn't going to let me log in. Dammit! After a few more attempts I gave up and went back to using TTL. Yesterday, however, I decided to look into this again. The problem persisted so I logged into the VEC website, followed the links for getting help with the site (I couldn't see help for the app) and sent a message using the form on the website. In the initial query I pointed out that I'd like to use the system to book tickets -- especially so I could enjoy free WiFi -- but that the app wouldn't let me log in. I asked how I might fix the problem. The first reply was: Could you please confirm which Mobile App you have downloaded and we will advise you accordingly. Okay, fair enough. I'd spoken about \"the app\" (although I'd only been offered one via the site) and it seems there's more than one. So I wrote back and confirmed I was talking about the Ticket Wallet . They replied: Could you please provide us with your booking reference number and we will advise you accordingly. I... erm.... Hello? Booking reference? I smell a faint whiff of Catch-22 here.... Never mind. I write back and point out that there is no booking, I'm asking about a problem with their app. Could you please confirm if you have registered on the Virgin Trains East Coast website and we will advise you accordingly. Well this is getting fun. I'd been logged in and used their contact form when I sought help. You'd think that it would record this information in some way. Fair enough, perhaps not. So I confirm that, yes, I had created an account with their website and was trying to use that to log in (I also quoted a line from my original message where I'd said this, right from the start). If you have registered with us please provide us with the email address used as the email address in the original email davep.org+virgin@gmail.com is not recognised on our system. Erm... Well this is getting silly now. That's absolutely the email address I'd registered with and was logging in with. That's why I was trying to log into the app with it! So I replied confirming that that was the address I'd registered with and hence my confusion. The reply? This: I can confirm Virgin Trains East Coast has two Mobile Application, the Virgin Trains East Coast App and the Virgin Trains East Coast Live App. When you purchase an eligible Virgin Trains East Coast ticket on the website you will be offered the option of having your ticket delivered to your mobile device as an m-ticket. To use the app, simply sign in with your Virgin Trains East Coast login details, and the app will synch with your online account. If you havent registered that device before, it will ask you to name your device. That name will then be shown in your account and when buying tickets, so you can choose which device to send your tickets to. Thank you for contacting the Virgin Trains East Coast web support team, should you require any further assistance please dont hesitate to contact us on 03457 225 111. I... erm.... what? I'm still unsure what this was really telling me. The words made sense, it seemed to be filled with facts, but none of this seemed to pertain to what I was asking them. Worse still, it seemed to give the impression that you needed to have purchased a ticket before you could use the mobile app (at least that's one interpretation I'm getting from the above) and yet, when you follow the links on the website, it says something very different. I replied pointing out that I was failing to see how that addressed what I'd asked, and I reiterated my problem. At this point I got a little frustrated and tweeted my frustration: In support hell trying to log in with @Virgin_TrainsEC Android app. Cant imagine why its got this sort of rating. pic.twitter.com/pSnuJiiUoB &mdash; Dave Pearson (@davepdotorg) June 17, 2016 Which got this reply: @davepdotorg I understand it&#39;s having a couple of issues today. Booking references will be accepted on your train. ^NB &mdash; Virgin Trains EC (@Virgin_TrainsEC) June 17, 2016 While I get that social media staff, more than any, can be overworked and are often trying to put out all sorts of fires, this wasn't in any way helpful to me. I pointed out what the actual issue was: @Virgin_TrainsEC The problem goes deeper than that. Ive never been able to log in. Ever. Support says ac doesnt exist. But it does. O_o &mdash; Dave Pearson (@davepdotorg) June 17, 2016 I'd also tweeted after my first, talking about the frustration of how TTL seem to do things well, but I only get free WiFi if I book via Virgin: What really bugs me: @Virgin_TrainsEC offer free WiFi if book thru them, but app wont work. @thetrainline works brill, but no free Wifi. &mdash; Dave Pearson (@davepdotorg) June 17, 2016 That tweet got a reply from them asking if I was talking about the wallet app (I was, of course) and if I'd registered with the website first. O_o So, after a lot of back and forth, I'd got nowhere with this. I did, a little while later, get an email asking for my phone number so they could call me; I replied with it. The phone call came a little later on. It didn't go well. At first I was told that the problem was that I needed to purchase a ticket and then that would mean I'd be able to log into the mobile app. Let's just take a moment to really appreciate what's being said: I SHOULD SPEND A HUNDRED POUNDS OR MORE SO I CAN EVEN LOG INTO THE APP. Only... that's nonsense. According to the website it works very different from that. What the website implies is: You create an account on the website. You download the wallet app. You log into the wallet app with the username and password you use on the website. This then registers the mobile device with the system. Then, and only then, can you buy a ticket. When I pointed this out to the nice lady on the other end of the line she seemed confused by the idea and had to go and check it. She then came back and confirmed that, yes, that's how it works. At which point I asked her how I was supposed to actually log in if it kept telling me my username and password were wrong. She then suggested that, yes, perhaps there was a problem and could I send a screenshot of the wallet app so they could look into it. A screenshot. O_o Sure, I guess I could send in a screenshot. You can see it above. It's quite simply the text \"Your username or password is incorrect\". That's it. That's the problem. It's nice and easy to type. It's text. It's English. I can't see any special pixels that would help debug the issue. But, nope, it needed a screenshot. I asked if, perhaps, I could speak with these \"technical\" people who'd be dealing with this. I was told that that wouldn't be possible and that, instead, she'd have her manager call me. She then hung up pretty sharpish after that. Right now, as of the time of writing, I'm waiting on that call. While I do wait, I'm going to make a prediction as to the cause of this. I'm willing to bet the problem is with the choice of email address. So many large companies have systems that assume that + isn't a valid character for an email address. I'm going to further guess that Virgin East Coast isn't one of them when it comes to their website. When it comes to their Wallet App though... Later in the evening: I never did get a call from the woman's manager, but an hour or so later I did get a call from someone at their \"web support team\". Sadly I wasn't in a position to take it so I'm no wiser as to what the call was actually going to be about. I'll return the call tomorrow and, all being well, write a second post about what happened. The main thing I take away from this today though is that, if you (as appears to have happened a few times today) follow a script and don't actually read what the customer is writing, it's going to turn into a very frustrating experience; especially for the customer."},{"title":"Starting fresh with GNU emacs","url":"/2016/05/26/starting_fresh_with_gnu_emacs.html","date":"2016-05-26","content":"As I've mentioned elsewhere on this blog, over the past few years, my use of GNU emacs has lapsed somewhat. There was a time when it was my only editor (except for the odd dips into vim to do some quick editing) and, back when I used to use GNU Linux as a desktop machine a lot, I'd have an emacs session up and running pretty much non-stop (it was one of the reasons I wrote uptimes.el ). In more recent times I've been working more on Windows and often inside Visual Studio. Even for my own \"for fun\" programming, I've mostly being doing things that didn't involve emacs much. In fact, most of my recent \"for fun\" coding has been done using Sublime Text because it was powerful, cross-platform and also had great support for the language I code in a lot when it comes to personal amusement projects . During that time I've wanted to get back into emacs. Quite a bit seems to have changed since I was last a very avid user and this also meant wanting and needing to catch up. The first thing I needed to do was finally get around to killing off my old ~/.emacs file. This has followed me around since I first got into emacs on OS/2 back in the mid 1990s. The file started out with a few setq expressions to tweak some settings and just kept growing and growing. It'd got to a point where there was old stuff in there that I had no use for and sometimes even no idea what it was for. Heck, to give some idea of how old the file was: there were items in there that handled running emacs on MS-DOS! So, a couple of weeks back, I dumped it. Dumped the whole lot. The plan then was to recreate it with as little hands-on coding as possible. I decided that, as much as I could, I'd tweak using customize and only hand-code (in ~/.emacs.d/init.el this time around) things when there was no obvious other way to do it. So far this is working out really well. Gone has the ugly and monolithic .emacs , replaced with something far more modular, much more tidy and far easier to maintain. Whereas my old config was almost 1,000 lines long, the new init.el is currently just 50 lines: ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Make use of the Common Lisp compatibility module. ( require &#39;cl ) ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Local config/lib directory support. ( defun davep:user-path ( path ) &quot;Given `file&#39; , return a path for it in the local config.&quot; ( concat user-emacs-directory path )) ( defvar davep:local ( davep:user-path &quot;davep/&quot; ) &quot;My local config and code directory.&quot; ) ( defvar davep:startup ( davep:user-path &quot;davep/startup&quot; ) &quot;My local startup code.&quot; ) ( defvar davep:lib ( davep:user-path &quot;davep/lib&quot; ) &quot;My local library code.&quot; ) ( defvar davep:lib-3rd-party ( davep:user-path &quot;davep/lib-3rd-party&quot; ) &quot;My local third party code.&quot; ) ( push davep:local load-path ) ( push davep:startup load-path ) ( push davep:lib load-path ) ( push davep:lib-3rd-party load-path ) ( defun have-own-package-p ( package ) &quot;Does a package of my own exist in this environment?&quot; ( locate-library package nil ( list davep:lib ))) ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Ensure custom values go in their own file. ( setq custom-file ( davep:user-path &quot;custom.el&quot; )) ( load custom-file ) ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Load various startup things. ( load &quot;env-tests&quot; ) ( require &#39;davep-keys ) ( require &#39;davep-languages ) ( require &#39;davep-style ) ( require &#39;uptimes ) ( require &#39;csrclr ) ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ;; Local autoloading. ( require &#39;autoloading ) ( load-davep-autoloads ) All the other stuff, things to tweak language modes so they indent \"just so\", my own special keyboard bindings, that sort of thing, they're all farmed off into their own files: davep@Bellerophon:~/.emacs.d/davep/startup$ v total 40 -rw-r--r-- 1 davep staff 4211 24 May 14 :38 davep-keys.el -rw-r--r-- 1 davep staff 4078 16 May 13 :51 davep-languages.el -rw-r--r-- 1 davep staff 537 25 May 14 :13 davep-style.el -rw-r--r-- 1 davep staff 1339 16 May 09 :39 env-tests.el Another thing I'm trying to do is dump all the old third party code I had locally and, instead, use emacs' own package manager now. Currently this is also working well for me given that I'm using both ELPA and MELPA . I haven't managed to dump everything yet, but it's a useful exercise to slowly work through the various files I was carting around and deciding if I need them or not (like, I'm fairly sure I won't be needing a cobol-mode any time soon -- that can go). On top of all of this, on top of starting with a \"clean slate\" emacs, I've also started keeping track of what I do on GitHub. I've got a private repo for my ~/.emacs.d/ that I can now easily sync between my various machines. One final thing that I'm starting to try and do is actually make full use of emacs again. One example is that I'm writing this blog post in it. Until now I've been using SublimeText with a Jekyll package to compose and manage things but, this time around I'm giving hyde and markdown-mode a go. So far they're working out pretty well too (albeit hyde was a bit odd to set up and isn't 100% making sense to me yet)."},{"title":"I now own a Macbook","url":"/2016/04/28/i-now-own-a-macbook.html","date":"2016-04-28","content":"I've had my iMac for about 10 months now and I can safely say that it's a purchase I don't regret. While I'm still not convinced by the hype and nonsense that's normally associated with Apple products -- I've had plenty of moments where the damn thing really hasn't \"just worked\" -- I really do like the iMac as a Unix workstation. Recently I've had the need to consider buying a small laptop that I can use on train journeys. While I have a very capable Windows laptop it's a little too large to pull out and use on the tray you get on the back of a train seat. I also have a much-loved Chromebook but it would generally fail me on the train unless I always pay for the WiFi. So the ideal machine for me would be fairly small (no more than 12\" or so), be capable of doing things locally, and would also need a pretty good battery life (while the trains I travel on do provide sockets they seem to provide no power as often as they do). I did start to think about going with some sort of Macbook but, every time I looked at them, I ended up deciding they were too expensive. Until yesterday. Yesterday I found that the local computer store had the 13\" Macbook Air on sale -- 150 off the usual price plus another 50 off if I got there and bought it before 5pm. So I had to go and look. Having looked I came away with one. So far I'm very pleased with it. While the one I have is the lower spec version (just 128GB of SSD and 4GB of memory) it seems to work well for my needs. As for what my needs are? I want to be able to work on web projects locally, hack on JavaScript and HTML, that sort of thing. As well as that I want to be able to run Git and, when I do have a net connection, sync to GitHub and browse the web, do email, faff around on reddit, etc. For this it's perfect. I'm finding it more than fast enough for what I want (I'd even go so far as to say that it's faster than the iMac). The keyboard is just the right size, the trackpad is perfect (and works just like the Magic Trackpad I use on my iMac), the screen is very readable. So far I'm struggling to find any real fault with it. Okay, sure, there are some obvious downsides, the main one being that, for what I paid for this, I could probably have got a lower-end gaming Windows laptop with plenty of drive space, memory and a good graphics card. But that's not what I was after. A machine that big and that powerful would sit in the laptop bag and not get used. I wanted a machine that was easy to drag out, open up and use. And that's what's happening with the Air. In fact, it's being used on the train right now; that's where I'm waffling on about this, to kill time, somewhere north of Newcastle, with the sea to my right and the snow coming down."},{"title":"Until next alarm is back","url":"/2015/12/17/until-next-alarm-is-back.html","date":"2015-12-17","content":"Now and again Google seem to actually listen. While they do generally have a bad habit of removing things from things and saying it's for everyone's good (because options are bad and they can't maintain them, apparently) it seems they can do the odd turnaround now and again. One thing they removed from Android recently was the \" until next alarm \"\" option when putting a device in \"do not disturb\" mode. Seems they've added that back in 6.0.1: It's a small thing, but it makes so much more sense and makes things so much easier (even if it's a trivial thing). Nice one Google. More of this please."},{"title":"My first proper BT broadband outage","url":"/2015/11/18/my-first-proper-bt-broadband-outage.html","date":"2015-11-18","content":"Until I moved about a year ago I'd always used Demon Internet as my ISP. I stated with them during the old tenner-a-month days when there were only a handful of points-of-presence to be called. I stuck with them through them getting full local POP coverage, through having an ISDN line and then finally ADSL. When I moved though I decided it might be easier to just go with BT; for the most part this hasn't actually been a bad decision. This week though I suffered my first proper outage with them and it was rather frustrating. It kicked off at around 2015-11-16 21:00. I noticed that Google Drive (in Chrome) was complaining that it was offline. I then noticed that gmail and a couple of other tabs in Chrome were complaining about the same thing. I did a couple of local network checks and found nothing, checked the router and it was connected and reporting just fine, so then I rebooted the router and things appeared to improve. For a short while anyway. Then I started to notice other problems; mostly that some sites would time out, others not. Initially I was getting a lot of DNS timeouts and, while I normally use Google's DNS servers (BT's have long had lots of problems 1 ), I tried switching back to BT's own and that appeared to improve matters. For a while anyway. I mentioned the issues on twitter and got a handful of replies from different people running into similar issues. It was clear that this wasn't just me. I then went looking for BT's broadband status page but hilariously was unable to load it because of the problem. This is my first bit of real frustration with them. Here's how the page looks inside a desktop browser: Now compare it as seen inside Android Chrome on my Nexus 6: Apparently they have decided that I'd never want to be able to check why my broadband might be down, from a mobile device. Yes, sure, there's the option to put my phone number in -- perhaps it tells me after I've done that -- but I don't even know my land line number; I don't use it as a phone most of the time and so never bother remembering it. The main point here is why the hell wouldn't they include the same useful information as the desktop view? Or perhaps use geolocation of the phone to narrow things down if they feel the need. Anyway, I gave up and went to bed. In the morning things were no better but, after another router reboot, I did manage to get a view of the status: Finally! Acknowledgement of the problem. Worryingly though it was dated almost 12 hours after I first noticed the problem. From what I can see that date and time isn't the date and time the status was last updated, it's the date and time it was first added. That suggest that they really hadn't noticed the problem all night. It's not like it was a problem that was hard to notice, at least from a customer's point of view. Check this graph from a down detector site : You'd think that a company as big as BT would have something in place that could catch network problems, especially ones that are able to be caught with a simple crowdsourcing \"press this button if you have a problem\" approach. But... nope. Appears not. O_o Anyway, a couple or so hours later the problem was finally fixed: (Notice how the date and time is the same as earlier; so 100% not an update time but a first-added time) I mentioned this on twitter: Looks like BT broadband problems are resolved. Everything working that I can see, and this... pic.twitter.com/m5Mo7vm5Yu &mdash; Dave Pearson (@davepdotorg) November 17, 2015 and I even got a reply (which I'd not gone looking for, so that was nice): @davepdotorg Yes Dave we have the problem fixed, if you still notice a few issues then reset the hub and try again. ^Chris &mdash; BT (@BTCare) November 17, 2015 Curious as to why it'd take almost 12 hours from the problem appearing to it being acknowledged on their status, I thought I'd ask: @BTCare All looking good. Any reason why it took 12 hours to acknowledge? &mdash; Dave Pearson (@davepdotorg) November 17, 2015 which got this reply: @davepdotorg Sorry it took so long, identifing the source of the problems would have taken some time. ^Shane &mdash; BT (@BTCare) November 17, 2015 which doesn't really make a whole lot of sense. Sure, you to spend time identifying the source of a problem to fix it, but you don't need to do that to notice and acknowledge that there's a problem. I've asked again but haven't received any sort of reply as of the time of writing (I'm not expecting one really). What I take from all of this is that BT are shockingly bad at keeping people informed of problems with their service when there's a large outage. I find that kind of annoying. I don't mind that there are problems, I do mind when a company can't take the time to clearly and quickly state \"yup, it's us, it's not you, we're looking into it...\" Don't even get me started on how the HH5 won't allow setting of DNS servers in the hub itself. That's stupid and frustrating beyond words.&#160; &#8617;"},{"title":"A little bit of usenet","url":"/2015/11/13/a-little-bit-of-usenet.html","date":"2015-11-13","content":"Earlier on today I needed a copy of wget on my iMac. It's not \"native\" to it so I got to wondering how you go about getting something like that onto it. Sure, I could have just grabbed the source and built myself, but really it's a lot nicer to use some sort of package manager. A quick search lead me to Homebrew and I was then up and running in no time. This in turn got me to thinking about how it might be fun to get some of the software I used to use on my GNU/Linux machine up and running again. The first one that came to mind was slrn . Sure enough slrn is available via Homebrew and installing it was dead simple. But then I was faced with a problem: I needed an NNTP server. Way back I used to run a local one in my office that fed from and to my ISP's. Back then my ISP was Demon Internet; these days I'm with BT. A quick search lead me to an article or two that BT had a NNTP server, of sorts, provided by a third party. So I did a quick check: Yay! This looked good. After that I fired up slrn and.... problems. It kept asking me to log in, to provide a user name and password. The only problem was that I'd read in more than one place that a user name and password weren't needed for BT's server; all that was required was you be on a BT IP address. Checking the slrn docs I found force_authentication but ensuring that was off made no difference. At this point I removed slrn and gave up. Later, thinking it might be an issue with just slrn and perhaps it was worth trying a native NNTP client, I grabbed Unison ( which is no longer supported but seems to work fine). I got that set up and ran into the same issue: it wanted login details. Finally, after a bit more digging, I stumbled on the reason why I was struggling to make any of this work: BT had closed support for the server back in December last year ! A quick search around the web and I stumbled on Eternal September . Given all I was interested in was the good old text groups this looked perfect. I quickly registered an account, ran up Unison again and plugged in my details and.... Now that's all sorted I should try again with slrn . At which point I'll need to drag out and tidy up post.el ( the version that was being maintained by some other people seems to have gone very stale , sadly)."},{"title":"I miss \"Until next alarm\"","url":"/2015/11/12/i-miss-until-next-alarm.html","date":"2015-11-12","content":"I actually can't remember when the change was now, it was either Android 5.0 or one of the 5.x point releases, but I can recall the frustration of Google having changed how you make an Android device silent, or not. The idea seemed clever enough but it was a real pain to switch to and use. Previously there'd simply been this neat system of setting he volume to either be some non-off value, vibrate or totally silent. I even had a neat little widget on the home screen of my phone to allow me to toggle between these 3 states. It was simple, and worked well. The new system though.... ugh. It was confusing and so much more long-winded to work with. At some point though they added one big redeeming feature: \"Until next alarm\". When I got into bed I could tell my tablet to go totally silent until my alarm went off in the morning, and then it would all work as normal. That was an utterly brilliant idea. So it made sense that if they changed anything about this in Marshmallow they'd keep that in and make it even more awesome, right? Right?!? Well fuck! Why? Just..... why?!? I actually prefer how the new one works. They've more or less solved the problem of how it was more faff to deal with, they've solved the problem of having to cock about with the volume rocker to get at the settings and then set the settings. I like all that. But taking \"Until next alarm\" away? That's just nuts. Sometimes I really get the impression that the Android developers are like the Chrome OS developers: they're having a ton of fun improving and onward developing the system but they have little connection to how people actually use this stuff."},{"title":"Voice search failing on Nexus 6","url":"/2015/11/11/voice-search-failing-on-nexus-6.html","date":"2015-11-11","content":"It's been quite a while since I used voiced search on my Nexus 6. Ever since I got the Moto 360 I've not really had a need to say \"OK Google\" to my phone because I could simply say it to my wrist. Today though, because I wanted to quickly look something up and my phone was to hand, I spoke to it and got this: Brilliant. I've been here before. I had exactly this sort of problem with my Xperia Z at one point . The problem appeared to go away eventually (actually, it sort of came and went a few times over a matter of weeks, if I recall correctly), although I never really got to the bottom of the cause. I've tried rebooting the phone and that hasn't helped at all. While it's more of a vague annoyance than anything else (like I say above, my Android Wear device is my goto tool for talking to Google these days) it does frustrate a little when fairly expensive tools don't \"just work\"."},{"title":"Usenet spam, still a thing","url":"/2015/11/06/usenet-spam-still-a-thing.html","date":"2015-11-06","content":"This just turned up in email a little earlier: What's of particular interest is the email address this was sent to. It was one that I only ever (to my knowledge) used for posts to Usenet. While my gmail spam folder is filled with emails to that and other addresses I used for Usenet over the years this is the first bit of \"proper\" spam I've had to it in a long time. It's signficant that it's some sort of Xbase -related thing too. I think the Usenet group I posted to more than any other will have been comp.lang.clipper . Unless I had some lapse of judgement at some point in the late 1990s or early 2000s (I think I only got the davep.org domain in 1999, now I think about it) the address this was sent to was used nowhere else. I've also never been a \"Visual Objects and/or Vulcan.NET user\". While I did once own a copy of Visual Objects (two copies actually -- a beta and then a final release) it wasn't in a way that I'd have been on some mailing list and even if I had the address in question wouldn't have been the one used. So, yeah, great way to impress me with a new product: make your first contact with me look exactly like some old Usenet spam. Edit to add: I've since had it confrimed by the sender of the email that my address was indeed pulled from comp.lang.clipper ."},{"title":"How to kill OS X's HelpViewer","url":"/2015/11/02/how-to-kill-os-xs-helpviewer.html","date":"2015-11-02","content":"A little earlier today I decided it was time that I read up a little more about the abilities of OS X's Spotlight facility. I use it a little -- it's a handy tool to get at some often-used applications that I don't really need laying around in the dock -- but I was starting to wonder if I could get more out of it. The obvious first place to look was in the HelpViewer; all the information I'm ever going to need will be on the local machine, right? So I open the HelpViewer, from the Spotlight bar, and type in that I want information about Spotlight. The page comes up blank. The page was pretty small so, while I pondered why it might be blank, I resized it and it disappeared! I tried to open it again and.... nothing. Nothing I did would make the HelpViewer show again. I then tried following the advice on this page but none of that appeared to help. I then looked for the HelpViewer in the Activity Monitor and killed it with that. Running it again after that got me back to where I started. I tried the while process again and, sure enough, trying to resize the window made it disappear. I can make it happen every single time: So it looks like another fine example of the Apple \"it just works\" thing. For \"doesn't always just work\" values of \"just works\"."},{"title":"Apple Accounts","url":"/2015/10/21/apple-accounts.html","date":"2015-10-21","content":"As much as I like my iMac, and as much as I am generally impressed with OS X the more I use it, I'm constantly frustrated by the little issues I run into that make life so much more interesting and which fly in the face of the \"it just works with Apple\" fandom thing. The more I use the iMac, the more I appreciate that Macs and OS X are just as \"fun\" as anything running Windows. A little earlier was a good example. I wanted to share part of the iMac's filesystem using SMB . This seemed easy enough, the instructions on how to do it were clear and, after following them, it utterly failed. Brilliant. So I Googled the issue a bit and ran into this handy forum post . Apparently you can't actually connect with SMB if the account you're going to be using to connect with is using iCloud login rather than a separate login. Brilliant. Not an obvious thing. Nothing said this was the case. According to the forum post even Apple couldn't help the person who'd been trying to make it work. But at least there was a workaround. All I'd need to do is split the password, have a login for the machine that wasn't the iCloud login and I'd be all good. I did it, it worked. I could browse the iMac's filesystem from my Windows machine and all was good (I'd been able to do this the other way around for ages and with no problems whatsoever). Then I got curious. What would happen if, once I had this set up, I \"unsplit\" the password and went back to using the iCloud password to log in? That's when it got really fun. To do this it asks you for the current password and also your iCloud password. I entered both and... Yup. It refuses, every single time, to accept that the iCloud password I'm entering is valid. Trust me, it is. I'm entering the correct password. I can log in to the iCloud website with it just fine. But when I use it to try and \"unsplit\" my password.... nope. Brilliant. I've even tried disabling SMB sharing for my account, and even turning off SMB sharing altogether. This doesn't seem to make any difference. Right now, as far as I can see, now that I've split the password I can't go back despite the fact that there's a method of doing it made available. Brilliant."},{"title":"Microsoft accounts","url":"/2015/10/19/microsoft-accounts.html","date":"2015-10-19","content":"I have too many Microsoft accounts. Far too many. And they still confuse the hell out of me. I found out over the weekend that the office was closing down the old internal email server. Everything moving to Office365. I use Gmail for my email (I have a freebie Google Apps account that I use as the front end for it -- when it comes to things like email I'm Gmail all the way). So, as of today, I have a new work-oriented Microsoft account. Problem is, I already had a work-oriented Microsoft account because that's how I use MSDN and download stuff from that. I also have a personal outlook.com account for reasons I can't remember now. And then there's the Windows gaming login, which might or might not be related the the one above. And then there's the old Xbox live account that I think has nothing to do with the above. And then... The problem I have is that I never seem to be able to log in with an existing MS account any time something new crops up, and so I somehow seem to end up having to make a new one. And now I have too many and there's no obvious way to merge them or kill them off without losing some service I don't even know I need to use any more. And then there's my two Skype accounts (personal and work)... Make it stop! Please! And give me a merge facility!"},{"title":"Labour want more money","url":"/2015/10/08/labour-want-more-money.html","date":"2015-10-08","content":"I woke up this morning to see this being retweeted by a few people I follow: Even if I was to let my usual net-cynic side take over and decide there's a good chance it's a made-up story there's no getting away from the fact that this is a story that isn't in isolation. I hear this sort of thing time and again; especially from people who have to deal with the fallout from this first hand. This is something that is happening, in 2015, in the country I live in. I wish it wasn't. This is why I find Labour's accusation of lying so damn annoying and frustrating. For a short while I simply decided that that was that. They're as corrupt as the rest of them and only in it for the money. This was made even more clear by how often they kept trumpeting the new member numbers. It's all about the numbers -- all about the money. But then I saw this video : and got to thinking that perhaps, just perhaps, some change for the better is actually happening inside Labour. Perhaps I should give the organisation the benefit of the doubt. Perhaps, if I contacted the membership team and asked why they'd decided I was lying, they'd give me the information and I could sort things out. So I did. I wrote to them. I sent this to them, via the form on their website, on 2015-09-28: On September 5th 2015 I received an email from you accusing me of having lied when I sought to become a supporter, with a view to applying to be a member after seeing the results of the leadership election. This was a rather hurtful event and one I wrote about here: http://blog.davep.org/2015/09/07/labour-said-no-thanks-to-my-support.html Having watched https://www.youtube.com/watch?v=RYNPzJgV8TI I find myself in the odd position of liking the message of a party that, at the same time, accused me of something without evidence. Given this I'd like to get to the bottom of what happened, hopefully find out what evidence was used to make the accusation and, perhaps, get an apology so that I can seriously consider joining and supporting what is happening. I look forward to your reply. I, of course, gave all my full details -- the email address I'd used, my home address, my full name, etc. All the information that I'd given when I signed up as a supporter. From what I could tell they had everything they needed to be able to check and give an adequate reply. It took a while but I finally got a reply. This email came through on 2015-10-06: So that seems pretty clear: a non-answer to my question and they're asking for another 10 on top of the 3 they already have off me to find out what evidence they have that meant it was okay for them to take my 3 and then accuse me of lying. What's the betting that I'll spend that 10 and get a non-answer? What's even more infuriating is that I'm not actually asking for information they have on file about me, I'm asking for clarification for something they've already told me. It's really hard not to view this as a simple bait and switch. So now I'm left wondering what to do next; trying to decide if I just give it up as a bad job and accept that, really, nothing has changed and they're as bad as ever. Corbyn might well be talking a good game but, under that cover, it's still just another money-grabbing organisation that wants power and very little change."},{"title":"Change of watch face","url":"/2015/10/07/change-of-watch-face.html","date":"2015-10-07","content":"I'll be the first to admit that I'm a creature of habit. Once I get used to something I find it hard to change. In many areas of my life there has to be really compelling reasons to change something. I've found that this is the case with my Android Wear watch. When I first got it it took me a couple or so days to find a face that I was happy with and, in the end, I went with Pujie Black , along with a colour scheme I set up myself (called RGB , for obvious reasons). Today though I stumbled on Krona Sunlight . This face really got my interest. Part of the reason is that, while what I'm wearing is normally called a \"watch\", I don't see it as a watch (just like my phone isn't really a phone). It's a wearable Android device that gives me handy info at a glance and lets me set reminders and things without even having to reach for my phone, tablet, Chromebook or desktop machine. This face fits perfectly into that. While it lacks the battery information (edit to add: it doesn't lack battery information, it's just an option that is off by default), and second time display, that Pujie Black has, it more than makes up for it with the rather fantastic display of weather and sunrise/set information -- especially how it displays temperature. This was enough to not only have me buy a copy, but also to switch to it. I'm going to be sticking with it for the next couple of days to see how I feel about it and see if I miss any of the other information. This might be a little bit of change I can cope with."},{"title":"iMac Time Wiggle","url":"/2015/10/07/imac-time-wiggle.html","date":"2015-10-07","content":"Apparently that famous Apple obsession with design doesn't apply to the time display on the OS X login screen (the wake-from-sleep password confirmation one anyway): I've never noticed it before. I'm not sure if this came about with the upgrade to El Capitan or not. But now I've seen it I can't unsee it."},{"title":"El Capitan","url":"/2015/10/06/el-capitan.html","date":"2015-10-06","content":"Almost a week ago (yes, I have being meaning to write something down about this and have kept failing to do so) my iMac told me that there was a new version of the OS waiting for me. While this is doubtless no big deal for most Mac owners, this was interesting to me because it's the first time I've experienced an OSX upgrade since I got the iMac . The download took a while and, while the install had a couple of curious bumps along the way, nothing seemed to actually go wrong. The two main things I noticed were that it seemed to take the installer an absolute age to close down all running apps before it got to doing the installation. The other was that Mac progress bars seem to have a very odd way of calculating things. Often it would tell me that there was (for example) 28 minutes to go, it'd stay like that for 20 minutes, then drop 5 minutes, then appear to finish very soon after. Mostly though I just left it alone and let it do its own thing. While the whole process took quite a while, it came back just fine (if I'm fair I'm not sure it took much more time than when I upgraded my laptop from Windows 8.1 to Windows 10). The changes and improvements aren't really that obvious. I think I would say that the machine feels a little quicker in places, but nothing I can really put my finger on. One of the things I do like is the new split-screen facility for full-screen apps. While I don't use the full-screen facility that much I have found the need to split the screen before. Some of the other improvements I've read about seem to involve things I'm never going to use: either improvements to Safari (Chrome all the way for me), the Mac Mail app (Gmail all the way for me, with Kiwi for Gmail being my client of choice on the iMac) or various iOS-oriented things which are of little use (while I do own an iOS device it's not one I use much). Overall the thing I'm taking away from this is that the upgrade was smooth, nothing was obviously broken or changed in a way that was confusing (unlike some Windows or ChromeOS updates I've experienced in the past) and I didn't have to do anything that required much in the way of knowledge to keep it all going. Doubtless that won't always be the case, such is the nature of OS upgrades."},{"title":"My iMac thinks I'm in Spain","url":"/2015/09/10/my-imac-thinks-im-in-spain.html","date":"2015-09-10","content":"While on the phone earlier I was doing that thing you often do when chatting with someone where you don't have to concentrate on something in front of you: I was randomly clicking around stuff on a machine. In this case I was faffing around on my iMac . One of the places I landed was in the About dialog, looking at the support details: Out if idle curiosity I clicked the \"OS X Support\" link, which opened my browser and took me to Apple's website. Only.... it didn't take me to a part of the site that was that useful to me: Yes, for reasons best known to Apple or my iMac, I apparently need my help to be in Spanish. O_o I could understand this if I had my system set to Spanish, which I don't: About the only \"non-standard\" thing I have in my setup is the date, which I've set to ISO 8601 style rather than the usual UK style. I even experimented with changing that to the default on the remote chance that it was tickling some sort of odd bug in OS X. So, yes, another wonderful example of Apple stuff \"just working\" and being good for mortals. Well, for interesting values of \"working\" anyway."},{"title":"Labour said no thanks to my support","url":"/2015/09/07/labour-said-no-thanks-to-my-support.html","date":"2015-09-07","content":"I've never been a member of a political party. Ever. The main reason is I'm not that much of a \"joiner\" and I tend to dislike making compromises on subjects that actually matter. I have been a member of political causes in the past but even those I've had to leave because of the struggle I felt when it came to being associated with actions I disagreed with (yes, I am looking at you National Secular Society ). While there are plenty of causes that I support, either in spirit or in actual donations, I almost never actually join up. I've also been a fairly flexible supporter of candidates in general elections. While my politics are very much what you'd call \"left\" my voting patterns tend to be related to how suitable I find a candidate from the parties that I find I have a lot of overlap with in terms of stated aims. Unsurprisingly, for all of my voting life, this has been a case of selecting from Labour or LibDem candidates (with the odd look at the Green candidate). When doing so one of the major factors in making the choice has been tactical voting given that, for most of my life, I've lived in (what normally appeared to be) Tory safe seats. But, for many reasons, I've always felt an important connection to Labour. Possibly one of the best moments, in political terms, was that night in 1997 , as I drove back home, down the M3 from London, listening to the radio, hearing Tory after Tory fall and realising that, for the first time in my (politically concious) life, I was going to enjoy the benefits, we were all going to enjoy the benefits, of a Labour government. This was such a sweet victory after having really felt the defeat of 1992 . The Blair horror show that followed was.... horrific. I don't think I've ever felt as let down by an organisation as I did by that Labour government. Fast forward to this year and I was really hopeful that, perhaps, Labour would be back in government, and this time, lessons would have been learnt. I wasn't as enthusiastic as before but I was cautiously optimistic. Sadly, it wasn't to be. After this happened, and looking around me and seeing where we were now and where we were heading, I found myself thinking that, perhaps, this time, it was time to break my \"no joining\" rule. I started to seriously consider joining Labour, lending some sort of support, somehow being involved and taking part. That's when I first noticed the whole business of being able to take part in the Labour leadership election by being a supporter. This seemed like the perfect way to dip my toe in, see how I felt about being associated in some way, get a feel for how things worked and, perhaps, depending on how it all went, actually join. So I paid my 3.00 and looked forward to the process that was to follow. I then waited, and waited, and waited, and then on Saturday this happened: In other words.... I got purged . And a couple of events before this have me wondering and a little suspicious of how this went down. I'll make clear here though: my application to be a supporter was 100% genuine. As I say above, this was a first step on a road that I felt might actually end up with me joining a party -- something I've never done before. It wasn't something I did lightly. It was something I did after conversations with a couple of other people where the conversations were about genuine concern with how our country is shaping up right now. Even as late as a week before I got the above email I was having a conversation with my nephew who, I'm deeply proud to say, is a very politically-aware teenager (far more than I was at his age) and is actually a member of the Labour Party. The conversation was about how I was starting to trust the party again and how I was even considering joining depending on how events went. My application wasn't some joke thing, wasn't done on a whim, wasn't done to try and skew any result. It was done because it was something I cared about and wanted to explore further. Anyway, come late on last week I'd had no sort of ballot email and, prompted by a couple of emails from a couple of the leadership campaign groups, I filled in the form to ask them to hurry it up. I think it was late on Thursday evening (2015-09-03) or early Friday morning (2015-09-04). A little later on Friday this happened (Anroid twitter): Same follow as seen from Tweetdeck: I've no idea who @polycarponkundi is but it seemed clear from their timeline that they are a Labour supporter or even member and that they are a strong supporter of the Liz Kendall leadership campaign. I didn't think too much of the follow; it seemed like an unusual coincidence that I'd chase up my ballot email and then someone apparently involved in the party would follow me, but coincidences happen. Then, the following day, I get the letter telling me to sod off. Suddenly the coincidence seems less of a coincidence. I go and check the profile and notice that they've even unfollowed me, just a couple of days after the follow. Note the lack of \"follows @davepdotorg\" in the profile? Very odd. Right now I'm not drawing any firm conclusions about what happened, and I have asked them what the follow and unfollow was all about . It would be unfair of me to decide the events were connected without asking first. All of this though has made something clear to me. Labour have decided that they never want my support, ever again. I have it in writing. Well, sort of. What I actually have in writing is an email that says \"we're taking and keeping your 3.00 and we're calling you a liar while we do this. If you want to prove that you're not a liar you need to actually join us, actually send us even more money. Oh, and by the way, we're not going to tell you what evidence we have that you're a liar, so ner.\" Thank you Labour. At least I know where I stand now. You can safely assume that you'll never have my support ever again."},{"title":"Unknown promo","url":"/2015/09/04/unknown-promo.html","date":"2015-09-04","content":"Ahh, Google, knower of all things that can be known about me, tracker of all things that can be tracked about me, controller of my phone and even my watch, able to use Now to suggest stuff I need to know even before I need to know it. Tell me again what promo that 10GB was from..."},{"title":"Full Apple keyboard on Windows machine","url":"/2015/08/17/full-apple-keyboard-on-windows-machine.html","date":"2015-08-17","content":"I seem to have somehow messed up my left hand. I'm not sure what the problem is yet, I'm speaking to the doctor and have had an x-ray to check out one possible cause, but the simple fact is that my left hand has an issue. Sometimes the arm is painful, pretty much all the time a couple of fingers are near-numb. One unfortunate side-effect of this is that I'm finding typing rather uncomfortable. Except, that is, when I'm typing in my iMac . Given that the vast majority of the typing I do is on my Windows 7 desktop machine I decided it was time to look at getting a new keyboard, one that was as comfortable to type on as the Apple keyboard. Given that I really needed to be in a position where I could actually try the keyboards out I headed off to the local PC World. Long story short: none of the Windows-oriented keyboards I tried did it for me. None were as comfortable as the Mac keyboard. I tried a few a couple of times and then suddenly had an idea... Apple do a full-size keyboard and, from what I've seen in the past, it does work with Windows, after a fashion. So I went to talk to the Apple guy, checked they had one in stock, handed over 40 and headed home again. Having now worked with it for a couple of days I think this might be one of the best keyboard purchases I've ever made. It's not ideal, of course. The keyboard isn't designed to work with Windows, it's designed for the Mac. But for the most part I'm finding that it's not confusing and I'm adapting just fine. I had to go searching for an unofficial layout that I could install (one that's actually old enough that it doesn't even say it supports Windows 7) and installing that seems to have cured a few issues. The issues I do have remaining are: Depending on the application I'm in, @ and \" are swapped. Really, I'm not kidding. In SublimeText @ and \" are the right way round; in Skype they're the wrong way round. I suspect that this might be down to the fact that I need to restart applications so they take up the new mapping (a reboot of the machine might be in order here). The keyboard has no marked insert toggle key. There is one, it's the 0 on the numeric keyboard if you have (also missing, but with a mapping) numlock turned off. Alt and Win are the wrong way round. The Cmd key acts as the Win key and it is in the same position as Alt is normally in. I'm actually adapting to this pretty quickly. Apple hates the # key. Much like I have problems typing # on the iMac, the same issue exists when typing on Windows too. Whereas on the iMac I have to use Alt-3 to get a #, on the Windows machine I have to use Ctrl-Alt-3. Not ideal but it works. They're the main issues I've discovered so far. It's possible that there are other niggles waiting for me but, hopefully, there's workarounds for them too. Mostly though I'm finding that the small adjustments I have to make to how I work are worth it given just how comfortable this keyboard is to type on. I really do wish there was a Windows-oriented keyboard that had the exact same build quality."},{"title":"Bloody Facebook","url":"/2015/08/13/bloody-facebook.html","date":"2015-08-13","content":"I've never really liked Facebook. I forget exactly when I ended up on there -- perhaps 2009 or so -- but I can remember exactly who to blame. It was all the fault of Rich Daley . On an atheism-oriented BB that has long since fallen off the net he convinced me that it was \" X for adults\" (where X was a popular early social network whose name totally escapes me now) and I fell for it. And I hated it. But I stuck with it. I stuck with it until September 2011. I realised that after a few years of using it I still found the site confusing, ugly, unfriendly (in terms of design) and somewhat invasive too. On top of that I'd made the common mistake of allowing anyone I'd ever run unto on the net add me there and so the contact list was huge and out of control -- I didn't really know who most of the people were. So I deleted the account . Back then there was, as I recall, no explicit delete option, or to do the delete thing you had to deactive and wait 14 days, or some such thing. I know that I followed the advice in the docs and did whatever was required to have my account totally deleted. This week, at the urging of friends, I finally decided to create an account again. I initially tried to create the account using the old email address (well, actually, a variation on it that would appear to be the same to systems that understand the significance of a + in an email address) but it told me that the address was in use. Which was a worry. So I created the account using a different address (my actual \"main\" address this time, as opposed to my Google address) and set about setting it up. In doing so I tried to tell it that I wanted to associate my old address with this new account and, again, it refused, telling me there was an active account for that address. I then went and checked and, sure enough, there was my old account, still there, all the data, nothing had changed! Fucking Facebook! These days, however, it does look like there are very clear instructions on how to actually fully delete an account , so I've tried again for the old account. It's another 14 days of deactivation but with an actual promise that, yes, this time, they'll delete all my shit. They better. Meanwhile... I have a shiny new Facebook account. And I still find it confusing, ugly, unfriendly (in terms of design) and somewhat invasive."},{"title":"Best update ever","url":"/2015/08/03/best-update-ever.html","date":"2015-08-03","content":"Oh goodie! An update for Adobe Creative Cloud on the iMac! Oh! Improved update experience too! I really must install this then... Well fuck."},{"title":"Evernote discovers pop-up advertising","url":"/2015/07/09/evernote-discovers-pop-up-advertising.html","date":"2015-07-09","content":"By the looks of things, with the recent updates to their desktop applications, Evernote have discovered the joys of pop-ups for advertising purposes. I'm finding it just as annoying as it was back in the days when people thought it was the smart way to make you buy things on the web. Now, to be fair, the pop-up you see above is the one on my iMac and that at least has the good taste to only pop up within the application itself (although the Evernote icon in the dock at the bottom of the screen kept jumping around like it really wanted attention when this happened). The Windows one, however, is much worse. I've actually not had a chance to capture a copy yet as it normally has the habit of getting in the way while I'm actually trying to do something; but the Windows version has the bad taste to actually pop up over my desktop. Yes, that's right, over my bloody desktop! In both cases it's advertising Evernote's paid-for tiers in a way that it never has before. It's seriously annoying. Now, before anyone pipes up that it's a company that needs money to keep things going... I know. I don't mind that. I don't mind the odd nag here and there. More to the point I actually don't mind paying for software and services. I actually do pay for software and services. There's a handful of different tools and the like that I make good use of every month which I pay for because they're worth paying for. Evernote is one that I've been considering paying for too. The problem is, what they offer in the paid versions isn't really anything I need. Everything I use Evernote for can be done in the free version; I have no need to pay for it. There is, of course, a good argument to be made in favour of the idea that if you benefit from a service you should pay for it anyway so that it doesn't go away. Having watched the likes of Catch and Springpad disappear I think that's a very compelling argument and one that has had me, in recent months, thinking I should buy some paid-for Evernote tier. The problem I face now though is this: this move by Evernote to go with a pop-up nagware model, especially one that's willing to pop up nagging windows on my desktop, gives me the feeling that the company is struggling and getting desperate. While this should have me thinking that now is a really good time to pay for something I appreciate it's actually having the opposite effect. It's having me wonder if, in fact, I should be looking for an alternative that isn't giving this impression. Yes, even one that I'd need to pay for."},{"title":"Odd iPod update","url":"/2015/07/01/odd-ipod-update.html","date":"2015-07-01","content":"Last night, before heading for bed, I noticed that there was an update available for OS X on the iMac, and also for iTunes. Despite the late hour I decided to do the update anyway. OS X updated pretty smoothly (albeit with some rather unhelpful progress bars that appear to give estimated times that have no relation to reality), as did iTunes. I was then told that there was an update for my iPod as well (all part of this new thing where Apple have invented Spotify, obviously). I let that start doing its thing and that's where things got odd. First it started the update and the iPod appeared to insist that it wasn't plugged into the iMac, even though it was. Then I gave it a second go (after unplugging it and plugging it in again) and it all seemed to go through just fine, only... ...while the iPod was pretty sure it was now running iOS 8.4, iTunes on the iMac had other ideas: The following morning iTunes kept insisting that it needed to do the update so, even though the iPod was obviously up to date, I let it do it anyway. After it'd gone through the update process again it still insisted that the iPod was running 8.3 rather than 8.4. Until, that is, I unplgged it and plugged it back in again. So now it all seems fine. I just had to do a variation on \"have you tried turning it off and on again?\" Once again I find myself running into things on a Mac that are very common elsewhere, on other operating systems, and which Mac owners would often have you believe weren't an issue."},{"title":"My first couple of weeks with an iMac","url":"/2015/06/27/my-first-couple-of-weeks-with-an-imac.html","date":"2015-06-27","content":"My history with computers starts with a Sinclair ZX81 in the early 1980s, followed shortly by a Vic20, then on to the BBC B and fairly quickly on to very early IBM PC compatible machines. In the early 1990s I added OS/2 (during the introduction of Warp) and not too long after that GNU/Linux. Along the way I've also used the odd Unix here and there as well as CP/M, RSTS and VMS. Aside from an inherited Mac whose model name escapes me, and whose operating system version also escapes me, I've never really had too much exposure to the world of Apple. A couple of weeks back all of that changed. It's quite a long time since I had a Unix of some form as a desktop machine and I was starting to get the urge to have one again. During all of this time I've had a GNU/Linux box or two available but for the past few years I've always used them from the (dis)comfort of my Windows desktop. Generally that was fine because the uses I had were not desktop. Anyway, long story short: I started out thinking that I wanted some form of Unix on my desk again and, somehow, ended up walking out of a shop with an iMac. Given the above history I thought it might be fun to jot down my experiences in the first couple of weeks. This will be a vaguely random wander through my experiences. It's not a review. It's not even really intended as a judgement of the machine and the operating system. It's nothing more than a collection of notes of what I found and my reaction to what I found. The keyboard The first strong reaction I had to the machine was regarding the keyboard. I thought I was going to hate it. I've had the misfortune of using various chiclet keyboards over the years and I've hated every single one. I find that I can't type on them, that it doesn't feel right, and that it makes my fingers ache badly if I spend too much time using them. My history and experiences has always been such that I've generally preferred very mechanical-feeling keyboards. This just wasn't the case with the iMac keyboard. I don't know why, I still don't know why, but this feels like one of the most comfortable keyboards I've ever typed on. Despite the keys being chiclet style they move in a very positive way that really surprised me. It doesn't hurt to type, at all, and I'm finding I can type faster on this keyboard than any other I've typed on before. There is a flipside though. I find the whole design far too cramped. Even now, a couple of weeks later, as I type this on it, I wish the keys were just a little bigger and just a little more spaced out. I'm adjusting, of course -- much of this is about muscle memory -- but it does mean that it's in a constant fight with my \"knowledge\" of my other main keyboards. And then there's the keys that it lacks. I'm still finding that this is a terrible keyboard for a programmer. For one thing, here on the UK version of the keyboard, there's no # key. At least, there's no simple, comfortable, direct access to the # key. Any time I want to type a # I have to shift my left hand to find the (I think it's called the) option key and hit 3. Shift 3 is . And it gets even worse. This setup doesn't work at all in GNU emacs so I then have to put the keyboard in Australian mode so I can use shift-3 to get a #. Why there isn't a proper # key is beyond me. And then there's the (on the version that came with this iMac) complete lack of page keys as well as home and end. Overall this makes the whole keyboard feel very unfriendly to programmers and also to writers in general. This, of course, is my bias and muscle memory from PCs showing. I'm still not convinced that that bias and muscle memory is wrong. The mouse When I first started with it I hated the mouse. I should be fair and point out that, overall, I hate mice anyway. For a good 20 years I've thrown away every mouse I've ever had turn up with a machine and have made use of a trackball instead. I find that a trackball gives me far more control and is far more comfortable. So, initially, I put the Apple mouse to one side and plugged in a trackball instead. For reasons I forget now I found myself needed to use the Apple mouse again. Once I did that I decided to \"force\" myself to give it a fair shot and, now, I'm glad I did. Much like with the keyboard, despite me having a bias against what it is, this has turned out to be one of the most comfortable mice I've ever used. It sits right in the hand, the lack of actual buttons means I don't have to shape my hand to fit the design but, instead, the design allows for how my hand rests. I also rather like the gestures too. This is the first mouse that has stayed on my desktop. I'm surprised. By the way, whoever thought that the \"natural\" scroll option, which is on by default, was \"natural\", is barking mad. The GUI One of the main intended uses for this machine is the Unix shell, working inside the terminal. Given that the actual UI of the OS doesn't matter so much to me. That said, I'm finding it pretty pleasant. I find it a lot tidier-looking than Windows, although I also find it more frustrating in some places. One good example is in the Finder, when I have a folder open. I find that it's quite common for me, on Windows, when I have an Explorer window open, to want to copy the path of the folder for use elsewhere. That's very easy to do because the path is in an edit field at the top of the window and can be edited and copied. If there's a way to do this with the OS X Finder I've yet to figure that one one. Another thing I'm still not getting used to, and I'm still very unconvinced by, as a design decision, is the business of having an application's menus always appear at the top of the screen disconnected from the application windows themselves. I appreciate that this is a very Apple/Mac way of doing things but I really can't get used to the idea -- especially given that it gives the (incorrect) impression that the whole GUI is really single tasking. On the whole though most of this doesn't matter too much to me. Large parts of what I'm doing is in the terminal window, with other parts of it being in my editors of choice (either SublimeText or GNU emacs, depending on what I'm doing) or inside Google Chrome. In other words the general experience is one that carries over most of the main operating systems I've used on desktop machines. Installing software For an operating system that prides itself on being simple to use and easy to understand, and especially one whose bigger fans sell as being simple to use and easy to understand (especially in relation to Windows), the whole business of installing software seems very confusing and very scrappy. So far I've found a few different ways of installing software and none of it makes a whole lot of sense to me without going and searching about it and reading up on it. Sometimes I download an app and all I need to do is drag it into the Applications folder. Other times I get a zip which I have to open and then... it can go a couple of different ways. Sometimes I get a 'dmg' and when I open that up I get a window where I have to drag one icon onto another icon in that window to do the install. Sometimes I get something like the last one I mention but instead I have to double-click on an icon that's in the window. There might even be other options I've had to follow. I forget now. And then there's the business of removing software! That seems to be complete chaos. In some cases you delete the app and it's all good. In other cases you need to do that and hunt down some other bits and remove them too. In other cases it seems like the author has supplied their own uninstaller. We've been here before. I know this setup rather well. This is exactly the sort of world we lived in back when Windows 3.1 was a new thing. This came as and still is a massive surprise to me: OS X is as sophisticated as a fancy shell that ran on top of MS DOS when it comes to software management. Doing the right thing, except when not While I'm on the subject of the famous great design of the Mac... what's up with the business of seeing the time format? The system preferences seem very flexible when it comes to setting date and time formats. I really like the dialog that provides this: As you might see above, my preference when it comes to date formats is to have everything in ISO 8601 format. Having set that I then noticed that the time shown in the menu bar on the desktop was.... whatever the hell Apple appear to have decided for me! Even Windows lets me set the date format as I want it in the desktop time display. Apple, meanwhile, seem to provide a great method of letting you set your date and time formats \"just so\" and then they seem to just go right ahead and ignore your preference in the one place you'll see it the most. If you have a Mac, you have software I wrote on it (I think) From what I could tell every Mac has a copy of GNU emacs installed, out of the box. That actually kind of impressed me. Sure, it's a rather out of date version of GNU emacs, but it's a copy of GNU emacs and that's all that matters. That fact actually means something rather interesting, to me. See, there's two small packages that are part of GNU emacs that I originally wrote. One is called 5x5, the other quickurl. So, yeah, from what I can see, on every new Mac you'll find two bodies of code that I originally wrote, pre-installed. Yeah, I know, shitty claim to fame. I'll take it anyway. ;) Overall initial impression Overall my initial impression is a good one. The Apple iMac seems to make for a pretty good Unix workstation. The keyboard layout could do with some work to make it more friendly to programmers (well, to this programmer) but overall it all makes sense and is easy to navigate. If most of what you do is actually online then I'd say that an iMac would be a huge waste of money. If you want a desktop machine for web browsing and generally working \"in the cloud\" then you'd do a lot better to buy a Chromebase (or, of course, a Chromebook if you're looking at Macbooks). On top of this, if most of what you're doing is online but you want to do some client-side stuff such as image/video editing and gaming then I struggle to see how an iMac would be a good choice too. For the money it's hilariously underpowered when compared to a reasonably equivalent Windows PC (or, of course, GNU/Linux machine if what you want to do can be done there). My own reasons for purchase were about having a desktop Unix workstation that I could install various compilers on so I could muck about and work on some fun projects I want to get done. It was an unusual extravagance that I don't regret and, so far, I've been pleased with. There's very few people I'd actually recommend one to though as it seems pretty clear to me that, generally, their money could buy them so much more. But it's a nice new shiny toy. ;)"},{"title":"Wear timer issue fixed, sort of","url":"/2015/06/26/wear-timer-issue-fixed-sort-of.html","date":"2015-06-26","content":"Following on from yesterday's problem with the Android Wear timer I think I now have a solution. It came up while chatting with Mike McLoughlin about the issue . I got to thinking that this problem felt like one that I've seen a number of times before with Google stuff. One thing that's rather common (in many cases for very obvious reasons -- you can't cover the whole world in one go) with Google is how they struggle to get languages and localisation right. This felt like it was a similar issue. Mike had reported that his watch appeared to be unaffected by the issue (I'm guessing he's on the latest version of Wear -- the conversation headed off in a different direction before that became necessary) so I checked what his language was on his phone. Turns out he was the same as me: British English. So much for that idea. But then he suggested switching to US English and back again. Happy enough to apply a very Microsoft \"turn it off and on again\" approach to a Google device (really, all big tech companies really are the same and really do suffer the same issues) I switched to en-US on the phone and tried setting a timer in voice on the watch. It worked! So then I switched back to en-GB on the phone and... ...it still worked! I've tried setting timers in voice on the watch a few times since and it's yet to fail. It would appear, as odd as it is, that this is the fix. Well, a fix."},{"title":"Did Google just break Wear timers?","url":"/2015/06/25/did-google-just-break-wear-timers.html","date":"2015-06-25","content":"I didn't pay too much attention to it when it happened but it looks like Android Wear, on the phone side, got an update in the last 24 hours. Only this evening did I notice that this seems to have broken something I heavily use on my watch: timers. I find the timer facility on Wear especially useful when I'm cooking, either to ensure that different parts of the cooking process come together at a sensible time, or when I put something on and need to go off and do something else (perhaps come back to the office while and get on with some work as something bakes, etc). To be clear, the timer app is still there and, if I select to start a timer \"by hand\" on the watch, it works as it always has done. Also, if I say \"OK Google, set a timer for five minutes\" it still does the voice recognition thing: It's what happens next that's the problem. Before it would have started a countdown timer. As well as vibrating the watch when the timer runs down the timer app also has the very useful feature of showing the countdown on the watch face. This means you can glance every so often and see how long is left to go. Instead, as of today (well, this evening when I made dinner was when I first noticed it), it starts an on-watch alarm app instead! This is utterly useless. Sure, it does still vibrate the watch when the alarm time arrives, and the alarm time is the right offset from when the timer was requested, but it lacks the on-face countdown. It's an alarm. It's not a timer! Looking in the Wear app it would appear that the correct application is assigned to the correct action: As such, I'm at a loss on how to fix this. I can't find anything on the watch itself that could be done to change this, and I've tried restarting the watch on the off chance that something went a bit odd. It turns out too that I'm not alone. I found a thread on reddit where others have the same problem . What really bugs me about this is that this is very Google. I've run into this sort of thing so many times before, be it on Android, ChromeOS or in their apps in general. They'll change (or screw up) something that's very simple and straightforward and in common use, something that should show up in testing pretty easily. Surely there has to be some way of pushing out an update without screwing up the apps that are assigned to actions? As much as I really like what Google offer, as much as I value their services and global platform over the other choices, this sort of thing frustrates the hell out of me."},{"title":"Medium login on Android and iOS","url":"/2015/06/25/medium-login-on-android-and-ios.html","date":"2015-06-25","content":"I woke up this morning to find that one of my more recent favourite websites, Medium , had finally released an Android application. I'm more of an avid reader than a writer on there (I've only ever written 2 articles on there, and have toyed with the import facility too) so I imagine the app won't make too much of a difference to me, but it was nice to see that something that had been iOS-only was now on Android too. I installed it on my Nexus 7 and Nexus 6 and then, given that I have an iOS device now , I installed it on that too. In doing so I noticed a very curious difference: vs: Notice how Android has Google as an option whereas that's not an option on iOS? The curious thing is, when I installed it on my Android devices, I logged in with my Google account and it all just worked. I was into my account, there were the sorts of stories I'd be interested in, and there were the couple of stories I'd written. On iOS I logged in with my Twitter account and the same thing happened (I don't use and don't have an account on Facebook). It was than that I had to think about how I even logged into Medium normally (via the web, which is what I'd always used up until now). Seems I'd always used the Twitter login (which would make sense). So here's the thing that's got me wondering now: when I logged in with my Google account, how did it make the connection to my Twitter account? I mean, sure, there's got to be enough data kicking around to actually make the connection and it seems like a safe enough one to make but... huh? I must be missing something here though, it's as unexpected as it is handy. It's also worth noting that if you go to log in to the website Google accounts are not an option (there is a sub-option for \"Android Users\" where you have to create an account based off your email address, from what I can see). I'm left trying to decide if I missed a step here, if this is clever, or if this is just plain creepy (and who's responsible for having made the connection). Edit to add: Cara from Medium was kind enough to notice my tweet pointing to this post and let me know the how and why of the above . Turns out it's what Rich suggested in the comments."},{"title":"And now for some iOS","url":"/2015/06/23/and-now-for-some-ios.html","date":"2015-06-23","content":"I'm on a bit of a \"explore other universes\" trip at the moment, it would seem. The other weekend I finally cracked and purchased my first ever OS X device and, earlier today, I purchased my first ever iOS device. Don't worry, I'm not abandoning the world of Android; far from it if my experiences of iOS so far are anything to go by. However, having started slowly working through a book that teaches Cocoa and Swift I thought it might be interesting to be in a position, at some point in the future, to be able to make and throw an app at an iOS device and it seemed the most affordable way of doing that was to grab an iPod. So I did. One of the first things I did, and I'm glad to find it was possible, was to load it up with apps that make it into a reasonable Google device (so, so far, I've got Gmail, Google+, Google Calendar and Google Music on there -- need to sort Google Drive too, at least). Next up was to get some music on it too -- might as well actually use it to listen to music, I guess. That actually turned out to be more fun than I was expecting. See, I gave up on iTunes many years ago, back when it was pretty much the only legit method of buying music online. Since then I've tended to work with ripped copies of my CD collection or I've listened to music I've bought on Google Play (the latter bulked out with the former thanks to Google's music uploader). And here's the fun part: if you use the recent Google Music Chrome app (which, it seems, allows unlimited downloads of your albums) to pull the music down, and drop them into iTune's import folder, magic happens and iTunes gets nearly populated with music. Even better, music that I'd originally ripped as WMAs comes back own as mp3s, so solving the problem of iTunes not doing WMAs. Handy! So, anyway, that's the iPod set up as a generally useful device. As for iOS itself.... Ugh. I'm far from impressed. Compared to Android it feels old and clunky and very constraining. For example, I can't really control what's on the home page. Sure, I can move things about, and I can even remove apps I've installed, but I can't remove/hide Apple's own apps at all. The best I've managed to do is drop all of them in a folder together and ignore that folder. I'm finding the whole navigation thing kind of frustrating too. The lack of a standard back button -- as you have on Android -- means that different apps seem to do different things in terms of allowing back navigation. I'm also still unsure how you can easily task switch (if there is a way of doing that it's not obvious to me). Another thing that's frustrating me is \"AirDrop\". I tried to use it to get the screenshot you see above onto my iMac but nothing I did would make it work. The iPod would see the iMac and the iMac would see the iPod but the filed didn't appear to want to move at all. Yet another thing that seems rather unstable is the whole business of WiFi sync. That seems like a sensible idea -- let iTunes on the Mac know that the iPod lives on the same network and have them sync that way. Problem is that I'm finding that it drop out during a sync more often than not. The only reliable method of doing a sync that I've found is to use the USB cable. I've yet to write the blog post about my experiences with the Mac so far but what I'm finding here fits in with what I've found with the Mac: some of the ideas are really rather clever but they just don't quite work as well as people would seem to want to have you believe. Apple gear has this reputation of \"just working\" and I'm finding that this really doesn't seem to be the case at all. Still, it's all a learning process and I know far more about Apple gear now than I did a week or so back, and I'm learning more as I go."},{"title":"ChromeOS file manager got better","url":"/2015/06/22/chromeos-file-manager-got-better.html","date":"2015-06-22","content":"The ChromeOS file manager has always been a bit.... rubbish. Kind of. Back in the very early days it only let you work with the Chromebook's (very small) local file system. Then, some time later, they added Google Drive integration, which was seriously handy. But it still lacked some important stuff, like the ability to mount filesystems from Windows machines, or to use sftp, or the like. That seems to have all changed with the addition of the \"Add new services\" button: As is often the way with Chromebooks, unless you're closely following forums or Google+ communities (I don't), you tend not to know when this stuff is going to turn up or even when it does (I mean, really, is it too much to ask that the device alert you to handy new features? I mean, my watch did !). For all I know this has been there a while and it's the first time I've noticed. No mater how long it's been there, it's really rather handy. I've already been able to hook it up to my Dropbox account, there's an SMB filesystem handler (that I've not had a chance to test yet) and an sftp service (which I have tested and seem to work well enough for my needs). There's more too: I'm guessing there's an API out there now that people can work with so I guess the list of services you can install will grow over time. For people who want to do a little more than just browse the web, Chromebooks (and other Chrome* devices for that matter) just got a little more useful."},{"title":"A ChromeOS issue","url":"/2015/06/21/a-chromeos-issue.html","date":"2015-06-21","content":"Since the last update I've being having a rather odd issue on my old Chromebook. This is my Samsung Series 5, the \"original\" commercial Chromebook to be released (in the UK anyway). I first noticed it in TweetDeck but have since noticed that it's affecting any browser tab. Simply put, sections of the display either \"lag\" in their content or they simply show up empty. First I tried to get a screenshot of what was going on but it didn't work. I did get to show that there was a problem, but what was grabbed by the screenshot wasn't what I saw seeing on the screen. Here's the screenshot: The only way I can show how it looked to me on the screen is with a (rather horrible I'm afraid) photo: It's unclear to me if this is something wrong with the Chromebook itself, or in this release of the OS. It is running the beta channel -- currently on 44.0.2403.54 -- so, of course, this sort of thing is to be expected. If it is the case that that Chromebook is on its way out -- either in terms of that actual machine dying or support for it at the OS level going away -- it won't be a terrible loss. It's been a great machine and has served me well and wasn't terribly expensive to begin with (the lack of expense is one of the things I really like about Chromebooks, which is why the Pixel continues to perplex me), replacing it with one of the newer crop of Chromebooks won't break the bank. But I'd be a little sad to see it go, I've done some pretty significant things on it and it is, in some ways, a little bit of computer history. Edit to add: I've now moved it back over to the stable channel, with a powerwash on the way (of course) and this seems to have done the trick. I'm no longer seeing any problems. The switch to stable even had the problem showing. Here's a video of stable downloading: That's pretty much the sort of thing I was seeing all over the place, and it appeared to be getting worse as time went on. Hopefully this was a one-off and the problem isn't simply up in the beta cannel and waiting to head down to stable."},{"title":"Moto360 updated","url":"/2015/06/20/moto360-updated.html","date":"2015-06-20","content":"Yesterday evening I finally got the following notification on my Moto360: Given the charge was quite a way below that I took the watch off and put it on charge and then did the update later. From what I could tell it all went pretty smooth. After updating it even offered me a little tutorial on some of the new things it's added. So far I've used (or set up) the following: The much better \"launcher\" Finding and running apps on the watch was always a bit of a pain, so much so that others had even written special launchers for Android Wear. This seems to be pretty much solved now. Pressing and holding the watch's side button will pop up application list, from here you can swipe right to your contacts (them letting you send messages, start calls, etc) and right again for the usual list of actions that you used to go straight into. The way it's done now makes a lot more sense and seems far cleaner. WiFi I've yet to notice the benefit of this, but I've not paid too much attention yet either. The watch now does WiFi. This is supposed to mean that it can still work with my phone when it's out of Bluetooth range. I say I don't know if it's working yet because I use an app to tell me if my phone is out of range and it still keeps tripping as normal -- but I'm unsure if that means it's simply telling me it's out of BT range but really the watch is now doing its thing over WiFi, or perhaps the phone connection really has been lost despite me having set up the WiFi connection. More testing needs to happen here. Setting this up was curious: I had to turn it on on the watch and then select the access points I wanted to work with, again on the watch. But to actually connect I had to switch back to my phone to enter the AP passwords (which makes perfect sense of course, nobody wants to type passwords into a watch face). Gestures These needed to be turned on in settings. I've being using them this morning to navigate cards on the watch and it's really well done and really natural. Simply put, you flick your wrist up, or down, to \"flick\" from one card to another. All it seems to be missing is some method of gesturing that I want to swipe a card out of the way. Other than the above it's pretty much business as usual. Hopefully there's been some work to improve battery life and all that sort of stuff, and only time will tell if a difference has been made there."},{"title":"ChromeOS ssh has gone! (sort of)","url":"/2015/06/19/chromeos-ssh-has-gone-sort-of.html","date":"2015-06-19","content":"I've no idea when this happened, and I'll admit that the advice it gives is advice I've mostly being following anyway for quite a long time, but it seems that ssh in the ChromeOS terminal has been removed. This is what just happened when I tried to use it just now: To be fair, Chrome Secure Shell is pretty damn good and has served me well for the past couple or so years, working well on the Chromebook and on Windows 7 and 8 (and also now on the Mac, although I'm tending to use ssh in its native terminal more). I wonder if any other of the limited features of the ChromeOS terminal (in non-dev mode anyway) are going to go the same way? As an aside to the above, something kind of ironic happened as I was writing this. I opened Chrome so I could preview the post as I was writing it and I suffered one of Chrome's rather common extension crashes. Look what one of those extensions was (and I wasn't even using it at the time): Not exactly the best advert for the non-optional replacement."},{"title":"A mild Chrome annoyance","url":"/2015/06/18/a-mild-chrome-annoyance.html","date":"2015-06-18","content":"For a long time now Chrome has been my web browser of choice. It has, to some degree, become my \"other emacs\" (ignoring for a moment that my use of GNU emacs has sort of lapsed the last few years). By that I mean that it's a portable environment that serves me well on many operating systems and, for one of my machines, actually is the operating system. I really appreciate how Chrome's sync lets me feel right at home no matter which machine I'm on. But I've run into one small issue that's kind of annoying. In some situations I find it pleasing, and I find it makes sense, that some web \"apps\" open in a window of their own rather than in a Chrome tab. On Windows and on ChromeOS this is simple enough, all I need to do is find the \"app\" in the Chrome app launcher, pull up the content menu, and tell it to open as a window. Nice and simple 1 . Now, the Mac, so well known for doing everything every other OS does but doing it better and being easier to use.... you'd expect it's at least the same there, right? Nope. There's no option at all to open as a window! So, on the Mac, while I'd love to be able to open Gmail as a window/app in its own right, I'm totally out of luck, it seems. I've no idea whose \"fault\" this is. It's not clear to me if this is a Chrome/Google decision or if it's about how things have to work on a Mac. Thing is, I find it hard to believe that it's the latter given that Google Keep runs in its own window on the Mac and I can happily pin it to the dock. It's that simple on ChromeOS too. In case you're wondering why I didn't also illustrate that, it's because you can't take a screenshot on ChromeOS while you've got a context menu open. O_o&#160; &#8617;"},{"title":"Hello, World!","url":"/2015/06/18/hello-world.html","date":"2015-06-18","content":"Hello, world. So I've decided that it's time I had a blog again. An actual blog. Not a set of posts on Google+ or a torrent of 140-character thoughts on twitter but an actual blog. Part of the reason for this is that there's a couple of personal coding projects I want to have a go at over the next few months and writing about them as I work on them might be fun. Another reason is that I've being wanting to explore the business of hosting a blog on GitHub pages for quite some time and now's the perfect time to do it. So how am I doing this? Well, for starters, I recently acquired an iMac. The reasons for how and why I chose to do this are varied and mostly uninteresting but what it does mean is that, for the first time in quite a long time, I have a Unix desktop machine again. This fact alone means it's nice and easy for me to play with the likes of Git (or, at the moment more GitHub for Mac than the command line git), ruby, Jekyll and SublimeText (along with a rather nifty package for quickly kicking off a blog post ). So that's how I'm doing it. Writing it all locally and pushing it up to GitHub and hosting it with GitHub Pages . As this goes on I imagine much will change. I've started out with a basic setup, created by simply using: davep@Ariel:~/blogging$ jekyll new davep.github.com From now on I'll be playing with styles and my own layouts to see what I can come up with and what I like (although, I most say, for the most part I'm actually liking the clean look it delivers out of the box). One thing that's obviously missing right now is a facility for commenting. That's something I'll look into should I feel it's necessary -- from what I've seen elsewhere it's easy enough to make use of something like disqus . Update: This has now happened. One other thing I might look at doing is putting this behind my own domain. For the moment it's only available via github.io and I guess it might look nicer if it was actually available via a URL that looks like the name I've attached to the blog. Update: This has now happened. Anyway, that's it for now. Time to push this up and think some more about where it'll go from here."}]